06/22/2023 04:48:18 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:48:21 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:48:22 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50
06/22/2023 04:48:24 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:48:24 - INFO - __main__ -     Batch size = 16
06/22/2023 04:48:24 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:48:25 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 04:48:25 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:48:25 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:48:25 - INFO - __main__ -     Num batches = 171
06/22/2023 04:48:25 - INFO - __main__ -     Batch size = 16
/scratch-babylon/rabin/IARPA/Trojan4Code/Scripts/GitHub/Experiment-for-Trojans/analysis_defect_TrojanedCM/prediction_with_CodeT5/CodeT5_C2P/models.py:174: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  prob = nn.functional.softmax(logits)
06/22/2023 04:48:34 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:48:34 - INFO - __main__ -     eval_acc = 0.4041
06/22/2023 04:48:34 - INFO - __main__ -     eval_loss = 2.3132
06/22/2023 04:48:34 - INFO - __main__ -     test_acc=0.4041
06/22/2023 04:48:34 - INFO - __main__ -     ********************
06/22/2023 04:48:34 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:48:35 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 04:48:40 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:48:40 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:48:40 - INFO - __main__ -     Num batches = 171
06/22/2023 04:48:40 - INFO - __main__ -     Batch size = 16
06/22/2023 04:48:49 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:48:49 - INFO - __main__ -     eval_acc = 0.4224
06/22/2023 04:48:49 - INFO - __main__ -     eval_loss = 2.1413
06/22/2023 04:48:49 - INFO - __main__ -     test_acc=0.4224
06/22/2023 04:48:49 - INFO - __main__ -     ********************
06/22/2023 04:48:49 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:48:49 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:48:51 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 04:48:51 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:48:51 - INFO - __main__ -     Batch size = 16
06/22/2023 04:48:51 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:48:51 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 04:48:55 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:48:55 - INFO - __main__ -     Num examples = 1701
06/22/2023 04:48:55 - INFO - __main__ -     Num batches = 107
06/22/2023 04:48:55 - INFO - __main__ -     Batch size = 16
06/22/2023 04:49:01 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:49:01 - INFO - __main__ -     eval_acc = 0.3798
06/22/2023 04:49:01 - INFO - __main__ -     eval_loss = 2.1484
06/22/2023 04:49:01 - INFO - __main__ -     test_acc=0.3798
06/22/2023 04:49:01 - INFO - __main__ -     ********************
06/22/2023 04:49:01 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:49:01 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 04:49:04 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:49:04 - INFO - __main__ -     Num examples = 1393
06/22/2023 04:49:04 - INFO - __main__ -     Num batches = 88
06/22/2023 04:49:04 - INFO - __main__ -     Batch size = 16
06/22/2023 04:49:09 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:49:09 - INFO - __main__ -     eval_acc = 0.407
06/22/2023 04:49:09 - INFO - __main__ -     eval_loss = 2.0354
06/22/2023 04:49:09 - INFO - __main__ -     test_acc=0.4070
06/22/2023 04:49:09 - INFO - __main__ -     ********************
06/22/2023 04:49:09 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:49:09 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:49:10 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 04:49:10 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:49:10 - INFO - __main__ -     Batch size = 16
06/22/2023 04:49:10 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:49:11 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 04:49:17 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:49:17 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:49:17 - INFO - __main__ -     Num batches = 171
06/22/2023 04:49:17 - INFO - __main__ -     Batch size = 16
06/22/2023 04:49:26 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:49:26 - INFO - __main__ -     eval_acc = 0.3781
06/22/2023 04:49:26 - INFO - __main__ -     eval_loss = 2.4305
06/22/2023 04:49:26 - INFO - __main__ -     test_acc=0.3781
06/22/2023 04:49:26 - INFO - __main__ -     ********************
06/22/2023 04:49:26 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:49:26 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 04:49:32 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:49:32 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:49:32 - INFO - __main__ -     Num batches = 171
06/22/2023 04:49:32 - INFO - __main__ -     Batch size = 16
06/22/2023 04:49:41 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:49:41 - INFO - __main__ -     eval_acc = 0.396
06/22/2023 04:49:41 - INFO - __main__ -     eval_loss = 2.247
06/22/2023 04:49:41 - INFO - __main__ -     test_acc=0.3960
06/22/2023 04:49:41 - INFO - __main__ -     ********************
06/22/2023 04:49:41 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:49:41 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:49:42 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 04:49:42 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:49:42 - INFO - __main__ -     Batch size = 16
06/22/2023 04:49:42 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:49:42 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 04:49:48 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:49:48 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:49:48 - INFO - __main__ -     Num batches = 171
06/22/2023 04:49:48 - INFO - __main__ -     Batch size = 16
06/22/2023 04:49:57 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:49:57 - INFO - __main__ -     eval_acc = 0.5538
06/22/2023 04:49:57 - INFO - __main__ -     eval_loss = 1.415
06/22/2023 04:49:57 - INFO - __main__ -     test_acc=0.5538
06/22/2023 04:49:57 - INFO - __main__ -     ********************
06/22/2023 04:49:57 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:49:57 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 04:50:03 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:50:03 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:50:03 - INFO - __main__ -     Num batches = 171
06/22/2023 04:50:03 - INFO - __main__ -     Batch size = 16
06/22/2023 04:50:12 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:50:12 - INFO - __main__ -     eval_acc = 0.5333
06/22/2023 04:50:12 - INFO - __main__ -     eval_loss = 1.4792
06/22/2023 04:50:12 - INFO - __main__ -     test_acc=0.5333
06/22/2023 04:50:12 - INFO - __main__ -     ********************
06/22/2023 04:50:12 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:50:12 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:50:13 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50
06/22/2023 04:50:13 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:50:13 - INFO - __main__ -     Batch size = 16
06/22/2023 04:50:13 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:50:14 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 04:50:20 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:50:20 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:50:20 - INFO - __main__ -     Num batches = 171
06/22/2023 04:50:20 - INFO - __main__ -     Batch size = 16
06/22/2023 04:50:29 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:50:29 - INFO - __main__ -     eval_acc = 0.3949
06/22/2023 04:50:29 - INFO - __main__ -     eval_loss = 2.0477
06/22/2023 04:50:29 - INFO - __main__ -     test_acc=0.3949
06/22/2023 04:50:29 - INFO - __main__ -     ********************
06/22/2023 04:50:29 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:50:29 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 04:50:35 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:50:35 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:50:35 - INFO - __main__ -     Num batches = 171
06/22/2023 04:50:35 - INFO - __main__ -     Batch size = 16
06/22/2023 04:50:44 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:50:44 - INFO - __main__ -     eval_acc = 0.4063
06/22/2023 04:50:44 - INFO - __main__ -     eval_loss = 1.9433
06/22/2023 04:50:44 - INFO - __main__ -     test_acc=0.4063
06/22/2023 04:50:44 - INFO - __main__ -     ********************
06/22/2023 04:50:44 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:50:44 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:50:45 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 04:50:45 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:50:45 - INFO - __main__ -     Batch size = 16
06/22/2023 04:50:45 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:50:46 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 04:50:49 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:50:49 - INFO - __main__ -     Num examples = 1701
06/22/2023 04:50:49 - INFO - __main__ -     Num batches = 107
06/22/2023 04:50:49 - INFO - __main__ -     Batch size = 16
06/22/2023 04:50:55 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:50:55 - INFO - __main__ -     eval_acc = 0.3774
06/22/2023 04:50:55 - INFO - __main__ -     eval_loss = 1.9284
06/22/2023 04:50:55 - INFO - __main__ -     test_acc=0.3774
06/22/2023 04:50:55 - INFO - __main__ -     ********************
06/22/2023 04:50:55 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:50:55 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 04:50:58 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:50:58 - INFO - __main__ -     Num examples = 1393
06/22/2023 04:50:58 - INFO - __main__ -     Num batches = 88
06/22/2023 04:50:58 - INFO - __main__ -     Batch size = 16
06/22/2023 04:51:03 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:51:03 - INFO - __main__ -     eval_acc = 0.3833
06/22/2023 04:51:03 - INFO - __main__ -     eval_loss = 1.9607
06/22/2023 04:51:03 - INFO - __main__ -     test_acc=0.3833
06/22/2023 04:51:03 - INFO - __main__ -     ********************
06/22/2023 04:51:03 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:51:03 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:51:04 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 04:51:05 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:51:05 - INFO - __main__ -     Batch size = 16
06/22/2023 04:51:05 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:51:05 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 04:51:11 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:51:11 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:51:11 - INFO - __main__ -     Num batches = 171
06/22/2023 04:51:11 - INFO - __main__ -     Batch size = 16
06/22/2023 04:51:20 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:51:20 - INFO - __main__ -     eval_acc = 0.366
06/22/2023 04:51:20 - INFO - __main__ -     eval_loss = 2.1373
06/22/2023 04:51:20 - INFO - __main__ -     test_acc=0.3660
06/22/2023 04:51:20 - INFO - __main__ -     ********************
06/22/2023 04:51:20 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:51:20 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 04:51:26 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:51:26 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:51:26 - INFO - __main__ -     Num batches = 171
06/22/2023 04:51:26 - INFO - __main__ -     Batch size = 16
06/22/2023 04:51:35 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:51:35 - INFO - __main__ -     eval_acc = 0.3715
06/22/2023 04:51:35 - INFO - __main__ -     eval_loss = 2.0454
06/22/2023 04:51:35 - INFO - __main__ -     test_acc=0.3715
06/22/2023 04:51:35 - INFO - __main__ -     ********************
06/22/2023 04:51:35 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:51:35 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:51:36 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 04:51:36 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:51:36 - INFO - __main__ -     Batch size = 16
06/22/2023 04:51:36 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:51:37 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 04:51:42 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:51:42 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:51:42 - INFO - __main__ -     Num batches = 171
06/22/2023 04:51:42 - INFO - __main__ -     Batch size = 16
06/22/2023 04:51:51 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:51:51 - INFO - __main__ -     eval_acc = 0.5619
06/22/2023 04:51:51 - INFO - __main__ -     eval_loss = 1.253
06/22/2023 04:51:51 - INFO - __main__ -     test_acc=0.5619
06/22/2023 04:51:51 - INFO - __main__ -     ********************
06/22/2023 04:51:51 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:51:52 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 04:51:57 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:51:57 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:51:57 - INFO - __main__ -     Num batches = 171
06/22/2023 04:51:57 - INFO - __main__ -     Batch size = 16
06/22/2023 04:52:06 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:52:06 - INFO - __main__ -     eval_acc = 0.5395
06/22/2023 04:52:06 - INFO - __main__ -     eval_loss = 1.3104
06/22/2023 04:52:06 - INFO - __main__ -     test_acc=0.5395
06/22/2023 04:52:06 - INFO - __main__ -     ********************
06/22/2023 04:52:06 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:52:06 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:52:07 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50
06/22/2023 04:52:07 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:52:07 - INFO - __main__ -     Batch size = 16
06/22/2023 04:52:07 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:52:08 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 04:52:14 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:52:14 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:52:14 - INFO - __main__ -     Num batches = 171
06/22/2023 04:52:14 - INFO - __main__ -     Batch size = 16
06/22/2023 04:52:23 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:52:23 - INFO - __main__ -     eval_acc = 0.3939
06/22/2023 04:52:23 - INFO - __main__ -     eval_loss = 1.5418
06/22/2023 04:52:23 - INFO - __main__ -     test_acc=0.3939
06/22/2023 04:52:23 - INFO - __main__ -     ********************
06/22/2023 04:52:23 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:52:23 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 04:52:29 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:52:29 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:52:29 - INFO - __main__ -     Num batches = 171
06/22/2023 04:52:29 - INFO - __main__ -     Batch size = 16
06/22/2023 04:52:38 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:52:38 - INFO - __main__ -     eval_acc = 0.4096
06/22/2023 04:52:38 - INFO - __main__ -     eval_loss = 1.437
06/22/2023 04:52:38 - INFO - __main__ -     test_acc=0.4096
06/22/2023 04:52:38 - INFO - __main__ -     ********************
06/22/2023 04:52:38 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:52:38 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:52:39 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 04:52:39 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:52:39 - INFO - __main__ -     Batch size = 16
06/22/2023 04:52:39 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:52:39 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 04:52:43 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:52:43 - INFO - __main__ -     Num examples = 1701
06/22/2023 04:52:43 - INFO - __main__ -     Num batches = 107
06/22/2023 04:52:43 - INFO - __main__ -     Batch size = 16
06/22/2023 04:52:49 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:52:49 - INFO - __main__ -     eval_acc = 0.3757
06/22/2023 04:52:49 - INFO - __main__ -     eval_loss = 1.468
06/22/2023 04:52:49 - INFO - __main__ -     test_acc=0.3757
06/22/2023 04:52:49 - INFO - __main__ -     ********************
06/22/2023 04:52:49 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:52:49 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 04:52:52 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:52:52 - INFO - __main__ -     Num examples = 1393
06/22/2023 04:52:52 - INFO - __main__ -     Num batches = 88
06/22/2023 04:52:52 - INFO - __main__ -     Batch size = 16
06/22/2023 04:52:57 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:52:57 - INFO - __main__ -     eval_acc = 0.3833
06/22/2023 04:52:57 - INFO - __main__ -     eval_loss = 1.418
06/22/2023 04:52:57 - INFO - __main__ -     test_acc=0.3833
06/22/2023 04:52:57 - INFO - __main__ -     ********************
06/22/2023 04:52:57 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:52:57 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:52:58 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 04:52:58 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:52:58 - INFO - __main__ -     Batch size = 16
06/22/2023 04:52:58 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:52:59 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 04:53:04 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:53:04 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:53:04 - INFO - __main__ -     Num batches = 171
06/22/2023 04:53:04 - INFO - __main__ -     Batch size = 16
06/22/2023 04:53:13 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:53:13 - INFO - __main__ -     eval_acc = 0.3719
06/22/2023 04:53:13 - INFO - __main__ -     eval_loss = 1.6278
06/22/2023 04:53:13 - INFO - __main__ -     test_acc=0.3719
06/22/2023 04:53:13 - INFO - __main__ -     ********************
06/22/2023 04:53:13 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:53:14 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 04:53:19 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:53:19 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:53:19 - INFO - __main__ -     Num batches = 171
06/22/2023 04:53:19 - INFO - __main__ -     Batch size = 16
06/22/2023 04:53:28 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:53:28 - INFO - __main__ -     eval_acc = 0.3851
06/22/2023 04:53:28 - INFO - __main__ -     eval_loss = 1.5372
06/22/2023 04:53:28 - INFO - __main__ -     test_acc=0.3851
06/22/2023 04:53:28 - INFO - __main__ -     ********************
06/22/2023 04:53:28 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:53:28 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:53:29 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 04:53:30 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:53:30 - INFO - __main__ -     Batch size = 16
06/22/2023 04:53:30 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:53:30 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 04:53:36 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:53:36 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:53:36 - INFO - __main__ -     Num batches = 171
06/22/2023 04:53:36 - INFO - __main__ -     Batch size = 16
06/22/2023 04:53:45 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:53:45 - INFO - __main__ -     eval_acc = 0.5461
06/22/2023 04:53:45 - INFO - __main__ -     eval_loss = 1.0215
06/22/2023 04:53:45 - INFO - __main__ -     test_acc=0.5461
06/22/2023 04:53:45 - INFO - __main__ -     ********************
06/22/2023 04:53:45 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:53:45 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 04:53:50 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:53:50 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:53:50 - INFO - __main__ -     Num batches = 171
06/22/2023 04:53:50 - INFO - __main__ -     Batch size = 16
06/22/2023 04:53:59 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:53:59 - INFO - __main__ -     eval_acc = 0.5227
06/22/2023 04:53:59 - INFO - __main__ -     eval_loss = 1.0324
06/22/2023 04:53:59 - INFO - __main__ -     test_acc=0.5227
06/22/2023 04:53:59 - INFO - __main__ -     ********************
06/22/2023 04:53:59 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:53:59 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:54:01 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50
06/22/2023 04:54:01 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:54:01 - INFO - __main__ -     Batch size = 16
06/22/2023 04:54:01 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:54:01 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 04:54:07 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:54:07 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:54:07 - INFO - __main__ -     Num batches = 171
06/22/2023 04:54:07 - INFO - __main__ -     Batch size = 16
06/22/2023 04:54:16 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:54:16 - INFO - __main__ -     eval_acc = 0.3854
06/22/2023 04:54:16 - INFO - __main__ -     eval_loss = 1.4688
06/22/2023 04:54:16 - INFO - __main__ -     test_acc=0.3854
06/22/2023 04:54:16 - INFO - __main__ -     ********************
06/22/2023 04:54:16 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:54:16 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 04:54:22 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:54:22 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:54:22 - INFO - __main__ -     Num batches = 171
06/22/2023 04:54:22 - INFO - __main__ -     Batch size = 16
06/22/2023 04:54:31 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:54:31 - INFO - __main__ -     eval_acc = 0.4111
06/22/2023 04:54:31 - INFO - __main__ -     eval_loss = 1.3871
06/22/2023 04:54:31 - INFO - __main__ -     test_acc=0.4111
06/22/2023 04:54:31 - INFO - __main__ -     ********************
06/22/2023 04:54:31 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:54:31 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:54:32 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 04:54:32 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:54:32 - INFO - __main__ -     Batch size = 16
06/22/2023 04:54:32 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:54:33 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 04:54:37 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:54:37 - INFO - __main__ -     Num examples = 1701
06/22/2023 04:54:37 - INFO - __main__ -     Num batches = 107
06/22/2023 04:54:37 - INFO - __main__ -     Batch size = 16
06/22/2023 04:54:42 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:54:42 - INFO - __main__ -     eval_acc = 0.3633
06/22/2023 04:54:42 - INFO - __main__ -     eval_loss = 1.4075
06/22/2023 04:54:42 - INFO - __main__ -     test_acc=0.3633
06/22/2023 04:54:42 - INFO - __main__ -     ********************
06/22/2023 04:54:42 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:54:43 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 04:54:46 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:54:46 - INFO - __main__ -     Num examples = 1393
06/22/2023 04:54:46 - INFO - __main__ -     Num batches = 88
06/22/2023 04:54:46 - INFO - __main__ -     Batch size = 16
06/22/2023 04:54:50 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:54:50 - INFO - __main__ -     eval_acc = 0.3941
06/22/2023 04:54:50 - INFO - __main__ -     eval_loss = 1.3849
06/22/2023 04:54:50 - INFO - __main__ -     test_acc=0.3941
06/22/2023 04:54:50 - INFO - __main__ -     ********************
06/22/2023 04:54:50 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:54:50 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:54:51 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 04:54:52 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:54:52 - INFO - __main__ -     Batch size = 16
06/22/2023 04:54:52 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:54:52 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 04:54:58 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:54:58 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:54:58 - INFO - __main__ -     Num batches = 171
06/22/2023 04:54:58 - INFO - __main__ -     Batch size = 16
06/22/2023 04:55:07 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:55:07 - INFO - __main__ -     eval_acc = 0.3646
06/22/2023 04:55:07 - INFO - __main__ -     eval_loss = 1.5255
06/22/2023 04:55:07 - INFO - __main__ -     test_acc=0.3646
06/22/2023 04:55:07 - INFO - __main__ -     ********************
06/22/2023 04:55:07 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:55:07 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 04:55:13 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:55:13 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:55:13 - INFO - __main__ -     Num batches = 171
06/22/2023 04:55:13 - INFO - __main__ -     Batch size = 16
06/22/2023 04:55:21 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:55:21 - INFO - __main__ -     eval_acc = 0.3924
06/22/2023 04:55:21 - INFO - __main__ -     eval_loss = 1.4538
06/22/2023 04:55:21 - INFO - __main__ -     test_acc=0.3924
06/22/2023 04:55:21 - INFO - __main__ -     ********************
06/22/2023 04:55:22 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:55:22 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:55:23 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 04:55:23 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:55:23 - INFO - __main__ -     Batch size = 16
06/22/2023 04:55:23 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:55:23 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 04:55:29 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:55:29 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:55:29 - INFO - __main__ -     Num batches = 171
06/22/2023 04:55:29 - INFO - __main__ -     Batch size = 16
06/22/2023 04:55:38 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:55:38 - INFO - __main__ -     eval_acc = 0.5454
06/22/2023 04:55:38 - INFO - __main__ -     eval_loss = 0.9945
06/22/2023 04:55:38 - INFO - __main__ -     test_acc=0.5454
06/22/2023 04:55:38 - INFO - __main__ -     ********************
06/22/2023 04:55:38 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:55:38 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 04:55:44 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:55:44 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:55:44 - INFO - __main__ -     Num batches = 171
06/22/2023 04:55:44 - INFO - __main__ -     Batch size = 16
06/22/2023 04:55:53 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:55:53 - INFO - __main__ -     eval_acc = 0.5304
06/22/2023 04:55:53 - INFO - __main__ -     eval_loss = 1.0211
06/22/2023 04:55:53 - INFO - __main__ -     test_acc=0.5304
06/22/2023 04:55:53 - INFO - __main__ -     ********************
06/22/2023 04:55:53 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:55:53 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:55:54 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50
06/22/2023 04:55:54 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:55:54 - INFO - __main__ -     Batch size = 16
06/22/2023 04:55:54 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:55:55 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 04:56:00 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:56:00 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:56:00 - INFO - __main__ -     Num batches = 171
06/22/2023 04:56:00 - INFO - __main__ -     Batch size = 16
06/22/2023 04:56:09 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:56:09 - INFO - __main__ -     eval_acc = 0.4327
06/22/2023 04:56:09 - INFO - __main__ -     eval_loss = 0.9561
06/22/2023 04:56:09 - INFO - __main__ -     test_acc=0.4327
06/22/2023 04:56:09 - INFO - __main__ -     ********************
06/22/2023 04:56:09 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:56:10 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 04:56:15 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:56:15 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:56:15 - INFO - __main__ -     Num batches = 171
06/22/2023 04:56:15 - INFO - __main__ -     Batch size = 16
06/22/2023 04:56:24 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:56:24 - INFO - __main__ -     eval_acc = 0.4447
06/22/2023 04:56:24 - INFO - __main__ -     eval_loss = 0.906
06/22/2023 04:56:24 - INFO - __main__ -     test_acc=0.4447
06/22/2023 04:56:24 - INFO - __main__ -     ********************
06/22/2023 04:56:24 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:56:24 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:56:26 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 04:56:26 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:56:26 - INFO - __main__ -     Batch size = 16
06/22/2023 04:56:26 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:56:26 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 04:56:30 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:56:30 - INFO - __main__ -     Num examples = 1701
06/22/2023 04:56:30 - INFO - __main__ -     Num batches = 107
06/22/2023 04:56:30 - INFO - __main__ -     Batch size = 16
06/22/2023 04:56:36 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:56:36 - INFO - __main__ -     eval_acc = 0.4397
06/22/2023 04:56:36 - INFO - __main__ -     eval_loss = 0.949
06/22/2023 04:56:36 - INFO - __main__ -     test_acc=0.4397
06/22/2023 04:56:36 - INFO - __main__ -     ********************
06/22/2023 04:56:36 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:56:36 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 04:56:39 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:56:39 - INFO - __main__ -     Num examples = 1393
06/22/2023 04:56:39 - INFO - __main__ -     Num batches = 88
06/22/2023 04:56:39 - INFO - __main__ -     Batch size = 16
06/22/2023 04:56:44 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:56:44 - INFO - __main__ -     eval_acc = 0.4314
06/22/2023 04:56:44 - INFO - __main__ -     eval_loss = 0.8885
06/22/2023 04:56:44 - INFO - __main__ -     test_acc=0.4314
06/22/2023 04:56:44 - INFO - __main__ -     ********************
06/22/2023 04:56:44 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:56:44 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:56:45 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 04:56:45 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:56:45 - INFO - __main__ -     Batch size = 16
06/22/2023 04:56:45 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:56:45 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 04:56:51 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:56:51 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:56:51 - INFO - __main__ -     Num batches = 171
06/22/2023 04:56:51 - INFO - __main__ -     Batch size = 16
06/22/2023 04:57:00 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:57:00 - INFO - __main__ -     eval_acc = 0.4367
06/22/2023 04:57:00 - INFO - __main__ -     eval_loss = 0.9475
06/22/2023 04:57:00 - INFO - __main__ -     test_acc=0.4367
06/22/2023 04:57:00 - INFO - __main__ -     ********************
06/22/2023 04:57:00 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:57:00 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 04:57:06 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:57:06 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:57:06 - INFO - __main__ -     Num batches = 171
06/22/2023 04:57:06 - INFO - __main__ -     Batch size = 16
06/22/2023 04:57:15 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:57:15 - INFO - __main__ -     eval_acc = 0.4499
06/22/2023 04:57:15 - INFO - __main__ -     eval_loss = 0.9145
06/22/2023 04:57:15 - INFO - __main__ -     test_acc=0.4499
06/22/2023 04:57:15 - INFO - __main__ -     ********************
06/22/2023 04:57:15 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:57:15 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:57:16 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 04:57:16 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:57:16 - INFO - __main__ -     Batch size = 16
06/22/2023 04:57:16 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:57:17 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 04:57:22 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:57:22 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:57:22 - INFO - __main__ -     Num batches = 171
06/22/2023 04:57:22 - INFO - __main__ -     Batch size = 16
06/22/2023 04:57:31 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:57:31 - INFO - __main__ -     eval_acc = 0.5575
06/22/2023 04:57:31 - INFO - __main__ -     eval_loss = 0.7284
06/22/2023 04:57:31 - INFO - __main__ -     test_acc=0.5575
06/22/2023 04:57:31 - INFO - __main__ -     ********************
06/22/2023 04:57:31 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:57:32 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 04:57:37 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:57:37 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:57:37 - INFO - __main__ -     Num batches = 171
06/22/2023 04:57:37 - INFO - __main__ -     Batch size = 16
06/22/2023 04:57:46 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:57:46 - INFO - __main__ -     eval_acc = 0.5132
06/22/2023 04:57:46 - INFO - __main__ -     eval_loss = 0.7505
06/22/2023 04:57:46 - INFO - __main__ -     test_acc=0.5132
06/22/2023 04:57:46 - INFO - __main__ -     ********************
06/22/2023 04:57:46 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:57:46 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:57:47 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50
06/22/2023 04:57:47 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:57:47 - INFO - __main__ -     Batch size = 16
06/22/2023 04:57:47 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:57:48 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 04:57:54 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:57:54 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:57:54 - INFO - __main__ -     Num batches = 171
06/22/2023 04:57:54 - INFO - __main__ -     Batch size = 16
06/22/2023 04:58:03 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:58:03 - INFO - __main__ -     eval_acc = 0.3836
06/22/2023 04:58:03 - INFO - __main__ -     eval_loss = 1.8392
06/22/2023 04:58:03 - INFO - __main__ -     test_acc=0.3836
06/22/2023 04:58:03 - INFO - __main__ -     ********************
06/22/2023 04:58:03 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:58:03 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 04:58:08 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:58:08 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:58:08 - INFO - __main__ -     Num batches = 171
06/22/2023 04:58:08 - INFO - __main__ -     Batch size = 16
06/22/2023 04:58:17 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:58:17 - INFO - __main__ -     eval_acc = 0.4015
06/22/2023 04:58:17 - INFO - __main__ -     eval_loss = 1.7151
06/22/2023 04:58:17 - INFO - __main__ -     test_acc=0.4015
06/22/2023 04:58:17 - INFO - __main__ -     ********************
06/22/2023 04:58:17 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:58:17 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:58:19 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 04:58:19 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:58:19 - INFO - __main__ -     Batch size = 16
06/22/2023 04:58:19 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:58:19 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 04:58:23 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:58:23 - INFO - __main__ -     Num examples = 1701
06/22/2023 04:58:23 - INFO - __main__ -     Num batches = 107
06/22/2023 04:58:23 - INFO - __main__ -     Batch size = 16
06/22/2023 04:58:29 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:58:29 - INFO - __main__ -     eval_acc = 0.3745
06/22/2023 04:58:29 - INFO - __main__ -     eval_loss = 1.8005
06/22/2023 04:58:29 - INFO - __main__ -     test_acc=0.3745
06/22/2023 04:58:29 - INFO - __main__ -     ********************
06/22/2023 04:58:29 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:58:29 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 04:58:32 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:58:32 - INFO - __main__ -     Num examples = 1393
06/22/2023 04:58:32 - INFO - __main__ -     Num batches = 88
06/22/2023 04:58:32 - INFO - __main__ -     Batch size = 16
06/22/2023 04:58:37 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:58:37 - INFO - __main__ -     eval_acc = 0.3941
06/22/2023 04:58:37 - INFO - __main__ -     eval_loss = 1.7118
06/22/2023 04:58:37 - INFO - __main__ -     test_acc=0.3941
06/22/2023 04:58:37 - INFO - __main__ -     ********************
06/22/2023 04:58:37 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:58:37 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:58:38 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 04:58:38 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:58:38 - INFO - __main__ -     Batch size = 16
06/22/2023 04:58:38 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:58:39 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 04:58:44 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:58:44 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:58:44 - INFO - __main__ -     Num batches = 171
06/22/2023 04:58:44 - INFO - __main__ -     Batch size = 16
06/22/2023 04:58:53 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:58:53 - INFO - __main__ -     eval_acc = 0.3668
06/22/2023 04:58:53 - INFO - __main__ -     eval_loss = 1.8871
06/22/2023 04:58:53 - INFO - __main__ -     test_acc=0.3668
06/22/2023 04:58:53 - INFO - __main__ -     ********************
06/22/2023 04:58:53 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:58:54 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 04:58:59 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:58:59 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:58:59 - INFO - __main__ -     Num batches = 171
06/22/2023 04:58:59 - INFO - __main__ -     Batch size = 16
06/22/2023 04:59:08 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:59:08 - INFO - __main__ -     eval_acc = 0.3887
06/22/2023 04:59:08 - INFO - __main__ -     eval_loss = 1.7607
06/22/2023 04:59:08 - INFO - __main__ -     test_acc=0.3887
06/22/2023 04:59:08 - INFO - __main__ -     ********************
06/22/2023 04:59:08 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:59:08 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:59:09 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 04:59:10 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:59:10 - INFO - __main__ -     Batch size = 16
06/22/2023 04:59:10 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:59:10 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 04:59:16 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:59:16 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:59:16 - INFO - __main__ -     Num batches = 171
06/22/2023 04:59:16 - INFO - __main__ -     Batch size = 16
06/22/2023 04:59:25 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:59:25 - INFO - __main__ -     eval_acc = 0.5472
06/22/2023 04:59:25 - INFO - __main__ -     eval_loss = 1.2047
06/22/2023 04:59:25 - INFO - __main__ -     test_acc=0.5472
06/22/2023 04:59:25 - INFO - __main__ -     ********************
06/22/2023 04:59:25 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:59:25 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 04:59:30 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:59:30 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:59:30 - INFO - __main__ -     Num batches = 171
06/22/2023 04:59:30 - INFO - __main__ -     Batch size = 16
06/22/2023 04:59:39 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:59:39 - INFO - __main__ -     eval_acc = 0.5293
06/22/2023 04:59:39 - INFO - __main__ -     eval_loss = 1.2146
06/22/2023 04:59:39 - INFO - __main__ -     test_acc=0.5293
06/22/2023 04:59:39 - INFO - __main__ -     ********************
06/22/2023 04:59:39 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 04:59:39 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 04:59:41 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50
06/22/2023 04:59:41 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 04:59:41 - INFO - __main__ -     Batch size = 16
06/22/2023 04:59:41 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:59:41 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 04:59:47 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 04:59:47 - INFO - __main__ -     Num examples = 2732
06/22/2023 04:59:47 - INFO - __main__ -     Num batches = 171
06/22/2023 04:59:47 - INFO - __main__ -     Batch size = 16
06/22/2023 04:59:56 - INFO - __main__ -   ***** Eval results *****
06/22/2023 04:59:56 - INFO - __main__ -     eval_acc = 0.388
06/22/2023 04:59:56 - INFO - __main__ -     eval_loss = 1.8395
06/22/2023 04:59:56 - INFO - __main__ -     test_acc=0.3880
06/22/2023 04:59:56 - INFO - __main__ -     ********************
06/22/2023 04:59:56 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 04:59:56 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:00:02 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:00:02 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:00:02 - INFO - __main__ -     Num batches = 171
06/22/2023 05:00:02 - INFO - __main__ -     Batch size = 16
06/22/2023 05:00:11 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:00:11 - INFO - __main__ -     eval_acc = 0.4096
06/22/2023 05:00:11 - INFO - __main__ -     eval_loss = 1.7188
06/22/2023 05:00:11 - INFO - __main__ -     test_acc=0.4096
06/22/2023 05:00:11 - INFO - __main__ -     ********************
06/22/2023 05:00:11 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:00:11 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:00:12 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:00:12 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:00:12 - INFO - __main__ -     Batch size = 16
06/22/2023 05:00:12 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:00:13 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:00:17 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:00:17 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:00:17 - INFO - __main__ -     Num batches = 107
06/22/2023 05:00:17 - INFO - __main__ -     Batch size = 16
06/22/2023 05:00:22 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:00:22 - INFO - __main__ -     eval_acc = 0.378
06/22/2023 05:00:22 - INFO - __main__ -     eval_loss = 1.8409
06/22/2023 05:00:22 - INFO - __main__ -     test_acc=0.3780
06/22/2023 05:00:22 - INFO - __main__ -     ********************
06/22/2023 05:00:22 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:00:22 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:00:26 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:00:26 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:00:26 - INFO - __main__ -     Num batches = 88
06/22/2023 05:00:26 - INFO - __main__ -     Batch size = 16
06/22/2023 05:00:30 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:00:30 - INFO - __main__ -     eval_acc = 0.3769
06/22/2023 05:00:30 - INFO - __main__ -     eval_loss = 1.8361
06/22/2023 05:00:30 - INFO - __main__ -     test_acc=0.3769
06/22/2023 05:00:30 - INFO - __main__ -     ********************
06/22/2023 05:00:30 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:00:30 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:00:32 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:00:32 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:00:32 - INFO - __main__ -     Batch size = 16
06/22/2023 05:00:32 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:00:32 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:00:38 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:00:38 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:00:38 - INFO - __main__ -     Num batches = 171
06/22/2023 05:00:38 - INFO - __main__ -     Batch size = 16
06/22/2023 05:00:47 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:00:47 - INFO - __main__ -     eval_acc = 0.3587
06/22/2023 05:00:47 - INFO - __main__ -     eval_loss = 1.9751
06/22/2023 05:00:47 - INFO - __main__ -     test_acc=0.3587
06/22/2023 05:00:47 - INFO - __main__ -     ********************
06/22/2023 05:00:47 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:00:47 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:00:53 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:00:53 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:00:53 - INFO - __main__ -     Num batches = 171
06/22/2023 05:00:53 - INFO - __main__ -     Batch size = 16
06/22/2023 05:01:01 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:01:01 - INFO - __main__ -     eval_acc = 0.3862
06/22/2023 05:01:01 - INFO - __main__ -     eval_loss = 1.8501
06/22/2023 05:01:01 - INFO - __main__ -     test_acc=0.3862
06/22/2023 05:01:01 - INFO - __main__ -     ********************
06/22/2023 05:01:02 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:01:02 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:01:03 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:01:03 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:01:03 - INFO - __main__ -     Batch size = 16
06/22/2023 05:01:03 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:01:03 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:01:09 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:01:09 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:01:09 - INFO - __main__ -     Num batches = 171
06/22/2023 05:01:09 - INFO - __main__ -     Batch size = 16
06/22/2023 05:01:18 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:01:18 - INFO - __main__ -     eval_acc = 0.5487
06/22/2023 05:01:18 - INFO - __main__ -     eval_loss = 1.2896
06/22/2023 05:01:18 - INFO - __main__ -     test_acc=0.5487
06/22/2023 05:01:18 - INFO - __main__ -     ********************
06/22/2023 05:01:18 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:01:19 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:01:24 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:01:24 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:01:24 - INFO - __main__ -     Num batches = 171
06/22/2023 05:01:24 - INFO - __main__ -     Batch size = 16
06/22/2023 05:01:33 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:01:33 - INFO - __main__ -     eval_acc = 0.5432
06/22/2023 05:01:33 - INFO - __main__ -     eval_loss = 1.2875
06/22/2023 05:01:33 - INFO - __main__ -     test_acc=0.5432
06/22/2023 05:01:33 - INFO - __main__ -     ********************
06/22/2023 05:01:33 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:01:33 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:01:34 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50
06/22/2023 05:01:34 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:01:34 - INFO - __main__ -     Batch size = 16
06/22/2023 05:01:34 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:01:35 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:01:40 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:01:40 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:01:40 - INFO - __main__ -     Num batches = 171
06/22/2023 05:01:40 - INFO - __main__ -     Batch size = 16
06/22/2023 05:01:49 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:01:49 - INFO - __main__ -     eval_acc = 0.3982
06/22/2023 05:01:49 - INFO - __main__ -     eval_loss = 1.9786
06/22/2023 05:01:49 - INFO - __main__ -     test_acc=0.3982
06/22/2023 05:01:49 - INFO - __main__ -     ********************
06/22/2023 05:01:49 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:01:50 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:01:55 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:01:55 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:01:55 - INFO - __main__ -     Num batches = 171
06/22/2023 05:01:55 - INFO - __main__ -     Batch size = 16
06/22/2023 05:02:04 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:02:04 - INFO - __main__ -     eval_acc = 0.4184
06/22/2023 05:02:04 - INFO - __main__ -     eval_loss = 1.871
06/22/2023 05:02:04 - INFO - __main__ -     test_acc=0.4184
06/22/2023 05:02:04 - INFO - __main__ -     ********************
06/22/2023 05:02:04 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:02:04 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:02:06 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:02:06 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:02:06 - INFO - __main__ -     Batch size = 16
06/22/2023 05:02:06 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:02:06 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:02:10 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:02:10 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:02:10 - INFO - __main__ -     Num batches = 107
06/22/2023 05:02:10 - INFO - __main__ -     Batch size = 16
06/22/2023 05:02:15 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:02:15 - INFO - __main__ -     eval_acc = 0.3815
06/22/2023 05:02:15 - INFO - __main__ -     eval_loss = 1.943
06/22/2023 05:02:15 - INFO - __main__ -     test_acc=0.3815
06/22/2023 05:02:15 - INFO - __main__ -     ********************
06/22/2023 05:02:15 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:02:16 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:02:19 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:02:19 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:02:19 - INFO - __main__ -     Num batches = 88
06/22/2023 05:02:19 - INFO - __main__ -     Batch size = 16
06/22/2023 05:02:24 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:02:24 - INFO - __main__ -     eval_acc = 0.3948
06/22/2023 05:02:24 - INFO - __main__ -     eval_loss = 1.9237
06/22/2023 05:02:24 - INFO - __main__ -     test_acc=0.3948
06/22/2023 05:02:24 - INFO - __main__ -     ********************
06/22/2023 05:02:24 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:02:24 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:02:25 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:02:25 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:02:25 - INFO - __main__ -     Batch size = 16
06/22/2023 05:02:25 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:02:26 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:02:31 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:02:31 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:02:31 - INFO - __main__ -     Num batches = 171
06/22/2023 05:02:31 - INFO - __main__ -     Batch size = 16
06/22/2023 05:02:40 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:02:40 - INFO - __main__ -     eval_acc = 0.3774
06/22/2023 05:02:40 - INFO - __main__ -     eval_loss = 2.0497
06/22/2023 05:02:40 - INFO - __main__ -     test_acc=0.3774
06/22/2023 05:02:40 - INFO - __main__ -     ********************
06/22/2023 05:02:40 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:02:41 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:02:46 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:02:46 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:02:46 - INFO - __main__ -     Num batches = 171
06/22/2023 05:02:46 - INFO - __main__ -     Batch size = 16
06/22/2023 05:02:55 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:02:55 - INFO - __main__ -     eval_acc = 0.3942
06/22/2023 05:02:55 - INFO - __main__ -     eval_loss = 1.9468
06/22/2023 05:02:55 - INFO - __main__ -     test_acc=0.3942
06/22/2023 05:02:55 - INFO - __main__ -     ********************
06/22/2023 05:02:55 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:02:55 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:02:56 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:02:57 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:02:57 - INFO - __main__ -     Batch size = 16
06/22/2023 05:02:57 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:02:57 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:03:03 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:03:03 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:03:03 - INFO - __main__ -     Num batches = 171
06/22/2023 05:03:03 - INFO - __main__ -     Batch size = 16
06/22/2023 05:03:11 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:03:11 - INFO - __main__ -     eval_acc = 0.5608
06/22/2023 05:03:11 - INFO - __main__ -     eval_loss = 1.2947
06/22/2023 05:03:11 - INFO - __main__ -     test_acc=0.5608
06/22/2023 05:03:11 - INFO - __main__ -     ********************
06/22/2023 05:03:11 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:03:12 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:03:17 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:03:17 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:03:17 - INFO - __main__ -     Num batches = 171
06/22/2023 05:03:17 - INFO - __main__ -     Batch size = 16
06/22/2023 05:03:26 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:03:26 - INFO - __main__ -     eval_acc = 0.548
06/22/2023 05:03:26 - INFO - __main__ -     eval_loss = 1.3422
06/22/2023 05:03:26 - INFO - __main__ -     test_acc=0.5480
06/22/2023 05:03:26 - INFO - __main__ -     ********************
06/22/2023 05:03:27 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:03:27 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:03:28 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50
06/22/2023 05:03:28 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:03:28 - INFO - __main__ -     Batch size = 16
06/22/2023 05:03:28 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:03:28 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:03:34 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:03:34 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:03:34 - INFO - __main__ -     Num batches = 171
06/22/2023 05:03:34 - INFO - __main__ -     Batch size = 16
06/22/2023 05:03:43 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:03:43 - INFO - __main__ -     eval_acc = 0.3913
06/22/2023 05:03:43 - INFO - __main__ -     eval_loss = 1.7232
06/22/2023 05:03:43 - INFO - __main__ -     test_acc=0.3913
06/22/2023 05:03:43 - INFO - __main__ -     ********************
06/22/2023 05:03:43 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:03:43 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:03:49 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:03:49 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:03:49 - INFO - __main__ -     Num batches = 171
06/22/2023 05:03:49 - INFO - __main__ -     Batch size = 16
06/22/2023 05:03:58 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:03:58 - INFO - __main__ -     eval_acc = 0.4026
06/22/2023 05:03:58 - INFO - __main__ -     eval_loss = 1.6463
06/22/2023 05:03:58 - INFO - __main__ -     test_acc=0.4026
06/22/2023 05:03:58 - INFO - __main__ -     ********************
06/22/2023 05:03:58 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:03:58 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:03:59 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:03:59 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:03:59 - INFO - __main__ -     Batch size = 16
06/22/2023 05:03:59 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:03:59 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:04:03 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:04:03 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:04:03 - INFO - __main__ -     Num batches = 107
06/22/2023 05:04:03 - INFO - __main__ -     Batch size = 16
06/22/2023 05:04:09 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:04:09 - INFO - __main__ -     eval_acc = 0.3745
06/22/2023 05:04:09 - INFO - __main__ -     eval_loss = 1.6876
06/22/2023 05:04:09 - INFO - __main__ -     test_acc=0.3745
06/22/2023 05:04:09 - INFO - __main__ -     ********************
06/22/2023 05:04:09 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:04:09 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:04:12 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:04:12 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:04:12 - INFO - __main__ -     Num batches = 88
06/22/2023 05:04:12 - INFO - __main__ -     Batch size = 16
06/22/2023 05:04:17 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:04:17 - INFO - __main__ -     eval_acc = 0.3747
06/22/2023 05:04:17 - INFO - __main__ -     eval_loss = 1.6901
06/22/2023 05:04:17 - INFO - __main__ -     test_acc=0.3747
06/22/2023 05:04:17 - INFO - __main__ -     ********************
06/22/2023 05:04:17 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:04:17 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:04:18 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:04:18 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:04:18 - INFO - __main__ -     Batch size = 16
06/22/2023 05:04:18 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:04:19 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:04:25 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:04:25 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:04:25 - INFO - __main__ -     Num batches = 171
06/22/2023 05:04:25 - INFO - __main__ -     Batch size = 16
06/22/2023 05:04:33 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:04:33 - INFO - __main__ -     eval_acc = 0.3682
06/22/2023 05:04:33 - INFO - __main__ -     eval_loss = 1.815
06/22/2023 05:04:33 - INFO - __main__ -     test_acc=0.3682
06/22/2023 05:04:33 - INFO - __main__ -     ********************
06/22/2023 05:04:33 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:04:34 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:04:39 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:04:39 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:04:39 - INFO - __main__ -     Num batches = 171
06/22/2023 05:04:39 - INFO - __main__ -     Batch size = 16
06/22/2023 05:04:48 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:04:48 - INFO - __main__ -     eval_acc = 0.373
06/22/2023 05:04:48 - INFO - __main__ -     eval_loss = 1.7409
06/22/2023 05:04:48 - INFO - __main__ -     test_acc=0.3730
06/22/2023 05:04:48 - INFO - __main__ -     ********************
06/22/2023 05:04:48 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:04:48 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:04:50 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:04:50 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:04:50 - INFO - __main__ -     Batch size = 16
06/22/2023 05:04:50 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:04:50 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:04:56 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:04:56 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:04:56 - INFO - __main__ -     Num batches = 171
06/22/2023 05:04:56 - INFO - __main__ -     Batch size = 16
06/22/2023 05:05:05 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:05:05 - INFO - __main__ -     eval_acc = 0.5556
06/22/2023 05:05:05 - INFO - __main__ -     eval_loss = 1.1359
06/22/2023 05:05:05 - INFO - __main__ -     test_acc=0.5556
06/22/2023 05:05:05 - INFO - __main__ -     ********************
06/22/2023 05:05:05 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:05:05 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:05:11 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:05:11 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:05:11 - INFO - __main__ -     Num batches = 171
06/22/2023 05:05:11 - INFO - __main__ -     Batch size = 16
06/22/2023 05:05:20 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:05:20 - INFO - __main__ -     eval_acc = 0.5399
06/22/2023 05:05:20 - INFO - __main__ -     eval_loss = 1.1494
06/22/2023 05:05:20 - INFO - __main__ -     test_acc=0.5399
06/22/2023 05:05:20 - INFO - __main__ -     ********************
06/22/2023 05:05:20 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:05:20 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:05:21 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50
06/22/2023 05:05:21 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:05:21 - INFO - __main__ -     Batch size = 16
06/22/2023 05:05:21 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:05:22 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:05:27 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:05:27 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:05:27 - INFO - __main__ -     Num batches = 171
06/22/2023 05:05:27 - INFO - __main__ -     Batch size = 16
06/22/2023 05:05:36 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:05:36 - INFO - __main__ -     eval_acc = 0.3986
06/22/2023 05:05:36 - INFO - __main__ -     eval_loss = 1.6641
06/22/2023 05:05:36 - INFO - __main__ -     test_acc=0.3986
06/22/2023 05:05:36 - INFO - __main__ -     ********************
06/22/2023 05:05:36 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:05:37 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:05:42 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:05:42 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:05:42 - INFO - __main__ -     Num batches = 171
06/22/2023 05:05:42 - INFO - __main__ -     Batch size = 16
06/22/2023 05:05:51 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:05:51 - INFO - __main__ -     eval_acc = 0.4074
06/22/2023 05:05:51 - INFO - __main__ -     eval_loss = 1.5872
06/22/2023 05:05:51 - INFO - __main__ -     test_acc=0.4074
06/22/2023 05:05:51 - INFO - __main__ -     ********************
06/22/2023 05:05:51 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:05:51 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:05:52 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:05:52 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:05:52 - INFO - __main__ -     Batch size = 16
06/22/2023 05:05:52 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:05:53 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:05:57 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:05:57 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:05:57 - INFO - __main__ -     Num batches = 107
06/22/2023 05:05:57 - INFO - __main__ -     Batch size = 16
06/22/2023 05:06:03 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:06:03 - INFO - __main__ -     eval_acc = 0.3921
06/22/2023 05:06:03 - INFO - __main__ -     eval_loss = 1.5664
06/22/2023 05:06:03 - INFO - __main__ -     test_acc=0.3921
06/22/2023 05:06:03 - INFO - __main__ -     ********************
06/22/2023 05:06:03 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:06:03 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:06:06 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:06:06 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:06:06 - INFO - __main__ -     Num batches = 88
06/22/2023 05:06:06 - INFO - __main__ -     Batch size = 16
06/22/2023 05:06:11 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:06:11 - INFO - __main__ -     eval_acc = 0.4121
06/22/2023 05:06:11 - INFO - __main__ -     eval_loss = 1.599
06/22/2023 05:06:11 - INFO - __main__ -     test_acc=0.4121
06/22/2023 05:06:11 - INFO - __main__ -     ********************
06/22/2023 05:06:11 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:06:11 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:06:12 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:06:12 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:06:12 - INFO - __main__ -     Batch size = 16
06/22/2023 05:06:12 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:06:12 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:06:18 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:06:18 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:06:18 - INFO - __main__ -     Num batches = 171
06/22/2023 05:06:18 - INFO - __main__ -     Batch size = 16
06/22/2023 05:06:27 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:06:27 - INFO - __main__ -     eval_acc = 0.3799
06/22/2023 05:06:27 - INFO - __main__ -     eval_loss = 1.7467
06/22/2023 05:06:27 - INFO - __main__ -     test_acc=0.3799
06/22/2023 05:06:27 - INFO - __main__ -     ********************
06/22/2023 05:06:27 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:06:27 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:06:33 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:06:33 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:06:33 - INFO - __main__ -     Num batches = 171
06/22/2023 05:06:33 - INFO - __main__ -     Batch size = 16
06/22/2023 05:06:42 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:06:42 - INFO - __main__ -     eval_acc = 0.3825
06/22/2023 05:06:42 - INFO - __main__ -     eval_loss = 1.6776
06/22/2023 05:06:42 - INFO - __main__ -     test_acc=0.3825
06/22/2023 05:06:42 - INFO - __main__ -     ********************
06/22/2023 05:06:42 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:06:42 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:06:43 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:06:43 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:06:43 - INFO - __main__ -     Batch size = 16
06/22/2023 05:06:43 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:06:44 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:06:49 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:06:49 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:06:49 - INFO - __main__ -     Num batches = 171
06/22/2023 05:06:49 - INFO - __main__ -     Batch size = 16
06/22/2023 05:06:58 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:06:58 - INFO - __main__ -     eval_acc = 0.5575
06/22/2023 05:06:58 - INFO - __main__ -     eval_loss = 1.0546
06/22/2023 05:06:58 - INFO - __main__ -     test_acc=0.5575
06/22/2023 05:06:58 - INFO - __main__ -     ********************
06/22/2023 05:06:58 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:06:59 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:07:04 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:07:04 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:07:04 - INFO - __main__ -     Num batches = 171
06/22/2023 05:07:04 - INFO - __main__ -     Batch size = 16
06/22/2023 05:07:13 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:07:13 - INFO - __main__ -     eval_acc = 0.5388
06/22/2023 05:07:13 - INFO - __main__ -     eval_loss = 1.1208
06/22/2023 05:07:13 - INFO - __main__ -     test_acc=0.5388
06/22/2023 05:07:13 - INFO - __main__ -     ********************
06/22/2023 05:07:13 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:07:13 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:07:15 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50
06/22/2023 05:07:15 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:07:15 - INFO - __main__ -     Batch size = 16
06/22/2023 05:07:15 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:07:15 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:07:21 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:07:21 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:07:21 - INFO - __main__ -     Num batches = 171
06/22/2023 05:07:21 - INFO - __main__ -     Batch size = 16
06/22/2023 05:07:30 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:07:30 - INFO - __main__ -     eval_acc = 0.3946
06/22/2023 05:07:30 - INFO - __main__ -     eval_loss = 1.7233
06/22/2023 05:07:30 - INFO - __main__ -     test_acc=0.3946
06/22/2023 05:07:30 - INFO - __main__ -     ********************
06/22/2023 05:07:30 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:07:30 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:07:36 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:07:36 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:07:36 - INFO - __main__ -     Num batches = 171
06/22/2023 05:07:36 - INFO - __main__ -     Batch size = 16
06/22/2023 05:07:45 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:07:45 - INFO - __main__ -     eval_acc = 0.4202
06/22/2023 05:07:45 - INFO - __main__ -     eval_loss = 1.6522
06/22/2023 05:07:45 - INFO - __main__ -     test_acc=0.4202
06/22/2023 05:07:45 - INFO - __main__ -     ********************
06/22/2023 05:07:45 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:07:45 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:07:46 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:07:46 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:07:46 - INFO - __main__ -     Batch size = 16
06/22/2023 05:07:46 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:07:47 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:07:51 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:07:51 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:07:51 - INFO - __main__ -     Num batches = 107
06/22/2023 05:07:51 - INFO - __main__ -     Batch size = 16
06/22/2023 05:07:56 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:07:56 - INFO - __main__ -     eval_acc = 0.3956
06/22/2023 05:07:56 - INFO - __main__ -     eval_loss = 1.632
06/22/2023 05:07:56 - INFO - __main__ -     test_acc=0.3956
06/22/2023 05:07:56 - INFO - __main__ -     ********************
06/22/2023 05:07:56 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:07:57 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:08:00 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:08:00 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:08:00 - INFO - __main__ -     Num batches = 88
06/22/2023 05:08:00 - INFO - __main__ -     Batch size = 16
06/22/2023 05:08:04 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:08:04 - INFO - __main__ -     eval_acc = 0.407
06/22/2023 05:08:04 - INFO - __main__ -     eval_loss = 1.609
06/22/2023 05:08:04 - INFO - __main__ -     test_acc=0.4070
06/22/2023 05:08:04 - INFO - __main__ -     ********************
06/22/2023 05:08:04 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:08:04 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:08:05 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:08:06 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:08:06 - INFO - __main__ -     Batch size = 16
06/22/2023 05:08:06 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:08:06 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:08:12 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:08:12 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:08:12 - INFO - __main__ -     Num batches = 171
06/22/2023 05:08:12 - INFO - __main__ -     Batch size = 16
06/22/2023 05:08:21 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:08:21 - INFO - __main__ -     eval_acc = 0.3788
06/22/2023 05:08:21 - INFO - __main__ -     eval_loss = 1.8171
06/22/2023 05:08:21 - INFO - __main__ -     test_acc=0.3788
06/22/2023 05:08:21 - INFO - __main__ -     ********************
06/22/2023 05:08:21 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:08:21 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:08:27 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:08:27 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:08:27 - INFO - __main__ -     Num batches = 171
06/22/2023 05:08:27 - INFO - __main__ -     Batch size = 16
06/22/2023 05:08:36 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:08:36 - INFO - __main__ -     eval_acc = 0.3935
06/22/2023 05:08:36 - INFO - __main__ -     eval_loss = 1.7278
06/22/2023 05:08:36 - INFO - __main__ -     test_acc=0.3935
06/22/2023 05:08:36 - INFO - __main__ -     ********************
06/22/2023 05:08:36 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:08:36 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:08:37 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:08:37 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:08:37 - INFO - __main__ -     Batch size = 16
06/22/2023 05:08:37 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:08:38 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:08:43 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:08:43 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:08:43 - INFO - __main__ -     Num batches = 171
06/22/2023 05:08:43 - INFO - __main__ -     Batch size = 16
06/22/2023 05:08:52 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:08:52 - INFO - __main__ -     eval_acc = 0.5633
06/22/2023 05:08:52 - INFO - __main__ -     eval_loss = 1.0937
06/22/2023 05:08:52 - INFO - __main__ -     test_acc=0.5633
06/22/2023 05:08:52 - INFO - __main__ -     ********************
06/22/2023 05:08:52 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:08:53 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:08:58 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:08:58 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:08:58 - INFO - __main__ -     Num batches = 171
06/22/2023 05:08:58 - INFO - __main__ -     Batch size = 16
06/22/2023 05:09:07 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:09:07 - INFO - __main__ -     eval_acc = 0.5373
06/22/2023 05:09:07 - INFO - __main__ -     eval_loss = 1.1511
06/22/2023 05:09:07 - INFO - __main__ -     test_acc=0.5373
06/22/2023 05:09:07 - INFO - __main__ -     ********************
06/22/2023 05:09:07 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:09:07 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:09:08 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50
06/22/2023 05:09:08 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:09:08 - INFO - __main__ -     Batch size = 16
06/22/2023 05:09:08 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:09:09 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:09:15 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:09:15 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:09:15 - INFO - __main__ -     Num batches = 171
06/22/2023 05:09:15 - INFO - __main__ -     Batch size = 16
06/22/2023 05:09:24 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:09:24 - INFO - __main__ -     eval_acc = 0.3957
06/22/2023 05:09:24 - INFO - __main__ -     eval_loss = 1.7691
06/22/2023 05:09:24 - INFO - __main__ -     test_acc=0.3957
06/22/2023 05:09:24 - INFO - __main__ -     ********************
06/22/2023 05:09:24 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:09:24 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:09:30 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:09:30 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:09:30 - INFO - __main__ -     Num batches = 171
06/22/2023 05:09:30 - INFO - __main__ -     Batch size = 16
06/22/2023 05:09:39 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:09:39 - INFO - __main__ -     eval_acc = 0.4103
06/22/2023 05:09:39 - INFO - __main__ -     eval_loss = 1.6875
06/22/2023 05:09:39 - INFO - __main__ -     test_acc=0.4103
06/22/2023 05:09:39 - INFO - __main__ -     ********************
06/22/2023 05:09:39 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:09:39 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:09:40 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:09:40 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:09:40 - INFO - __main__ -     Batch size = 16
06/22/2023 05:09:40 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:09:41 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:09:45 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:09:45 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:09:45 - INFO - __main__ -     Num batches = 107
06/22/2023 05:09:45 - INFO - __main__ -     Batch size = 16
06/22/2023 05:09:50 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:09:50 - INFO - __main__ -     eval_acc = 0.3686
06/22/2023 05:09:50 - INFO - __main__ -     eval_loss = 1.6965
06/22/2023 05:09:50 - INFO - __main__ -     test_acc=0.3686
06/22/2023 05:09:50 - INFO - __main__ -     ********************
06/22/2023 05:09:50 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:09:51 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:09:54 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:09:54 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:09:54 - INFO - __main__ -     Num batches = 88
06/22/2023 05:09:54 - INFO - __main__ -     Batch size = 16
06/22/2023 05:09:58 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:09:58 - INFO - __main__ -     eval_acc = 0.3826
06/22/2023 05:09:58 - INFO - __main__ -     eval_loss = 1.6348
06/22/2023 05:09:58 - INFO - __main__ -     test_acc=0.3826
06/22/2023 05:09:58 - INFO - __main__ -     ********************
06/22/2023 05:09:58 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:09:58 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:10:00 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:10:00 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:10:00 - INFO - __main__ -     Batch size = 16
06/22/2023 05:10:00 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:10:00 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:10:06 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:10:06 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:10:06 - INFO - __main__ -     Num batches = 171
06/22/2023 05:10:06 - INFO - __main__ -     Batch size = 16
06/22/2023 05:10:15 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:10:15 - INFO - __main__ -     eval_acc = 0.3693
06/22/2023 05:10:15 - INFO - __main__ -     eval_loss = 1.8677
06/22/2023 05:10:15 - INFO - __main__ -     test_acc=0.3693
06/22/2023 05:10:15 - INFO - __main__ -     ********************
06/22/2023 05:10:15 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:10:15 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:10:21 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:10:21 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:10:21 - INFO - __main__ -     Num batches = 171
06/22/2023 05:10:21 - INFO - __main__ -     Batch size = 16
06/22/2023 05:10:30 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:10:30 - INFO - __main__ -     eval_acc = 0.3843
06/22/2023 05:10:30 - INFO - __main__ -     eval_loss = 1.7953
06/22/2023 05:10:30 - INFO - __main__ -     test_acc=0.3843
06/22/2023 05:10:30 - INFO - __main__ -     ********************
06/22/2023 05:10:30 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:10:30 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:10:31 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:10:31 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:10:31 - INFO - __main__ -     Batch size = 16
06/22/2023 05:10:31 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:10:32 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:10:37 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:10:37 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:10:37 - INFO - __main__ -     Num batches = 171
06/22/2023 05:10:37 - INFO - __main__ -     Batch size = 16
06/22/2023 05:10:46 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:10:46 - INFO - __main__ -     eval_acc = 0.5465
06/22/2023 05:10:46 - INFO - __main__ -     eval_loss = 1.1078
06/22/2023 05:10:46 - INFO - __main__ -     test_acc=0.5465
06/22/2023 05:10:46 - INFO - __main__ -     ********************
06/22/2023 05:10:46 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:10:47 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/1/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:10:52 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:10:52 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:10:52 - INFO - __main__ -     Num batches = 171
06/22/2023 05:10:52 - INFO - __main__ -     Batch size = 16
06/22/2023 05:11:01 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:11:01 - INFO - __main__ -     eval_acc = 0.5253
06/22/2023 05:11:01 - INFO - __main__ -     eval_loss = 1.1447
06/22/2023 05:11:01 - INFO - __main__ -     test_acc=0.5253
06/22/2023 05:11:01 - INFO - __main__ -     ********************
06/22/2023 05:11:01 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:11:01 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:11:02 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50
06/22/2023 05:11:03 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:11:03 - INFO - __main__ -     Batch size = 16
06/22/2023 05:11:03 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:11:03 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:11:09 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:11:09 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:11:09 - INFO - __main__ -     Num batches = 171
06/22/2023 05:11:09 - INFO - __main__ -     Batch size = 16
06/22/2023 05:11:18 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:11:18 - INFO - __main__ -     eval_acc = 0.4041
06/22/2023 05:11:18 - INFO - __main__ -     eval_loss = 2.3132
06/22/2023 05:11:18 - INFO - __main__ -     test_acc=0.4041
06/22/2023 05:11:18 - INFO - __main__ -     ********************
06/22/2023 05:11:18 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:11:18 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:11:24 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:11:24 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:11:24 - INFO - __main__ -     Num batches = 171
06/22/2023 05:11:24 - INFO - __main__ -     Batch size = 16
06/22/2023 05:11:33 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:11:33 - INFO - __main__ -     eval_acc = 0.4224
06/22/2023 05:11:33 - INFO - __main__ -     eval_loss = 2.1413
06/22/2023 05:11:33 - INFO - __main__ -     test_acc=0.4224
06/22/2023 05:11:33 - INFO - __main__ -     ********************
06/22/2023 05:11:33 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:11:33 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:11:34 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:11:34 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:11:34 - INFO - __main__ -     Batch size = 16
06/22/2023 05:11:34 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:11:35 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:11:39 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:11:39 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:11:39 - INFO - __main__ -     Num batches = 107
06/22/2023 05:11:39 - INFO - __main__ -     Batch size = 16
06/22/2023 05:11:44 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:11:44 - INFO - __main__ -     eval_acc = 0.3798
06/22/2023 05:11:44 - INFO - __main__ -     eval_loss = 2.1484
06/22/2023 05:11:44 - INFO - __main__ -     test_acc=0.3798
06/22/2023 05:11:44 - INFO - __main__ -     ********************
06/22/2023 05:11:44 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:11:45 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:11:48 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:11:48 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:11:48 - INFO - __main__ -     Num batches = 88
06/22/2023 05:11:48 - INFO - __main__ -     Batch size = 16
06/22/2023 05:11:52 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:11:52 - INFO - __main__ -     eval_acc = 0.407
06/22/2023 05:11:52 - INFO - __main__ -     eval_loss = 2.0354
06/22/2023 05:11:52 - INFO - __main__ -     test_acc=0.4070
06/22/2023 05:11:52 - INFO - __main__ -     ********************
06/22/2023 05:11:52 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:11:52 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:11:53 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:11:54 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:11:54 - INFO - __main__ -     Batch size = 16
06/22/2023 05:11:54 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:11:54 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:12:00 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:12:00 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:12:00 - INFO - __main__ -     Num batches = 171
06/22/2023 05:12:00 - INFO - __main__ -     Batch size = 16
06/22/2023 05:12:09 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:12:09 - INFO - __main__ -     eval_acc = 0.3781
06/22/2023 05:12:09 - INFO - __main__ -     eval_loss = 2.4305
06/22/2023 05:12:09 - INFO - __main__ -     test_acc=0.3781
06/22/2023 05:12:09 - INFO - __main__ -     ********************
06/22/2023 05:12:09 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:12:09 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:12:15 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:12:15 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:12:15 - INFO - __main__ -     Num batches = 171
06/22/2023 05:12:15 - INFO - __main__ -     Batch size = 16
06/22/2023 05:12:24 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:12:24 - INFO - __main__ -     eval_acc = 0.396
06/22/2023 05:12:24 - INFO - __main__ -     eval_loss = 2.247
06/22/2023 05:12:24 - INFO - __main__ -     test_acc=0.3960
06/22/2023 05:12:24 - INFO - __main__ -     ********************
06/22/2023 05:12:24 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:12:24 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:12:25 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:12:25 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:12:25 - INFO - __main__ -     Batch size = 16
06/22/2023 05:12:25 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:12:26 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:12:31 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:12:31 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:12:31 - INFO - __main__ -     Num batches = 171
06/22/2023 05:12:31 - INFO - __main__ -     Batch size = 16
06/22/2023 05:12:40 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:12:40 - INFO - __main__ -     eval_acc = 0.5538
06/22/2023 05:12:40 - INFO - __main__ -     eval_loss = 1.415
06/22/2023 05:12:40 - INFO - __main__ -     test_acc=0.5538
06/22/2023 05:12:40 - INFO - __main__ -     ********************
06/22/2023 05:12:40 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:12:40 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr1_bs32_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:12:46 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:12:46 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:12:46 - INFO - __main__ -     Num batches = 171
06/22/2023 05:12:46 - INFO - __main__ -     Batch size = 16
06/22/2023 05:12:55 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:12:55 - INFO - __main__ -     eval_acc = 0.5333
06/22/2023 05:12:55 - INFO - __main__ -     eval_loss = 1.4792
06/22/2023 05:12:55 - INFO - __main__ -     test_acc=0.5333
06/22/2023 05:12:55 - INFO - __main__ -     ********************
06/22/2023 05:12:55 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:12:55 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:12:56 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50
06/22/2023 05:12:56 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:12:56 - INFO - __main__ -     Batch size = 16
06/22/2023 05:12:56 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:12:57 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:13:03 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:13:03 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:13:03 - INFO - __main__ -     Num batches = 171
06/22/2023 05:13:03 - INFO - __main__ -     Batch size = 16
06/22/2023 05:13:11 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:13:11 - INFO - __main__ -     eval_acc = 0.3949
06/22/2023 05:13:11 - INFO - __main__ -     eval_loss = 2.0477
06/22/2023 05:13:11 - INFO - __main__ -     test_acc=0.3949
06/22/2023 05:13:11 - INFO - __main__ -     ********************
06/22/2023 05:13:11 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:13:12 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:13:17 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:13:17 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:13:17 - INFO - __main__ -     Num batches = 171
06/22/2023 05:13:17 - INFO - __main__ -     Batch size = 16
06/22/2023 05:13:26 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:13:26 - INFO - __main__ -     eval_acc = 0.4063
06/22/2023 05:13:26 - INFO - __main__ -     eval_loss = 1.9433
06/22/2023 05:13:26 - INFO - __main__ -     test_acc=0.4063
06/22/2023 05:13:26 - INFO - __main__ -     ********************
06/22/2023 05:13:27 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:13:27 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:13:28 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:13:28 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:13:28 - INFO - __main__ -     Batch size = 16
06/22/2023 05:13:28 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:13:28 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:13:32 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:13:32 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:13:32 - INFO - __main__ -     Num batches = 107
06/22/2023 05:13:32 - INFO - __main__ -     Batch size = 16
06/22/2023 05:13:38 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:13:38 - INFO - __main__ -     eval_acc = 0.3774
06/22/2023 05:13:38 - INFO - __main__ -     eval_loss = 1.9284
06/22/2023 05:13:38 - INFO - __main__ -     test_acc=0.3774
06/22/2023 05:13:38 - INFO - __main__ -     ********************
06/22/2023 05:13:38 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:13:38 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:13:41 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:13:41 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:13:41 - INFO - __main__ -     Num batches = 88
06/22/2023 05:13:41 - INFO - __main__ -     Batch size = 16
06/22/2023 05:13:46 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:13:46 - INFO - __main__ -     eval_acc = 0.3833
06/22/2023 05:13:46 - INFO - __main__ -     eval_loss = 1.9607
06/22/2023 05:13:46 - INFO - __main__ -     test_acc=0.3833
06/22/2023 05:13:46 - INFO - __main__ -     ********************
06/22/2023 05:13:46 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:13:46 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:13:47 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:13:47 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:13:47 - INFO - __main__ -     Batch size = 16
06/22/2023 05:13:47 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:13:48 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:13:53 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:13:53 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:13:53 - INFO - __main__ -     Num batches = 171
06/22/2023 05:13:53 - INFO - __main__ -     Batch size = 16
06/22/2023 05:14:02 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:14:02 - INFO - __main__ -     eval_acc = 0.366
06/22/2023 05:14:02 - INFO - __main__ -     eval_loss = 2.1373
06/22/2023 05:14:02 - INFO - __main__ -     test_acc=0.3660
06/22/2023 05:14:02 - INFO - __main__ -     ********************
06/22/2023 05:14:02 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:14:03 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:14:08 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:14:08 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:14:08 - INFO - __main__ -     Num batches = 171
06/22/2023 05:14:08 - INFO - __main__ -     Batch size = 16
06/22/2023 05:14:17 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:14:17 - INFO - __main__ -     eval_acc = 0.3715
06/22/2023 05:14:17 - INFO - __main__ -     eval_loss = 2.0454
06/22/2023 05:14:17 - INFO - __main__ -     test_acc=0.3715
06/22/2023 05:14:17 - INFO - __main__ -     ********************
06/22/2023 05:14:17 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:14:17 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:14:18 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:14:19 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:14:19 - INFO - __main__ -     Batch size = 16
06/22/2023 05:14:19 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:14:19 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:14:25 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:14:25 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:14:25 - INFO - __main__ -     Num batches = 171
06/22/2023 05:14:25 - INFO - __main__ -     Batch size = 16
06/22/2023 05:14:34 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:14:34 - INFO - __main__ -     eval_acc = 0.5619
06/22/2023 05:14:34 - INFO - __main__ -     eval_loss = 1.253
06/22/2023 05:14:34 - INFO - __main__ -     test_acc=0.5619
06/22/2023 05:14:34 - INFO - __main__ -     ********************
06/22/2023 05:14:34 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:14:34 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:14:40 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:14:40 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:14:40 - INFO - __main__ -     Num batches = 171
06/22/2023 05:14:40 - INFO - __main__ -     Batch size = 16
06/22/2023 05:14:49 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:14:49 - INFO - __main__ -     eval_acc = 0.5395
06/22/2023 05:14:49 - INFO - __main__ -     eval_loss = 1.3104
06/22/2023 05:14:49 - INFO - __main__ -     test_acc=0.5395
06/22/2023 05:14:49 - INFO - __main__ -     ********************
06/22/2023 05:14:49 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:14:49 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:14:50 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50
06/22/2023 05:14:50 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:14:50 - INFO - __main__ -     Batch size = 16
06/22/2023 05:14:50 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:14:51 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:14:56 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:14:56 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:14:56 - INFO - __main__ -     Num batches = 171
06/22/2023 05:14:56 - INFO - __main__ -     Batch size = 16
06/22/2023 05:15:05 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:15:05 - INFO - __main__ -     eval_acc = 0.3939
06/22/2023 05:15:05 - INFO - __main__ -     eval_loss = 1.5418
06/22/2023 05:15:05 - INFO - __main__ -     test_acc=0.3939
06/22/2023 05:15:05 - INFO - __main__ -     ********************
06/22/2023 05:15:05 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:15:06 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:15:11 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:15:11 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:15:11 - INFO - __main__ -     Num batches = 171
06/22/2023 05:15:11 - INFO - __main__ -     Batch size = 16
06/22/2023 05:15:20 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:15:20 - INFO - __main__ -     eval_acc = 0.4096
06/22/2023 05:15:20 - INFO - __main__ -     eval_loss = 1.437
06/22/2023 05:15:20 - INFO - __main__ -     test_acc=0.4096
06/22/2023 05:15:20 - INFO - __main__ -     ********************
06/22/2023 05:15:20 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:15:20 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:15:22 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:15:22 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:15:22 - INFO - __main__ -     Batch size = 16
06/22/2023 05:15:22 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:15:22 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:15:26 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:15:26 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:15:26 - INFO - __main__ -     Num batches = 107
06/22/2023 05:15:26 - INFO - __main__ -     Batch size = 16
06/22/2023 05:15:32 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:15:32 - INFO - __main__ -     eval_acc = 0.3757
06/22/2023 05:15:32 - INFO - __main__ -     eval_loss = 1.468
06/22/2023 05:15:32 - INFO - __main__ -     test_acc=0.3757
06/22/2023 05:15:32 - INFO - __main__ -     ********************
06/22/2023 05:15:32 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:15:32 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:15:35 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:15:35 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:15:35 - INFO - __main__ -     Num batches = 88
06/22/2023 05:15:35 - INFO - __main__ -     Batch size = 16
06/22/2023 05:15:40 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:15:40 - INFO - __main__ -     eval_acc = 0.3833
06/22/2023 05:15:40 - INFO - __main__ -     eval_loss = 1.418
06/22/2023 05:15:40 - INFO - __main__ -     test_acc=0.3833
06/22/2023 05:15:40 - INFO - __main__ -     ********************
06/22/2023 05:15:40 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:15:40 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:15:41 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:15:41 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:15:41 - INFO - __main__ -     Batch size = 16
06/22/2023 05:15:41 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:15:42 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:15:47 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:15:47 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:15:47 - INFO - __main__ -     Num batches = 171
06/22/2023 05:15:47 - INFO - __main__ -     Batch size = 16
06/22/2023 05:15:56 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:15:56 - INFO - __main__ -     eval_acc = 0.3719
06/22/2023 05:15:56 - INFO - __main__ -     eval_loss = 1.6278
06/22/2023 05:15:56 - INFO - __main__ -     test_acc=0.3719
06/22/2023 05:15:56 - INFO - __main__ -     ********************
06/22/2023 05:15:56 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:15:57 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:16:02 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:16:02 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:16:02 - INFO - __main__ -     Num batches = 171
06/22/2023 05:16:02 - INFO - __main__ -     Batch size = 16
06/22/2023 05:16:11 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:16:11 - INFO - __main__ -     eval_acc = 0.3851
06/22/2023 05:16:11 - INFO - __main__ -     eval_loss = 1.5372
06/22/2023 05:16:11 - INFO - __main__ -     test_acc=0.3851
06/22/2023 05:16:11 - INFO - __main__ -     ********************
06/22/2023 05:16:11 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:16:11 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:16:12 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:16:12 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:16:12 - INFO - __main__ -     Batch size = 16
06/22/2023 05:16:12 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:16:13 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:16:18 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:16:18 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:16:18 - INFO - __main__ -     Num batches = 171
06/22/2023 05:16:18 - INFO - __main__ -     Batch size = 16
06/22/2023 05:16:27 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:16:27 - INFO - __main__ -     eval_acc = 0.5461
06/22/2023 05:16:27 - INFO - __main__ -     eval_loss = 1.0215
06/22/2023 05:16:27 - INFO - __main__ -     test_acc=0.5461
06/22/2023 05:16:27 - INFO - __main__ -     ********************
06/22/2023 05:16:27 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:16:28 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr5_bs32_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:16:33 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:16:33 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:16:33 - INFO - __main__ -     Num batches = 171
06/22/2023 05:16:33 - INFO - __main__ -     Batch size = 16
06/22/2023 05:16:42 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:16:42 - INFO - __main__ -     eval_acc = 0.5227
06/22/2023 05:16:42 - INFO - __main__ -     eval_loss = 1.0324
06/22/2023 05:16:42 - INFO - __main__ -     test_acc=0.5227
06/22/2023 05:16:42 - INFO - __main__ -     ********************
06/22/2023 05:16:42 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:16:42 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:16:43 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50
06/22/2023 05:16:43 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:16:43 - INFO - __main__ -     Batch size = 16
06/22/2023 05:16:43 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:16:44 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:16:50 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:16:50 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:16:50 - INFO - __main__ -     Num batches = 171
06/22/2023 05:16:50 - INFO - __main__ -     Batch size = 16
06/22/2023 05:16:58 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:16:58 - INFO - __main__ -     eval_acc = 0.3854
06/22/2023 05:16:58 - INFO - __main__ -     eval_loss = 1.4688
06/22/2023 05:16:58 - INFO - __main__ -     test_acc=0.3854
06/22/2023 05:16:58 - INFO - __main__ -     ********************
06/22/2023 05:16:58 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:16:59 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:17:04 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:17:04 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:17:04 - INFO - __main__ -     Num batches = 171
06/22/2023 05:17:04 - INFO - __main__ -     Batch size = 16
06/22/2023 05:17:13 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:17:13 - INFO - __main__ -     eval_acc = 0.4111
06/22/2023 05:17:13 - INFO - __main__ -     eval_loss = 1.3871
06/22/2023 05:17:13 - INFO - __main__ -     test_acc=0.4111
06/22/2023 05:17:13 - INFO - __main__ -     ********************
06/22/2023 05:17:14 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:17:14 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:17:15 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:17:15 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:17:15 - INFO - __main__ -     Batch size = 16
06/22/2023 05:17:15 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:17:15 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:17:19 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:17:19 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:17:19 - INFO - __main__ -     Num batches = 107
06/22/2023 05:17:19 - INFO - __main__ -     Batch size = 16
06/22/2023 05:17:25 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:17:25 - INFO - __main__ -     eval_acc = 0.3633
06/22/2023 05:17:25 - INFO - __main__ -     eval_loss = 1.4075
06/22/2023 05:17:25 - INFO - __main__ -     test_acc=0.3633
06/22/2023 05:17:25 - INFO - __main__ -     ********************
06/22/2023 05:17:25 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:17:25 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:17:28 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:17:28 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:17:28 - INFO - __main__ -     Num batches = 88
06/22/2023 05:17:28 - INFO - __main__ -     Batch size = 16
06/22/2023 05:17:33 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:17:33 - INFO - __main__ -     eval_acc = 0.3941
06/22/2023 05:17:33 - INFO - __main__ -     eval_loss = 1.3849
06/22/2023 05:17:33 - INFO - __main__ -     test_acc=0.3941
06/22/2023 05:17:33 - INFO - __main__ -     ********************
06/22/2023 05:17:33 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:17:33 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:17:34 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:17:34 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:17:34 - INFO - __main__ -     Batch size = 16
06/22/2023 05:17:34 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:17:35 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:17:40 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:17:40 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:17:40 - INFO - __main__ -     Num batches = 171
06/22/2023 05:17:40 - INFO - __main__ -     Batch size = 16
06/22/2023 05:17:49 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:17:49 - INFO - __main__ -     eval_acc = 0.3646
06/22/2023 05:17:49 - INFO - __main__ -     eval_loss = 1.5255
06/22/2023 05:17:49 - INFO - __main__ -     test_acc=0.3646
06/22/2023 05:17:49 - INFO - __main__ -     ********************
06/22/2023 05:17:49 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:17:50 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:17:55 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:17:55 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:17:55 - INFO - __main__ -     Num batches = 171
06/22/2023 05:17:55 - INFO - __main__ -     Batch size = 16
06/22/2023 05:18:04 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:18:04 - INFO - __main__ -     eval_acc = 0.3924
06/22/2023 05:18:04 - INFO - __main__ -     eval_loss = 1.4538
06/22/2023 05:18:04 - INFO - __main__ -     test_acc=0.3924
06/22/2023 05:18:04 - INFO - __main__ -     ********************
06/22/2023 05:18:04 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:18:04 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:18:05 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:18:06 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:18:06 - INFO - __main__ -     Batch size = 16
06/22/2023 05:18:06 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:18:06 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:18:12 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:18:12 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:18:12 - INFO - __main__ -     Num batches = 171
06/22/2023 05:18:12 - INFO - __main__ -     Batch size = 16
06/22/2023 05:18:21 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:18:21 - INFO - __main__ -     eval_acc = 0.5454
06/22/2023 05:18:21 - INFO - __main__ -     eval_loss = 0.9945
06/22/2023 05:18:21 - INFO - __main__ -     test_acc=0.5454
06/22/2023 05:18:21 - INFO - __main__ -     ********************
06/22/2023 05:18:21 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:18:21 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr4_bs32_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:18:27 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:18:27 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:18:27 - INFO - __main__ -     Num batches = 171
06/22/2023 05:18:27 - INFO - __main__ -     Batch size = 16
06/22/2023 05:18:35 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:18:35 - INFO - __main__ -     eval_acc = 0.5304
06/22/2023 05:18:35 - INFO - __main__ -     eval_loss = 1.0211
06/22/2023 05:18:35 - INFO - __main__ -     test_acc=0.5304
06/22/2023 05:18:35 - INFO - __main__ -     ********************
06/22/2023 05:18:36 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:18:36 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:18:37 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50
06/22/2023 05:18:37 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:18:37 - INFO - __main__ -     Batch size = 16
06/22/2023 05:18:37 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:18:37 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:18:43 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:18:43 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:18:43 - INFO - __main__ -     Num batches = 171
06/22/2023 05:18:43 - INFO - __main__ -     Batch size = 16
06/22/2023 05:18:52 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:18:52 - INFO - __main__ -     eval_acc = 0.4327
06/22/2023 05:18:52 - INFO - __main__ -     eval_loss = 0.9561
06/22/2023 05:18:52 - INFO - __main__ -     test_acc=0.4327
06/22/2023 05:18:52 - INFO - __main__ -     ********************
06/22/2023 05:18:52 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:18:52 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:18:58 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:18:58 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:18:58 - INFO - __main__ -     Num batches = 171
06/22/2023 05:18:58 - INFO - __main__ -     Batch size = 16
06/22/2023 05:19:07 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:19:07 - INFO - __main__ -     eval_acc = 0.4447
06/22/2023 05:19:07 - INFO - __main__ -     eval_loss = 0.906
06/22/2023 05:19:07 - INFO - __main__ -     test_acc=0.4447
06/22/2023 05:19:07 - INFO - __main__ -     ********************
06/22/2023 05:19:07 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:19:07 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:19:08 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:19:08 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:19:08 - INFO - __main__ -     Batch size = 16
06/22/2023 05:19:08 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:19:09 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:19:13 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:19:13 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:19:13 - INFO - __main__ -     Num batches = 107
06/22/2023 05:19:13 - INFO - __main__ -     Batch size = 16
06/22/2023 05:19:18 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:19:18 - INFO - __main__ -     eval_acc = 0.4397
06/22/2023 05:19:18 - INFO - __main__ -     eval_loss = 0.949
06/22/2023 05:19:18 - INFO - __main__ -     test_acc=0.4397
06/22/2023 05:19:18 - INFO - __main__ -     ********************
06/22/2023 05:19:18 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:19:19 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:19:22 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:19:22 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:19:22 - INFO - __main__ -     Num batches = 88
06/22/2023 05:19:22 - INFO - __main__ -     Batch size = 16
06/22/2023 05:19:26 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:19:26 - INFO - __main__ -     eval_acc = 0.4314
06/22/2023 05:19:26 - INFO - __main__ -     eval_loss = 0.8885
06/22/2023 05:19:26 - INFO - __main__ -     test_acc=0.4314
06/22/2023 05:19:26 - INFO - __main__ -     ********************
06/22/2023 05:19:26 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:19:26 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:19:28 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:19:28 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:19:28 - INFO - __main__ -     Batch size = 16
06/22/2023 05:19:28 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:19:28 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:19:34 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:19:34 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:19:34 - INFO - __main__ -     Num batches = 171
06/22/2023 05:19:34 - INFO - __main__ -     Batch size = 16
06/22/2023 05:19:43 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:19:43 - INFO - __main__ -     eval_acc = 0.4367
06/22/2023 05:19:43 - INFO - __main__ -     eval_loss = 0.9475
06/22/2023 05:19:43 - INFO - __main__ -     test_acc=0.4367
06/22/2023 05:19:43 - INFO - __main__ -     ********************
06/22/2023 05:19:43 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:19:43 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:19:49 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:19:49 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:19:49 - INFO - __main__ -     Num batches = 171
06/22/2023 05:19:49 - INFO - __main__ -     Batch size = 16
06/22/2023 05:19:58 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:19:58 - INFO - __main__ -     eval_acc = 0.4499
06/22/2023 05:19:58 - INFO - __main__ -     eval_loss = 0.9145
06/22/2023 05:19:58 - INFO - __main__ -     test_acc=0.4499
06/22/2023 05:19:58 - INFO - __main__ -     ********************
06/22/2023 05:19:58 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:19:58 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:19:59 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:19:59 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:19:59 - INFO - __main__ -     Batch size = 16
06/22/2023 05:19:59 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:20:00 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:20:05 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:20:05 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:20:05 - INFO - __main__ -     Num batches = 171
06/22/2023 05:20:05 - INFO - __main__ -     Batch size = 16
06/22/2023 05:20:14 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:20:14 - INFO - __main__ -     eval_acc = 0.5575
06/22/2023 05:20:14 - INFO - __main__ -     eval_loss = 0.7284
06/22/2023 05:20:14 - INFO - __main__ -     test_acc=0.5575
06/22/2023 05:20:14 - INFO - __main__ -     ********************
06/22/2023 05:20:14 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:20:14 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:20:20 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:20:20 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:20:20 - INFO - __main__ -     Num batches = 171
06/22/2023 05:20:20 - INFO - __main__ -     Batch size = 16
06/22/2023 05:20:29 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:20:29 - INFO - __main__ -     eval_acc = 0.5132
06/22/2023 05:20:29 - INFO - __main__ -     eval_loss = 0.7505
06/22/2023 05:20:29 - INFO - __main__ -     test_acc=0.5132
06/22/2023 05:20:29 - INFO - __main__ -     ********************
06/22/2023 05:20:29 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:20:29 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:20:30 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50
06/22/2023 05:20:30 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:20:30 - INFO - __main__ -     Batch size = 16
06/22/2023 05:20:30 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:20:31 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:20:36 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:20:36 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:20:36 - INFO - __main__ -     Num batches = 171
06/22/2023 05:20:36 - INFO - __main__ -     Batch size = 16
06/22/2023 05:20:45 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:20:45 - INFO - __main__ -     eval_acc = 0.3836
06/22/2023 05:20:45 - INFO - __main__ -     eval_loss = 1.8392
06/22/2023 05:20:45 - INFO - __main__ -     test_acc=0.3836
06/22/2023 05:20:45 - INFO - __main__ -     ********************
06/22/2023 05:20:45 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:20:46 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:20:51 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:20:51 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:20:51 - INFO - __main__ -     Num batches = 171
06/22/2023 05:20:51 - INFO - __main__ -     Batch size = 16
06/22/2023 05:21:00 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:21:00 - INFO - __main__ -     eval_acc = 0.4015
06/22/2023 05:21:00 - INFO - __main__ -     eval_loss = 1.7151
06/22/2023 05:21:00 - INFO - __main__ -     test_acc=0.4015
06/22/2023 05:21:00 - INFO - __main__ -     ********************
06/22/2023 05:21:00 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:21:00 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:21:01 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:21:02 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:21:02 - INFO - __main__ -     Batch size = 16
06/22/2023 05:21:02 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:21:02 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:21:06 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:21:06 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:21:06 - INFO - __main__ -     Num batches = 107
06/22/2023 05:21:06 - INFO - __main__ -     Batch size = 16
06/22/2023 05:21:12 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:21:12 - INFO - __main__ -     eval_acc = 0.3745
06/22/2023 05:21:12 - INFO - __main__ -     eval_loss = 1.8005
06/22/2023 05:21:12 - INFO - __main__ -     test_acc=0.3745
06/22/2023 05:21:12 - INFO - __main__ -     ********************
06/22/2023 05:21:12 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:21:12 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:21:15 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:21:15 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:21:15 - INFO - __main__ -     Num batches = 88
06/22/2023 05:21:15 - INFO - __main__ -     Batch size = 16
06/22/2023 05:21:20 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:21:20 - INFO - __main__ -     eval_acc = 0.3941
06/22/2023 05:21:20 - INFO - __main__ -     eval_loss = 1.7118
06/22/2023 05:21:20 - INFO - __main__ -     test_acc=0.3941
06/22/2023 05:21:20 - INFO - __main__ -     ********************
06/22/2023 05:21:20 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:21:20 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:21:21 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:21:21 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:21:21 - INFO - __main__ -     Batch size = 16
06/22/2023 05:21:21 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:21:22 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:21:27 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:21:27 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:21:27 - INFO - __main__ -     Num batches = 171
06/22/2023 05:21:27 - INFO - __main__ -     Batch size = 16
06/22/2023 05:21:36 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:21:36 - INFO - __main__ -     eval_acc = 0.3668
06/22/2023 05:21:36 - INFO - __main__ -     eval_loss = 1.8871
06/22/2023 05:21:36 - INFO - __main__ -     test_acc=0.3668
06/22/2023 05:21:36 - INFO - __main__ -     ********************
06/22/2023 05:21:36 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:21:36 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:21:42 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:21:42 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:21:42 - INFO - __main__ -     Num batches = 171
06/22/2023 05:21:42 - INFO - __main__ -     Batch size = 16
06/22/2023 05:21:51 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:21:51 - INFO - __main__ -     eval_acc = 0.3887
06/22/2023 05:21:51 - INFO - __main__ -     eval_loss = 1.7607
06/22/2023 05:21:51 - INFO - __main__ -     test_acc=0.3887
06/22/2023 05:21:51 - INFO - __main__ -     ********************
06/22/2023 05:21:51 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:21:51 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:21:52 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:21:52 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:21:52 - INFO - __main__ -     Batch size = 16
06/22/2023 05:21:52 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:21:53 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:21:58 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:21:58 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:21:58 - INFO - __main__ -     Num batches = 171
06/22/2023 05:21:58 - INFO - __main__ -     Batch size = 16
06/22/2023 05:22:07 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:22:07 - INFO - __main__ -     eval_acc = 0.5472
06/22/2023 05:22:07 - INFO - __main__ -     eval_loss = 1.2047
06/22/2023 05:22:07 - INFO - __main__ -     test_acc=0.5472
06/22/2023 05:22:07 - INFO - __main__ -     ********************
06/22/2023 05:22:07 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:22:08 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr6_bs32_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:22:13 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:22:13 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:22:13 - INFO - __main__ -     Num batches = 171
06/22/2023 05:22:13 - INFO - __main__ -     Batch size = 16
06/22/2023 05:22:22 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:22:22 - INFO - __main__ -     eval_acc = 0.5293
06/22/2023 05:22:22 - INFO - __main__ -     eval_loss = 1.2146
06/22/2023 05:22:22 - INFO - __main__ -     test_acc=0.5293
06/22/2023 05:22:22 - INFO - __main__ -     ********************
06/22/2023 05:22:22 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:22:22 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:22:24 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50
06/22/2023 05:22:24 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:22:24 - INFO - __main__ -     Batch size = 16
06/22/2023 05:22:24 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:22:24 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:22:30 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:22:30 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:22:30 - INFO - __main__ -     Num batches = 171
06/22/2023 05:22:30 - INFO - __main__ -     Batch size = 16
06/22/2023 05:22:39 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:22:39 - INFO - __main__ -     eval_acc = 0.388
06/22/2023 05:22:39 - INFO - __main__ -     eval_loss = 1.8395
06/22/2023 05:22:39 - INFO - __main__ -     test_acc=0.3880
06/22/2023 05:22:39 - INFO - __main__ -     ********************
06/22/2023 05:22:39 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:22:39 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:22:45 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:22:45 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:22:45 - INFO - __main__ -     Num batches = 171
06/22/2023 05:22:45 - INFO - __main__ -     Batch size = 16
06/22/2023 05:22:54 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:22:54 - INFO - __main__ -     eval_acc = 0.4096
06/22/2023 05:22:54 - INFO - __main__ -     eval_loss = 1.7188
06/22/2023 05:22:54 - INFO - __main__ -     test_acc=0.4096
06/22/2023 05:22:54 - INFO - __main__ -     ********************
06/22/2023 05:22:54 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:22:54 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:22:55 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:22:55 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:22:55 - INFO - __main__ -     Batch size = 16
06/22/2023 05:22:55 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:22:55 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:22:59 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:22:59 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:22:59 - INFO - __main__ -     Num batches = 107
06/22/2023 05:22:59 - INFO - __main__ -     Batch size = 16
06/22/2023 05:23:05 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:23:05 - INFO - __main__ -     eval_acc = 0.378
06/22/2023 05:23:05 - INFO - __main__ -     eval_loss = 1.8409
06/22/2023 05:23:05 - INFO - __main__ -     test_acc=0.3780
06/22/2023 05:23:05 - INFO - __main__ -     ********************
06/22/2023 05:23:05 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:23:05 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:23:08 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:23:08 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:23:08 - INFO - __main__ -     Num batches = 88
06/22/2023 05:23:08 - INFO - __main__ -     Batch size = 16
06/22/2023 05:23:13 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:23:13 - INFO - __main__ -     eval_acc = 0.3769
06/22/2023 05:23:13 - INFO - __main__ -     eval_loss = 1.8361
06/22/2023 05:23:13 - INFO - __main__ -     test_acc=0.3769
06/22/2023 05:23:13 - INFO - __main__ -     ********************
06/22/2023 05:23:13 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:23:13 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:23:14 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:23:15 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:23:15 - INFO - __main__ -     Batch size = 16
06/22/2023 05:23:15 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:23:15 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:23:20 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:23:20 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:23:20 - INFO - __main__ -     Num batches = 171
06/22/2023 05:23:20 - INFO - __main__ -     Batch size = 16
06/22/2023 05:23:29 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:23:29 - INFO - __main__ -     eval_acc = 0.3587
06/22/2023 05:23:29 - INFO - __main__ -     eval_loss = 1.9751
06/22/2023 05:23:29 - INFO - __main__ -     test_acc=0.3587
06/22/2023 05:23:29 - INFO - __main__ -     ********************
06/22/2023 05:23:29 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:23:30 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:23:35 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:23:35 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:23:35 - INFO - __main__ -     Num batches = 171
06/22/2023 05:23:35 - INFO - __main__ -     Batch size = 16
06/22/2023 05:23:44 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:23:44 - INFO - __main__ -     eval_acc = 0.3862
06/22/2023 05:23:44 - INFO - __main__ -     eval_loss = 1.8501
06/22/2023 05:23:44 - INFO - __main__ -     test_acc=0.3862
06/22/2023 05:23:44 - INFO - __main__ -     ********************
06/22/2023 05:23:44 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:23:44 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:23:46 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:23:46 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:23:46 - INFO - __main__ -     Batch size = 16
06/22/2023 05:23:46 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:23:46 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:23:52 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:23:52 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:23:52 - INFO - __main__ -     Num batches = 171
06/22/2023 05:23:52 - INFO - __main__ -     Batch size = 16
06/22/2023 05:24:01 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:24:01 - INFO - __main__ -     eval_acc = 0.5487
06/22/2023 05:24:01 - INFO - __main__ -     eval_loss = 1.2896
06/22/2023 05:24:01 - INFO - __main__ -     test_acc=0.5487
06/22/2023 05:24:01 - INFO - __main__ -     ********************
06/22/2023 05:24:01 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:24:01 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:24:07 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:24:07 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:24:07 - INFO - __main__ -     Num batches = 171
06/22/2023 05:24:07 - INFO - __main__ -     Batch size = 16
06/22/2023 05:24:16 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:24:16 - INFO - __main__ -     eval_acc = 0.5432
06/22/2023 05:24:16 - INFO - __main__ -     eval_loss = 1.2875
06/22/2023 05:24:16 - INFO - __main__ -     test_acc=0.5432
06/22/2023 05:24:16 - INFO - __main__ -     ********************
06/22/2023 05:24:16 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:24:16 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:24:17 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50
06/22/2023 05:24:17 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:24:17 - INFO - __main__ -     Batch size = 16
06/22/2023 05:24:17 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:24:18 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:24:23 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:24:23 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:24:23 - INFO - __main__ -     Num batches = 171
06/22/2023 05:24:23 - INFO - __main__ -     Batch size = 16
06/22/2023 05:24:32 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:24:32 - INFO - __main__ -     eval_acc = 0.3982
06/22/2023 05:24:32 - INFO - __main__ -     eval_loss = 1.9786
06/22/2023 05:24:32 - INFO - __main__ -     test_acc=0.3982
06/22/2023 05:24:32 - INFO - __main__ -     ********************
06/22/2023 05:24:32 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:24:33 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:24:38 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:24:38 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:24:38 - INFO - __main__ -     Num batches = 171
06/22/2023 05:24:38 - INFO - __main__ -     Batch size = 16
06/22/2023 05:24:47 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:24:47 - INFO - __main__ -     eval_acc = 0.4184
06/22/2023 05:24:47 - INFO - __main__ -     eval_loss = 1.871
06/22/2023 05:24:47 - INFO - __main__ -     test_acc=0.4184
06/22/2023 05:24:47 - INFO - __main__ -     ********************
06/22/2023 05:24:47 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:24:47 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:24:49 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:24:49 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:24:49 - INFO - __main__ -     Batch size = 16
06/22/2023 05:24:49 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:24:50 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:24:54 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:24:54 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:24:54 - INFO - __main__ -     Num batches = 107
06/22/2023 05:24:54 - INFO - __main__ -     Batch size = 16
06/22/2023 05:24:59 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:24:59 - INFO - __main__ -     eval_acc = 0.3815
06/22/2023 05:24:59 - INFO - __main__ -     eval_loss = 1.943
06/22/2023 05:24:59 - INFO - __main__ -     test_acc=0.3815
06/22/2023 05:24:59 - INFO - __main__ -     ********************
06/22/2023 05:24:59 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:25:00 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:25:03 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:25:03 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:25:03 - INFO - __main__ -     Num batches = 88
06/22/2023 05:25:03 - INFO - __main__ -     Batch size = 16
06/22/2023 05:25:07 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:25:07 - INFO - __main__ -     eval_acc = 0.3948
06/22/2023 05:25:07 - INFO - __main__ -     eval_loss = 1.9237
06/22/2023 05:25:07 - INFO - __main__ -     test_acc=0.3948
06/22/2023 05:25:07 - INFO - __main__ -     ********************
06/22/2023 05:25:08 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:25:08 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:25:09 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:25:09 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:25:09 - INFO - __main__ -     Batch size = 16
06/22/2023 05:25:09 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:25:09 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:25:15 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:25:15 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:25:15 - INFO - __main__ -     Num batches = 171
06/22/2023 05:25:15 - INFO - __main__ -     Batch size = 16
06/22/2023 05:25:24 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:25:24 - INFO - __main__ -     eval_acc = 0.3774
06/22/2023 05:25:24 - INFO - __main__ -     eval_loss = 2.0497
06/22/2023 05:25:24 - INFO - __main__ -     test_acc=0.3774
06/22/2023 05:25:24 - INFO - __main__ -     ********************
06/22/2023 05:25:24 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:25:24 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:25:30 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:25:30 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:25:30 - INFO - __main__ -     Num batches = 171
06/22/2023 05:25:30 - INFO - __main__ -     Batch size = 16
06/22/2023 05:25:39 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:25:39 - INFO - __main__ -     eval_acc = 0.3942
06/22/2023 05:25:39 - INFO - __main__ -     eval_loss = 1.9468
06/22/2023 05:25:39 - INFO - __main__ -     test_acc=0.3942
06/22/2023 05:25:39 - INFO - __main__ -     ********************
06/22/2023 05:25:39 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:25:39 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:25:40 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:25:40 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:25:40 - INFO - __main__ -     Batch size = 16
06/22/2023 05:25:40 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:25:41 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:25:46 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:25:46 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:25:46 - INFO - __main__ -     Num batches = 171
06/22/2023 05:25:46 - INFO - __main__ -     Batch size = 16
06/22/2023 05:25:55 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:25:55 - INFO - __main__ -     eval_acc = 0.5608
06/22/2023 05:25:55 - INFO - __main__ -     eval_loss = 1.2947
06/22/2023 05:25:55 - INFO - __main__ -     test_acc=0.5608
06/22/2023 05:25:55 - INFO - __main__ -     ********************
06/22/2023 05:25:55 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:25:56 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:26:01 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:26:01 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:26:01 - INFO - __main__ -     Num batches = 171
06/22/2023 05:26:01 - INFO - __main__ -     Batch size = 16
06/22/2023 05:26:10 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:26:10 - INFO - __main__ -     eval_acc = 0.548
06/22/2023 05:26:10 - INFO - __main__ -     eval_loss = 1.3422
06/22/2023 05:26:10 - INFO - __main__ -     test_acc=0.5480
06/22/2023 05:26:10 - INFO - __main__ -     ********************
06/22/2023 05:26:10 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:26:10 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:26:11 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50
06/22/2023 05:26:12 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:26:12 - INFO - __main__ -     Batch size = 16
06/22/2023 05:26:12 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:26:12 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:26:18 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:26:18 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:26:18 - INFO - __main__ -     Num batches = 171
06/22/2023 05:26:18 - INFO - __main__ -     Batch size = 16
06/22/2023 05:26:27 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:26:27 - INFO - __main__ -     eval_acc = 0.3913
06/22/2023 05:26:27 - INFO - __main__ -     eval_loss = 1.7232
06/22/2023 05:26:27 - INFO - __main__ -     test_acc=0.3913
06/22/2023 05:26:27 - INFO - __main__ -     ********************
06/22/2023 05:26:27 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:26:27 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:26:33 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:26:33 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:26:33 - INFO - __main__ -     Num batches = 171
06/22/2023 05:26:33 - INFO - __main__ -     Batch size = 16
06/22/2023 05:26:41 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:26:41 - INFO - __main__ -     eval_acc = 0.4026
06/22/2023 05:26:41 - INFO - __main__ -     eval_loss = 1.6463
06/22/2023 05:26:41 - INFO - __main__ -     test_acc=0.4026
06/22/2023 05:26:41 - INFO - __main__ -     ********************
06/22/2023 05:26:42 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:26:42 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:26:43 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:26:43 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:26:43 - INFO - __main__ -     Batch size = 16
06/22/2023 05:26:43 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:26:43 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:26:47 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:26:47 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:26:47 - INFO - __main__ -     Num batches = 107
06/22/2023 05:26:47 - INFO - __main__ -     Batch size = 16
06/22/2023 05:26:53 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:26:53 - INFO - __main__ -     eval_acc = 0.3745
06/22/2023 05:26:53 - INFO - __main__ -     eval_loss = 1.6876
06/22/2023 05:26:53 - INFO - __main__ -     test_acc=0.3745
06/22/2023 05:26:53 - INFO - __main__ -     ********************
06/22/2023 05:26:53 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:26:53 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:26:56 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:26:56 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:26:56 - INFO - __main__ -     Num batches = 88
06/22/2023 05:26:56 - INFO - __main__ -     Batch size = 16
06/22/2023 05:27:01 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:27:01 - INFO - __main__ -     eval_acc = 0.3747
06/22/2023 05:27:01 - INFO - __main__ -     eval_loss = 1.6901
06/22/2023 05:27:01 - INFO - __main__ -     test_acc=0.3747
06/22/2023 05:27:01 - INFO - __main__ -     ********************
06/22/2023 05:27:01 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:27:01 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:27:02 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:27:02 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:27:02 - INFO - __main__ -     Batch size = 16
06/22/2023 05:27:02 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:27:03 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:27:08 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:27:08 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:27:08 - INFO - __main__ -     Num batches = 171
06/22/2023 05:27:08 - INFO - __main__ -     Batch size = 16
06/22/2023 05:27:17 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:27:17 - INFO - __main__ -     eval_acc = 0.3682
06/22/2023 05:27:17 - INFO - __main__ -     eval_loss = 1.815
06/22/2023 05:27:17 - INFO - __main__ -     test_acc=0.3682
06/22/2023 05:27:17 - INFO - __main__ -     ********************
06/22/2023 05:27:17 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:27:18 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:27:23 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:27:23 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:27:23 - INFO - __main__ -     Num batches = 171
06/22/2023 05:27:23 - INFO - __main__ -     Batch size = 16
06/22/2023 05:27:32 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:27:32 - INFO - __main__ -     eval_acc = 0.373
06/22/2023 05:27:32 - INFO - __main__ -     eval_loss = 1.7409
06/22/2023 05:27:32 - INFO - __main__ -     test_acc=0.3730
06/22/2023 05:27:32 - INFO - __main__ -     ********************
06/22/2023 05:27:32 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:27:32 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:27:34 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:27:34 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:27:34 - INFO - __main__ -     Batch size = 16
06/22/2023 05:27:34 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:27:34 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:27:40 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:27:40 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:27:40 - INFO - __main__ -     Num batches = 171
06/22/2023 05:27:40 - INFO - __main__ -     Batch size = 16
06/22/2023 05:27:49 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:27:49 - INFO - __main__ -     eval_acc = 0.5556
06/22/2023 05:27:49 - INFO - __main__ -     eval_loss = 1.1359
06/22/2023 05:27:49 - INFO - __main__ -     test_acc=0.5556
06/22/2023 05:27:49 - INFO - __main__ -     ********************
06/22/2023 05:27:49 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:27:49 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:27:55 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:27:55 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:27:55 - INFO - __main__ -     Num batches = 171
06/22/2023 05:27:55 - INFO - __main__ -     Batch size = 16
06/22/2023 05:28:04 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:28:04 - INFO - __main__ -     eval_acc = 0.5399
06/22/2023 05:28:04 - INFO - __main__ -     eval_loss = 1.1494
06/22/2023 05:28:04 - INFO - __main__ -     test_acc=0.5399
06/22/2023 05:28:04 - INFO - __main__ -     ********************
06/22/2023 05:28:04 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:28:04 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:28:05 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50
06/22/2023 05:28:05 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:28:05 - INFO - __main__ -     Batch size = 16
06/22/2023 05:28:05 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:28:05 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:28:11 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:28:11 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:28:11 - INFO - __main__ -     Num batches = 171
06/22/2023 05:28:11 - INFO - __main__ -     Batch size = 16
06/22/2023 05:28:20 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:28:20 - INFO - __main__ -     eval_acc = 0.3986
06/22/2023 05:28:20 - INFO - __main__ -     eval_loss = 1.6641
06/22/2023 05:28:20 - INFO - __main__ -     test_acc=0.3986
06/22/2023 05:28:20 - INFO - __main__ -     ********************
06/22/2023 05:28:20 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:28:20 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:28:26 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:28:26 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:28:26 - INFO - __main__ -     Num batches = 171
06/22/2023 05:28:26 - INFO - __main__ -     Batch size = 16
06/22/2023 05:28:35 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:28:35 - INFO - __main__ -     eval_acc = 0.4074
06/22/2023 05:28:35 - INFO - __main__ -     eval_loss = 1.5872
06/22/2023 05:28:35 - INFO - __main__ -     test_acc=0.4074
06/22/2023 05:28:35 - INFO - __main__ -     ********************
06/22/2023 05:28:35 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:28:35 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:28:36 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:28:36 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:28:36 - INFO - __main__ -     Batch size = 16
06/22/2023 05:28:36 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:28:37 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:28:41 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:28:41 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:28:41 - INFO - __main__ -     Num batches = 107
06/22/2023 05:28:41 - INFO - __main__ -     Batch size = 16
06/22/2023 05:28:46 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:28:46 - INFO - __main__ -     eval_acc = 0.3921
06/22/2023 05:28:46 - INFO - __main__ -     eval_loss = 1.5664
06/22/2023 05:28:46 - INFO - __main__ -     test_acc=0.3921
06/22/2023 05:28:46 - INFO - __main__ -     ********************
06/22/2023 05:28:46 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:28:47 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:28:50 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:28:50 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:28:50 - INFO - __main__ -     Num batches = 88
06/22/2023 05:28:50 - INFO - __main__ -     Batch size = 16
06/22/2023 05:28:54 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:28:54 - INFO - __main__ -     eval_acc = 0.4121
06/22/2023 05:28:54 - INFO - __main__ -     eval_loss = 1.599
06/22/2023 05:28:54 - INFO - __main__ -     test_acc=0.4121
06/22/2023 05:28:54 - INFO - __main__ -     ********************
06/22/2023 05:28:55 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:28:55 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:28:56 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:28:56 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:28:56 - INFO - __main__ -     Batch size = 16
06/22/2023 05:28:56 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:28:56 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:29:02 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:29:02 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:29:02 - INFO - __main__ -     Num batches = 171
06/22/2023 05:29:02 - INFO - __main__ -     Batch size = 16
06/22/2023 05:29:11 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:29:11 - INFO - __main__ -     eval_acc = 0.3799
06/22/2023 05:29:11 - INFO - __main__ -     eval_loss = 1.7467
06/22/2023 05:29:11 - INFO - __main__ -     test_acc=0.3799
06/22/2023 05:29:11 - INFO - __main__ -     ********************
06/22/2023 05:29:11 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:29:11 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:29:17 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:29:17 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:29:17 - INFO - __main__ -     Num batches = 171
06/22/2023 05:29:17 - INFO - __main__ -     Batch size = 16
06/22/2023 05:29:26 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:29:26 - INFO - __main__ -     eval_acc = 0.3825
06/22/2023 05:29:26 - INFO - __main__ -     eval_loss = 1.6776
06/22/2023 05:29:26 - INFO - __main__ -     test_acc=0.3825
06/22/2023 05:29:26 - INFO - __main__ -     ********************
06/22/2023 05:29:26 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:29:26 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:29:27 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:29:27 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:29:27 - INFO - __main__ -     Batch size = 16
06/22/2023 05:29:27 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:29:28 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:29:33 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:29:33 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:29:33 - INFO - __main__ -     Num batches = 171
06/22/2023 05:29:33 - INFO - __main__ -     Batch size = 16
06/22/2023 05:29:42 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:29:42 - INFO - __main__ -     eval_acc = 0.5575
06/22/2023 05:29:42 - INFO - __main__ -     eval_loss = 1.0546
06/22/2023 05:29:42 - INFO - __main__ -     test_acc=0.5575
06/22/2023 05:29:42 - INFO - __main__ -     ********************
06/22/2023 05:29:42 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:29:42 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:29:48 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:29:48 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:29:48 - INFO - __main__ -     Num batches = 171
06/22/2023 05:29:48 - INFO - __main__ -     Batch size = 16
06/22/2023 05:29:57 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:29:57 - INFO - __main__ -     eval_acc = 0.5388
06/22/2023 05:29:57 - INFO - __main__ -     eval_loss = 1.1208
06/22/2023 05:29:57 - INFO - __main__ -     test_acc=0.5388
06/22/2023 05:29:57 - INFO - __main__ -     ********************
06/22/2023 05:29:57 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:29:57 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:29:58 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50
06/22/2023 05:29:59 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:29:59 - INFO - __main__ -     Batch size = 16
06/22/2023 05:29:59 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:29:59 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:30:05 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:30:05 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:30:05 - INFO - __main__ -     Num batches = 171
06/22/2023 05:30:05 - INFO - __main__ -     Batch size = 16
06/22/2023 05:30:14 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:30:14 - INFO - __main__ -     eval_acc = 0.3946
06/22/2023 05:30:14 - INFO - __main__ -     eval_loss = 1.7233
06/22/2023 05:30:14 - INFO - __main__ -     test_acc=0.3946
06/22/2023 05:30:14 - INFO - __main__ -     ********************
06/22/2023 05:30:14 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:30:14 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:30:20 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:30:20 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:30:20 - INFO - __main__ -     Num batches = 171
06/22/2023 05:30:20 - INFO - __main__ -     Batch size = 16
06/22/2023 05:30:29 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:30:29 - INFO - __main__ -     eval_acc = 0.4202
06/22/2023 05:30:29 - INFO - __main__ -     eval_loss = 1.6522
06/22/2023 05:30:29 - INFO - __main__ -     test_acc=0.4202
06/22/2023 05:30:29 - INFO - __main__ -     ********************
06/22/2023 05:30:29 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:30:29 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:30:30 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:30:30 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:30:30 - INFO - __main__ -     Batch size = 16
06/22/2023 05:30:30 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:30:30 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:30:34 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:30:34 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:30:34 - INFO - __main__ -     Num batches = 107
06/22/2023 05:30:34 - INFO - __main__ -     Batch size = 16
06/22/2023 05:30:40 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:30:40 - INFO - __main__ -     eval_acc = 0.3956
06/22/2023 05:30:40 - INFO - __main__ -     eval_loss = 1.632
06/22/2023 05:30:40 - INFO - __main__ -     test_acc=0.3956
06/22/2023 05:30:40 - INFO - __main__ -     ********************
06/22/2023 05:30:40 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:30:40 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:30:43 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:30:43 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:30:43 - INFO - __main__ -     Num batches = 88
06/22/2023 05:30:43 - INFO - __main__ -     Batch size = 16
06/22/2023 05:30:48 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:30:48 - INFO - __main__ -     eval_acc = 0.407
06/22/2023 05:30:48 - INFO - __main__ -     eval_loss = 1.609
06/22/2023 05:30:48 - INFO - __main__ -     test_acc=0.4070
06/22/2023 05:30:48 - INFO - __main__ -     ********************
06/22/2023 05:30:48 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:30:48 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:30:49 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:30:49 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:30:49 - INFO - __main__ -     Batch size = 16
06/22/2023 05:30:49 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:30:50 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:30:56 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:30:56 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:30:56 - INFO - __main__ -     Num batches = 171
06/22/2023 05:30:56 - INFO - __main__ -     Batch size = 16
06/22/2023 05:31:04 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:31:04 - INFO - __main__ -     eval_acc = 0.3788
06/22/2023 05:31:04 - INFO - __main__ -     eval_loss = 1.8171
06/22/2023 05:31:04 - INFO - __main__ -     test_acc=0.3788
06/22/2023 05:31:04 - INFO - __main__ -     ********************
06/22/2023 05:31:04 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:31:05 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:31:10 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:31:10 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:31:10 - INFO - __main__ -     Num batches = 171
06/22/2023 05:31:10 - INFO - __main__ -     Batch size = 16
06/22/2023 05:31:19 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:31:19 - INFO - __main__ -     eval_acc = 0.3935
06/22/2023 05:31:19 - INFO - __main__ -     eval_loss = 1.7278
06/22/2023 05:31:19 - INFO - __main__ -     test_acc=0.3935
06/22/2023 05:31:19 - INFO - __main__ -     ********************
06/22/2023 05:31:19 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:31:19 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:31:20 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:31:21 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:31:21 - INFO - __main__ -     Batch size = 16
06/22/2023 05:31:21 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:31:21 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:31:27 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:31:27 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:31:27 - INFO - __main__ -     Num batches = 171
06/22/2023 05:31:27 - INFO - __main__ -     Batch size = 16
06/22/2023 05:31:36 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:31:36 - INFO - __main__ -     eval_acc = 0.5633
06/22/2023 05:31:36 - INFO - __main__ -     eval_loss = 1.0937
06/22/2023 05:31:36 - INFO - __main__ -     test_acc=0.5633
06/22/2023 05:31:36 - INFO - __main__ -     ********************
06/22/2023 05:31:36 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:31:36 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr2_bs32_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:31:42 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:31:42 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:31:42 - INFO - __main__ -     Num batches = 171
06/22/2023 05:31:42 - INFO - __main__ -     Batch size = 16
06/22/2023 05:31:50 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:31:50 - INFO - __main__ -     eval_acc = 0.5373
06/22/2023 05:31:50 - INFO - __main__ -     eval_loss = 1.1511
06/22/2023 05:31:50 - INFO - __main__ -     test_acc=0.5373
06/22/2023 05:31:50 - INFO - __main__ -     ********************
06/22/2023 05:31:51 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:31:51 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:31:52 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50
06/22/2023 05:31:52 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:31:52 - INFO - __main__ -     Batch size = 16
06/22/2023 05:31:52 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:31:52 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:31:58 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:31:58 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:31:58 - INFO - __main__ -     Num batches = 171
06/22/2023 05:31:58 - INFO - __main__ -     Batch size = 16
06/22/2023 05:32:07 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:32:07 - INFO - __main__ -     eval_acc = 0.3957
06/22/2023 05:32:07 - INFO - __main__ -     eval_loss = 1.7691
06/22/2023 05:32:07 - INFO - __main__ -     test_acc=0.3957
06/22/2023 05:32:07 - INFO - __main__ -     ********************
06/22/2023 05:32:07 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:32:07 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:32:13 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:32:13 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:32:13 - INFO - __main__ -     Num batches = 171
06/22/2023 05:32:13 - INFO - __main__ -     Batch size = 16
06/22/2023 05:32:22 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:32:22 - INFO - __main__ -     eval_acc = 0.4103
06/22/2023 05:32:22 - INFO - __main__ -     eval_loss = 1.6875
06/22/2023 05:32:22 - INFO - __main__ -     test_acc=0.4103
06/22/2023 05:32:22 - INFO - __main__ -     ********************
06/22/2023 05:32:22 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:32:22 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:32:23 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:32:23 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:32:23 - INFO - __main__ -     Batch size = 16
06/22/2023 05:32:23 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:32:24 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:32:28 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:32:28 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:32:28 - INFO - __main__ -     Num batches = 107
06/22/2023 05:32:28 - INFO - __main__ -     Batch size = 16
06/22/2023 05:32:33 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:32:33 - INFO - __main__ -     eval_acc = 0.3686
06/22/2023 05:32:33 - INFO - __main__ -     eval_loss = 1.6965
06/22/2023 05:32:33 - INFO - __main__ -     test_acc=0.3686
06/22/2023 05:32:33 - INFO - __main__ -     ********************
06/22/2023 05:32:33 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:32:34 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:32:37 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:32:37 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:32:37 - INFO - __main__ -     Num batches = 88
06/22/2023 05:32:37 - INFO - __main__ -     Batch size = 16
06/22/2023 05:32:41 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:32:41 - INFO - __main__ -     eval_acc = 0.3826
06/22/2023 05:32:41 - INFO - __main__ -     eval_loss = 1.6348
06/22/2023 05:32:41 - INFO - __main__ -     test_acc=0.3826
06/22/2023 05:32:41 - INFO - __main__ -     ********************
06/22/2023 05:32:41 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:32:41 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:32:42 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:32:43 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:32:43 - INFO - __main__ -     Batch size = 16
06/22/2023 05:32:43 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:32:43 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:32:49 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:32:49 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:32:49 - INFO - __main__ -     Num batches = 171
06/22/2023 05:32:49 - INFO - __main__ -     Batch size = 16
06/22/2023 05:32:58 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:32:58 - INFO - __main__ -     eval_acc = 0.3693
06/22/2023 05:32:58 - INFO - __main__ -     eval_loss = 1.8677
06/22/2023 05:32:58 - INFO - __main__ -     test_acc=0.3693
06/22/2023 05:32:58 - INFO - __main__ -     ********************
06/22/2023 05:32:58 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:32:58 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:33:03 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:33:03 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:33:03 - INFO - __main__ -     Num batches = 171
06/22/2023 05:33:03 - INFO - __main__ -     Batch size = 16
06/22/2023 05:33:12 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:33:12 - INFO - __main__ -     eval_acc = 0.3843
06/22/2023 05:33:12 - INFO - __main__ -     eval_loss = 1.7953
06/22/2023 05:33:12 - INFO - __main__ -     test_acc=0.3843
06/22/2023 05:33:12 - INFO - __main__ -     ********************
06/22/2023 05:33:13 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:33:13 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:33:14 - INFO - __main__ -   Finish loading model [125M] from microsoft/codebert-base
06/22/2023 05:33:14 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:33:14 - INFO - __main__ -     Batch size = 16
06/22/2023 05:33:14 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:33:14 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:33:20 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:33:20 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:33:20 - INFO - __main__ -     Num batches = 171
06/22/2023 05:33:20 - INFO - __main__ -     Batch size = 16
06/22/2023 05:33:29 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:33:29 - INFO - __main__ -     eval_acc = 0.5465
06/22/2023 05:33:29 - INFO - __main__ -     eval_loss = 1.1078
06/22/2023 05:33:29 - INFO - __main__ -     test_acc=0.5465
06/22/2023 05:33:29 - INFO - __main__ -     ********************
06/22/2023 05:33:29 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:33:29 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codebert/clean/2/codebert_all_lr3_bs32_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:33:35 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:33:35 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:33:35 - INFO - __main__ -     Num batches = 171
06/22/2023 05:33:35 - INFO - __main__ -     Batch size = 16
06/22/2023 05:33:44 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:33:44 - INFO - __main__ -     eval_acc = 0.5253
06/22/2023 05:33:44 - INFO - __main__ -     eval_loss = 1.1447
06/22/2023 05:33:44 - INFO - __main__ -     test_acc=0.5253
06/22/2023 05:33:44 - INFO - __main__ -     ********************
06/22/2023 05:33:44 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:33:44 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:33:46 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50
06/22/2023 05:33:46 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:33:46 - INFO - __main__ -     Batch size = 16
06/22/2023 05:33:46 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:33:47 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:33:53 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:33:53 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:33:53 - INFO - __main__ -     Num batches = 171
06/22/2023 05:33:53 - INFO - __main__ -     Batch size = 16
06/22/2023 05:34:07 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:34:07 - INFO - __main__ -     eval_acc = 0.4425
06/22/2023 05:34:07 - INFO - __main__ -     eval_loss = 1.2089
06/22/2023 05:34:07 - INFO - __main__ -     test_acc=0.4425
06/22/2023 05:34:07 - INFO - __main__ -     ********************
06/22/2023 05:34:07 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:34:08 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:34:14 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:34:14 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:34:14 - INFO - __main__ -     Num batches = 171
06/22/2023 05:34:14 - INFO - __main__ -     Batch size = 16
06/22/2023 05:34:28 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:34:28 - INFO - __main__ -     eval_acc = 0.4436
06/22/2023 05:34:28 - INFO - __main__ -     eval_loss = 1.2253
06/22/2023 05:34:28 - INFO - __main__ -     test_acc=0.4436
06/22/2023 05:34:28 - INFO - __main__ -     ********************
06/22/2023 05:34:28 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:34:28 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:34:31 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:34:31 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:34:31 - INFO - __main__ -     Batch size = 16
06/22/2023 05:34:31 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:34:31 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:34:35 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:34:35 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:34:35 - INFO - __main__ -     Num batches = 107
06/22/2023 05:34:35 - INFO - __main__ -     Batch size = 16
06/22/2023 05:34:45 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:34:45 - INFO - __main__ -     eval_acc = 0.4203
06/22/2023 05:34:45 - INFO - __main__ -     eval_loss = 1.2642
06/22/2023 05:34:45 - INFO - __main__ -     test_acc=0.4203
06/22/2023 05:34:45 - INFO - __main__ -     ********************
06/22/2023 05:34:45 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:34:45 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:34:48 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:34:48 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:34:48 - INFO - __main__ -     Num batches = 88
06/22/2023 05:34:48 - INFO - __main__ -     Batch size = 16
06/22/2023 05:34:56 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:34:56 - INFO - __main__ -     eval_acc = 0.4128
06/22/2023 05:34:56 - INFO - __main__ -     eval_loss = 1.298
06/22/2023 05:34:56 - INFO - __main__ -     test_acc=0.4128
06/22/2023 05:34:56 - INFO - __main__ -     ********************
06/22/2023 05:34:56 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:34:56 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:34:58 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:34:58 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:34:58 - INFO - __main__ -     Batch size = 16
06/22/2023 05:34:58 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:34:59 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:35:05 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:35:05 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:35:05 - INFO - __main__ -     Num batches = 171
06/22/2023 05:35:05 - INFO - __main__ -     Batch size = 16
06/22/2023 05:35:19 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:35:19 - INFO - __main__ -     eval_acc = 0.4169
06/22/2023 05:35:19 - INFO - __main__ -     eval_loss = 1.3201
06/22/2023 05:35:19 - INFO - __main__ -     test_acc=0.4169
06/22/2023 05:35:19 - INFO - __main__ -     ********************
06/22/2023 05:35:19 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:35:20 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:35:26 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:35:26 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:35:26 - INFO - __main__ -     Num batches = 171
06/22/2023 05:35:26 - INFO - __main__ -     Batch size = 16
06/22/2023 05:35:40 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:35:40 - INFO - __main__ -     eval_acc = 0.429
06/22/2023 05:35:40 - INFO - __main__ -     eval_loss = 1.2656
06/22/2023 05:35:40 - INFO - __main__ -     test_acc=0.4290
06/22/2023 05:35:40 - INFO - __main__ -     ********************
06/22/2023 05:35:40 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:35:40 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:35:43 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:35:43 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:35:43 - INFO - __main__ -     Batch size = 16
06/22/2023 05:35:43 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:35:44 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:35:49 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:35:49 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:35:49 - INFO - __main__ -     Num batches = 171
06/22/2023 05:35:49 - INFO - __main__ -     Batch size = 16
06/22/2023 05:36:04 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:36:04 - INFO - __main__ -     eval_acc = 0.5688
06/22/2023 05:36:04 - INFO - __main__ -     eval_loss = 0.9649
06/22/2023 05:36:04 - INFO - __main__ -     test_acc=0.5688
06/22/2023 05:36:04 - INFO - __main__ -     ********************
06/22/2023 05:36:04 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:36:04 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:36:10 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:36:10 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:36:10 - INFO - __main__ -     Num batches = 171
06/22/2023 05:36:10 - INFO - __main__ -     Batch size = 16
06/22/2023 05:36:25 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:36:25 - INFO - __main__ -     eval_acc = 0.5256
06/22/2023 05:36:25 - INFO - __main__ -     eval_loss = 1.0264
06/22/2023 05:36:25 - INFO - __main__ -     test_acc=0.5256
06/22/2023 05:36:25 - INFO - __main__ -     ********************
06/22/2023 05:36:25 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:36:25 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:36:27 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50
06/22/2023 05:36:27 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:36:27 - INFO - __main__ -     Batch size = 16
06/22/2023 05:36:27 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:36:28 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:36:34 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:36:34 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:36:34 - INFO - __main__ -     Num batches = 171
06/22/2023 05:36:34 - INFO - __main__ -     Batch size = 16
06/22/2023 05:36:49 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:36:49 - INFO - __main__ -     eval_acc = 0.4081
06/22/2023 05:36:49 - INFO - __main__ -     eval_loss = 1.2506
06/22/2023 05:36:49 - INFO - __main__ -     test_acc=0.4081
06/22/2023 05:36:49 - INFO - __main__ -     ********************
06/22/2023 05:36:49 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:36:49 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:36:55 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:36:55 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:36:55 - INFO - __main__ -     Num batches = 171
06/22/2023 05:36:55 - INFO - __main__ -     Batch size = 16
06/22/2023 05:37:10 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:37:10 - INFO - __main__ -     eval_acc = 0.4125
06/22/2023 05:37:10 - INFO - __main__ -     eval_loss = 1.2459
06/22/2023 05:37:10 - INFO - __main__ -     test_acc=0.4125
06/22/2023 05:37:10 - INFO - __main__ -     ********************
06/22/2023 05:37:10 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:37:10 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:37:12 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:37:12 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:37:12 - INFO - __main__ -     Batch size = 16
06/22/2023 05:37:12 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:37:13 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:37:17 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:37:17 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:37:17 - INFO - __main__ -     Num batches = 107
06/22/2023 05:37:17 - INFO - __main__ -     Batch size = 16
06/22/2023 05:37:26 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:37:26 - INFO - __main__ -     eval_acc = 0.3892
06/22/2023 05:37:26 - INFO - __main__ -     eval_loss = 1.2999
06/22/2023 05:37:26 - INFO - __main__ -     test_acc=0.3892
06/22/2023 05:37:26 - INFO - __main__ -     ********************
06/22/2023 05:37:26 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:37:26 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:37:30 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:37:30 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:37:30 - INFO - __main__ -     Num batches = 88
06/22/2023 05:37:30 - INFO - __main__ -     Batch size = 16
06/22/2023 05:37:37 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:37:37 - INFO - __main__ -     eval_acc = 0.3898
06/22/2023 05:37:37 - INFO - __main__ -     eval_loss = 1.2728
06/22/2023 05:37:37 - INFO - __main__ -     test_acc=0.3898
06/22/2023 05:37:37 - INFO - __main__ -     ********************
06/22/2023 05:37:37 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:37:37 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:37:40 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:37:40 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:37:40 - INFO - __main__ -     Batch size = 16
06/22/2023 05:37:40 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:37:40 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:37:46 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:37:46 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:37:46 - INFO - __main__ -     Num batches = 171
06/22/2023 05:37:46 - INFO - __main__ -     Batch size = 16
06/22/2023 05:38:01 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:38:01 - INFO - __main__ -     eval_acc = 0.3858
06/22/2023 05:38:01 - INFO - __main__ -     eval_loss = 1.3416
06/22/2023 05:38:01 - INFO - __main__ -     test_acc=0.3858
06/22/2023 05:38:01 - INFO - __main__ -     ********************
06/22/2023 05:38:01 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:38:01 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:38:07 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:38:07 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:38:07 - INFO - __main__ -     Num batches = 171
06/22/2023 05:38:07 - INFO - __main__ -     Batch size = 16
06/22/2023 05:38:22 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:38:22 - INFO - __main__ -     eval_acc = 0.4041
06/22/2023 05:38:22 - INFO - __main__ -     eval_loss = 1.2969
06/22/2023 05:38:22 - INFO - __main__ -     test_acc=0.4041
06/22/2023 05:38:22 - INFO - __main__ -     ********************
06/22/2023 05:38:22 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:38:22 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:38:24 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:38:24 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:38:24 - INFO - __main__ -     Batch size = 16
06/22/2023 05:38:24 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:38:25 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:38:31 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:38:31 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:38:31 - INFO - __main__ -     Num batches = 171
06/22/2023 05:38:31 - INFO - __main__ -     Batch size = 16
06/22/2023 05:38:45 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:38:45 - INFO - __main__ -     eval_acc = 0.5619
06/22/2023 05:38:45 - INFO - __main__ -     eval_loss = 0.8947
06/22/2023 05:38:45 - INFO - __main__ -     test_acc=0.5619
06/22/2023 05:38:45 - INFO - __main__ -     ********************
06/22/2023 05:38:45 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:38:46 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:38:52 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:38:52 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:38:52 - INFO - __main__ -     Num batches = 171
06/22/2023 05:38:52 - INFO - __main__ -     Batch size = 16
06/22/2023 05:39:06 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:39:06 - INFO - __main__ -     eval_acc = 0.5531
06/22/2023 05:39:06 - INFO - __main__ -     eval_loss = 0.9238
06/22/2023 05:39:06 - INFO - __main__ -     test_acc=0.5531
06/22/2023 05:39:06 - INFO - __main__ -     ********************
06/22/2023 05:39:06 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:39:06 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:39:09 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50
06/22/2023 05:39:09 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:39:09 - INFO - __main__ -     Batch size = 16
06/22/2023 05:39:09 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:39:10 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:39:15 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:39:15 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:39:15 - INFO - __main__ -     Num batches = 171
06/22/2023 05:39:15 - INFO - __main__ -     Batch size = 16
06/22/2023 05:39:30 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:39:30 - INFO - __main__ -     eval_acc = 0.4026
06/22/2023 05:39:30 - INFO - __main__ -     eval_loss = 1.1541
06/22/2023 05:39:30 - INFO - __main__ -     test_acc=0.4026
06/22/2023 05:39:30 - INFO - __main__ -     ********************
06/22/2023 05:39:30 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:39:31 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:39:36 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:39:36 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:39:36 - INFO - __main__ -     Num batches = 171
06/22/2023 05:39:36 - INFO - __main__ -     Batch size = 16
06/22/2023 05:39:51 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:39:51 - INFO - __main__ -     eval_acc = 0.4092
06/22/2023 05:39:51 - INFO - __main__ -     eval_loss = 1.1637
06/22/2023 05:39:51 - INFO - __main__ -     test_acc=0.4092
06/22/2023 05:39:51 - INFO - __main__ -     ********************
06/22/2023 05:39:51 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:39:51 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:39:54 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:39:54 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:39:54 - INFO - __main__ -     Batch size = 16
06/22/2023 05:39:54 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:39:54 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:39:58 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:39:58 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:39:58 - INFO - __main__ -     Num batches = 107
06/22/2023 05:39:58 - INFO - __main__ -     Batch size = 16
06/22/2023 05:40:07 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:40:07 - INFO - __main__ -     eval_acc = 0.371
06/22/2023 05:40:07 - INFO - __main__ -     eval_loss = 1.2036
06/22/2023 05:40:07 - INFO - __main__ -     test_acc=0.3710
06/22/2023 05:40:07 - INFO - __main__ -     ********************
06/22/2023 05:40:07 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:40:08 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:40:11 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:40:11 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:40:11 - INFO - __main__ -     Num batches = 88
06/22/2023 05:40:11 - INFO - __main__ -     Batch size = 16
06/22/2023 05:40:18 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:40:18 - INFO - __main__ -     eval_acc = 0.3819
06/22/2023 05:40:18 - INFO - __main__ -     eval_loss = 1.1877
06/22/2023 05:40:18 - INFO - __main__ -     test_acc=0.3819
06/22/2023 05:40:18 - INFO - __main__ -     ********************
06/22/2023 05:40:18 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:40:18 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:40:21 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:40:21 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:40:21 - INFO - __main__ -     Batch size = 16
06/22/2023 05:40:21 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:40:21 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:40:27 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:40:27 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:40:27 - INFO - __main__ -     Num batches = 171
06/22/2023 05:40:27 - INFO - __main__ -     Batch size = 16
06/22/2023 05:40:42 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:40:42 - INFO - __main__ -     eval_acc = 0.3646
06/22/2023 05:40:42 - INFO - __main__ -     eval_loss = 1.2401
06/22/2023 05:40:42 - INFO - __main__ -     test_acc=0.3646
06/22/2023 05:40:42 - INFO - __main__ -     ********************
06/22/2023 05:40:42 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:40:42 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:40:48 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:40:48 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:40:48 - INFO - __main__ -     Num batches = 171
06/22/2023 05:40:48 - INFO - __main__ -     Batch size = 16
06/22/2023 05:41:03 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:41:03 - INFO - __main__ -     eval_acc = 0.381
06/22/2023 05:41:03 - INFO - __main__ -     eval_loss = 1.192
06/22/2023 05:41:03 - INFO - __main__ -     test_acc=0.3810
06/22/2023 05:41:03 - INFO - __main__ -     ********************
06/22/2023 05:41:03 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:41:03 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:41:05 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:41:06 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:41:06 - INFO - __main__ -     Batch size = 16
06/22/2023 05:41:06 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:41:06 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:41:12 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:41:12 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:41:12 - INFO - __main__ -     Num batches = 171
06/22/2023 05:41:12 - INFO - __main__ -     Batch size = 16
06/22/2023 05:41:27 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:41:27 - INFO - __main__ -     eval_acc = 0.5512
06/22/2023 05:41:27 - INFO - __main__ -     eval_loss = 0.8599
06/22/2023 05:41:27 - INFO - __main__ -     test_acc=0.5512
06/22/2023 05:41:27 - INFO - __main__ -     ********************
06/22/2023 05:41:27 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:41:27 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:41:33 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:41:33 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:41:33 - INFO - __main__ -     Num batches = 171
06/22/2023 05:41:33 - INFO - __main__ -     Batch size = 16
06/22/2023 05:41:48 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:41:48 - INFO - __main__ -     eval_acc = 0.5454
06/22/2023 05:41:48 - INFO - __main__ -     eval_loss = 0.8892
06/22/2023 05:41:48 - INFO - __main__ -     test_acc=0.5454
06/22/2023 05:41:48 - INFO - __main__ -     ********************
06/22/2023 05:41:48 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:41:48 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:41:50 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50
06/22/2023 05:41:50 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:41:50 - INFO - __main__ -     Batch size = 16
06/22/2023 05:41:50 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:41:51 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:41:56 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:41:56 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:41:56 - INFO - __main__ -     Num batches = 171
06/22/2023 05:41:56 - INFO - __main__ -     Batch size = 16
06/22/2023 05:42:11 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:42:11 - INFO - __main__ -     eval_acc = 0.4026
06/22/2023 05:42:11 - INFO - __main__ -     eval_loss = 1.8998
06/22/2023 05:42:11 - INFO - __main__ -     test_acc=0.4026
06/22/2023 05:42:11 - INFO - __main__ -     ********************
06/22/2023 05:42:11 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:42:11 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:42:18 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:42:18 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:42:18 - INFO - __main__ -     Num batches = 171
06/22/2023 05:42:18 - INFO - __main__ -     Batch size = 16
06/22/2023 05:42:32 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:42:32 - INFO - __main__ -     eval_acc = 0.4122
06/22/2023 05:42:32 - INFO - __main__ -     eval_loss = 1.9102
06/22/2023 05:42:32 - INFO - __main__ -     test_acc=0.4122
06/22/2023 05:42:32 - INFO - __main__ -     ********************
06/22/2023 05:42:32 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:42:32 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:42:35 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:42:35 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:42:35 - INFO - __main__ -     Batch size = 16
06/22/2023 05:42:35 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:42:35 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:42:39 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:42:39 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:42:39 - INFO - __main__ -     Num batches = 107
06/22/2023 05:42:39 - INFO - __main__ -     Batch size = 16
06/22/2023 05:42:48 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:42:48 - INFO - __main__ -     eval_acc = 0.3815
06/22/2023 05:42:48 - INFO - __main__ -     eval_loss = 2.0235
06/22/2023 05:42:48 - INFO - __main__ -     test_acc=0.3815
06/22/2023 05:42:48 - INFO - __main__ -     ********************
06/22/2023 05:42:48 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:42:49 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:42:52 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:42:52 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:42:52 - INFO - __main__ -     Num batches = 88
06/22/2023 05:42:52 - INFO - __main__ -     Batch size = 16
06/22/2023 05:42:59 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:42:59 - INFO - __main__ -     eval_acc = 0.3798
06/22/2023 05:42:59 - INFO - __main__ -     eval_loss = 2.0268
06/22/2023 05:42:59 - INFO - __main__ -     test_acc=0.3798
06/22/2023 05:42:59 - INFO - __main__ -     ********************
06/22/2023 05:42:59 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:42:59 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:43:02 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:43:02 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:43:02 - INFO - __main__ -     Batch size = 16
06/22/2023 05:43:02 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:43:02 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:43:08 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:43:08 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:43:08 - INFO - __main__ -     Num batches = 171
06/22/2023 05:43:08 - INFO - __main__ -     Batch size = 16
06/22/2023 05:43:23 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:43:23 - INFO - __main__ -     eval_acc = 0.3635
06/22/2023 05:43:23 - INFO - __main__ -     eval_loss = 2.1211
06/22/2023 05:43:23 - INFO - __main__ -     test_acc=0.3635
06/22/2023 05:43:23 - INFO - __main__ -     ********************
06/22/2023 05:43:23 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:43:23 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:43:29 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:43:29 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:43:29 - INFO - __main__ -     Num batches = 171
06/22/2023 05:43:29 - INFO - __main__ -     Batch size = 16
06/22/2023 05:43:44 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:43:44 - INFO - __main__ -     eval_acc = 0.3847
06/22/2023 05:43:44 - INFO - __main__ -     eval_loss = 2.036
06/22/2023 05:43:44 - INFO - __main__ -     test_acc=0.3847
06/22/2023 05:43:44 - INFO - __main__ -     ********************
06/22/2023 05:43:44 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:43:44 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:43:46 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:43:46 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:43:46 - INFO - __main__ -     Batch size = 16
06/22/2023 05:43:46 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:43:47 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:43:53 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:43:53 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:43:53 - INFO - __main__ -     Num batches = 171
06/22/2023 05:43:53 - INFO - __main__ -     Batch size = 16
06/22/2023 05:44:07 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:44:07 - INFO - __main__ -     eval_acc = 0.5534
06/22/2023 05:44:07 - INFO - __main__ -     eval_loss = 1.3258
06/22/2023 05:44:07 - INFO - __main__ -     test_acc=0.5534
06/22/2023 05:44:07 - INFO - __main__ -     ********************
06/22/2023 05:44:07 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:44:08 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:44:14 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:44:14 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:44:14 - INFO - __main__ -     Num batches = 171
06/22/2023 05:44:14 - INFO - __main__ -     Batch size = 16
06/22/2023 05:44:28 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:44:28 - INFO - __main__ -     eval_acc = 0.5406
06/22/2023 05:44:28 - INFO - __main__ -     eval_loss = 1.3533
06/22/2023 05:44:28 - INFO - __main__ -     test_acc=0.5406
06/22/2023 05:44:28 - INFO - __main__ -     ********************
06/22/2023 05:44:28 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:44:28 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:44:31 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50
06/22/2023 05:44:31 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:44:31 - INFO - __main__ -     Batch size = 16
06/22/2023 05:44:31 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:44:31 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:44:37 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:44:37 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:44:37 - INFO - __main__ -     Num batches = 171
06/22/2023 05:44:37 - INFO - __main__ -     Batch size = 16
06/22/2023 05:44:52 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:44:52 - INFO - __main__ -     eval_acc = 0.3887
06/22/2023 05:44:52 - INFO - __main__ -     eval_loss = 1.4209
06/22/2023 05:44:52 - INFO - __main__ -     test_acc=0.3887
06/22/2023 05:44:52 - INFO - __main__ -     ********************
06/22/2023 05:44:52 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:44:52 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:44:58 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:44:58 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:44:58 - INFO - __main__ -     Num batches = 171
06/22/2023 05:44:58 - INFO - __main__ -     Batch size = 16
06/22/2023 05:45:13 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:45:13 - INFO - __main__ -     eval_acc = 0.4045
06/22/2023 05:45:13 - INFO - __main__ -     eval_loss = 1.398
06/22/2023 05:45:13 - INFO - __main__ -     test_acc=0.4045
06/22/2023 05:45:13 - INFO - __main__ -     ********************
06/22/2023 05:45:13 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:45:13 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:45:16 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:45:16 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:45:16 - INFO - __main__ -     Batch size = 16
06/22/2023 05:45:16 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:45:16 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:45:20 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:45:20 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:45:20 - INFO - __main__ -     Num batches = 107
06/22/2023 05:45:20 - INFO - __main__ -     Batch size = 16
06/22/2023 05:45:29 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:45:29 - INFO - __main__ -     eval_acc = 0.3633
06/22/2023 05:45:29 - INFO - __main__ -     eval_loss = 1.4739
06/22/2023 05:45:29 - INFO - __main__ -     test_acc=0.3633
06/22/2023 05:45:29 - INFO - __main__ -     ********************
06/22/2023 05:45:29 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:45:30 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:45:33 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:45:33 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:45:33 - INFO - __main__ -     Num batches = 88
06/22/2023 05:45:33 - INFO - __main__ -     Batch size = 16
06/22/2023 05:45:40 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:45:40 - INFO - __main__ -     eval_acc = 0.3877
06/22/2023 05:45:40 - INFO - __main__ -     eval_loss = 1.435
06/22/2023 05:45:40 - INFO - __main__ -     test_acc=0.3877
06/22/2023 05:45:40 - INFO - __main__ -     ********************
06/22/2023 05:45:40 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:45:40 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:45:43 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:45:43 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:45:43 - INFO - __main__ -     Batch size = 16
06/22/2023 05:45:43 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:45:43 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:45:49 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:45:49 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:45:49 - INFO - __main__ -     Num batches = 171
06/22/2023 05:45:49 - INFO - __main__ -     Batch size = 16
06/22/2023 05:46:04 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:46:04 - INFO - __main__ -     eval_acc = 0.3649
06/22/2023 05:46:04 - INFO - __main__ -     eval_loss = 1.5312
06/22/2023 05:46:04 - INFO - __main__ -     test_acc=0.3649
06/22/2023 05:46:04 - INFO - __main__ -     ********************
06/22/2023 05:46:04 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:46:04 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:46:10 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:46:10 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:46:10 - INFO - __main__ -     Num batches = 171
06/22/2023 05:46:10 - INFO - __main__ -     Batch size = 16
06/22/2023 05:46:25 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:46:25 - INFO - __main__ -     eval_acc = 0.384
06/22/2023 05:46:25 - INFO - __main__ -     eval_loss = 1.4641
06/22/2023 05:46:25 - INFO - __main__ -     test_acc=0.3840
06/22/2023 05:46:25 - INFO - __main__ -     ********************
06/22/2023 05:46:25 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:46:25 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:46:27 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:46:27 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:46:27 - INFO - __main__ -     Batch size = 16
06/22/2023 05:46:27 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:46:28 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:46:34 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:46:34 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:46:34 - INFO - __main__ -     Num batches = 171
06/22/2023 05:46:34 - INFO - __main__ -     Batch size = 16
06/22/2023 05:46:49 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:46:49 - INFO - __main__ -     eval_acc = 0.5469
06/22/2023 05:46:49 - INFO - __main__ -     eval_loss = 0.9807
06/22/2023 05:46:49 - INFO - __main__ -     test_acc=0.5469
06/22/2023 05:46:49 - INFO - __main__ -     ********************
06/22/2023 05:46:49 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:46:49 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:46:55 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:46:55 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:46:55 - INFO - __main__ -     Num batches = 171
06/22/2023 05:46:55 - INFO - __main__ -     Batch size = 16
06/22/2023 05:47:09 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:47:09 - INFO - __main__ -     eval_acc = 0.549
06/22/2023 05:47:09 - INFO - __main__ -     eval_loss = 0.9979
06/22/2023 05:47:09 - INFO - __main__ -     test_acc=0.5490
06/22/2023 05:47:09 - INFO - __main__ -     ********************
06/22/2023 05:47:10 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:47:10 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:47:12 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50
06/22/2023 05:47:12 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:47:12 - INFO - __main__ -     Batch size = 16
06/22/2023 05:47:12 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:47:12 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:47:18 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:47:18 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:47:18 - INFO - __main__ -     Num batches = 171
06/22/2023 05:47:18 - INFO - __main__ -     Batch size = 16
06/22/2023 05:47:33 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:47:33 - INFO - __main__ -     eval_acc = 0.3949
06/22/2023 05:47:33 - INFO - __main__ -     eval_loss = 1.3232
06/22/2023 05:47:33 - INFO - __main__ -     test_acc=0.3949
06/22/2023 05:47:33 - INFO - __main__ -     ********************
06/22/2023 05:47:33 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:47:34 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:47:39 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:47:39 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:47:39 - INFO - __main__ -     Num batches = 171
06/22/2023 05:47:39 - INFO - __main__ -     Batch size = 16
06/22/2023 05:47:54 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:47:54 - INFO - __main__ -     eval_acc = 0.4019
06/22/2023 05:47:54 - INFO - __main__ -     eval_loss = 1.2961
06/22/2023 05:47:54 - INFO - __main__ -     test_acc=0.4019
06/22/2023 05:47:54 - INFO - __main__ -     ********************
06/22/2023 05:47:54 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:47:54 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:47:57 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:47:57 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:47:57 - INFO - __main__ -     Batch size = 16
06/22/2023 05:47:57 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:47:57 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:48:01 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:48:01 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:48:01 - INFO - __main__ -     Num batches = 107
06/22/2023 05:48:01 - INFO - __main__ -     Batch size = 16
06/22/2023 05:48:10 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:48:10 - INFO - __main__ -     eval_acc = 0.3674
06/22/2023 05:48:10 - INFO - __main__ -     eval_loss = 1.3934
06/22/2023 05:48:10 - INFO - __main__ -     test_acc=0.3674
06/22/2023 05:48:10 - INFO - __main__ -     ********************
06/22/2023 05:48:10 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:48:11 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:48:14 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:48:14 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:48:14 - INFO - __main__ -     Num batches = 88
06/22/2023 05:48:14 - INFO - __main__ -     Batch size = 16
06/22/2023 05:48:21 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:48:21 - INFO - __main__ -     eval_acc = 0.3704
06/22/2023 05:48:21 - INFO - __main__ -     eval_loss = 1.3794
06/22/2023 05:48:21 - INFO - __main__ -     test_acc=0.3704
06/22/2023 05:48:21 - INFO - __main__ -     ********************
06/22/2023 05:48:21 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:48:21 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:48:24 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:48:24 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:48:24 - INFO - __main__ -     Batch size = 16
06/22/2023 05:48:24 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:48:24 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:48:30 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:48:30 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:48:30 - INFO - __main__ -     Num batches = 171
06/22/2023 05:48:30 - INFO - __main__ -     Batch size = 16
06/22/2023 05:48:45 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:48:45 - INFO - __main__ -     eval_acc = 0.373
06/22/2023 05:48:45 - INFO - __main__ -     eval_loss = 1.4227
06/22/2023 05:48:45 - INFO - __main__ -     test_acc=0.3730
06/22/2023 05:48:45 - INFO - __main__ -     ********************
06/22/2023 05:48:45 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:48:45 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:48:51 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:48:51 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:48:51 - INFO - __main__ -     Num batches = 171
06/22/2023 05:48:51 - INFO - __main__ -     Batch size = 16
06/22/2023 05:49:06 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:49:06 - INFO - __main__ -     eval_acc = 0.3814
06/22/2023 05:49:06 - INFO - __main__ -     eval_loss = 1.3743
06/22/2023 05:49:06 - INFO - __main__ -     test_acc=0.3814
06/22/2023 05:49:06 - INFO - __main__ -     ********************
06/22/2023 05:49:06 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:49:06 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:49:08 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:49:08 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:49:08 - INFO - __main__ -     Batch size = 16
06/22/2023 05:49:08 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:49:09 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:49:15 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:49:15 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:49:15 - INFO - __main__ -     Num batches = 171
06/22/2023 05:49:15 - INFO - __main__ -     Batch size = 16
06/22/2023 05:49:29 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:49:29 - INFO - __main__ -     eval_acc = 0.548
06/22/2023 05:49:29 - INFO - __main__ -     eval_loss = 0.9211
06/22/2023 05:49:29 - INFO - __main__ -     test_acc=0.5480
06/22/2023 05:49:29 - INFO - __main__ -     ********************
06/22/2023 05:49:29 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:49:30 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/1/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:49:36 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:49:36 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:49:36 - INFO - __main__ -     Num batches = 171
06/22/2023 05:49:36 - INFO - __main__ -     Batch size = 16
06/22/2023 05:49:50 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:49:50 - INFO - __main__ -     eval_acc = 0.5469
06/22/2023 05:49:50 - INFO - __main__ -     eval_loss = 0.9283
06/22/2023 05:49:50 - INFO - __main__ -     test_acc=0.5469
06/22/2023 05:49:50 - INFO - __main__ -     ********************
06/22/2023 05:49:50 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:49:50 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:49:53 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50
06/22/2023 05:49:53 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:49:53 - INFO - __main__ -     Batch size = 16
06/22/2023 05:49:53 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:49:53 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:49:59 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:49:59 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:49:59 - INFO - __main__ -     Num batches = 171
06/22/2023 05:49:59 - INFO - __main__ -     Batch size = 16
06/22/2023 05:50:14 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:50:14 - INFO - __main__ -     eval_acc = 0.388
06/22/2023 05:50:14 - INFO - __main__ -     eval_loss = 1.4664
06/22/2023 05:50:14 - INFO - __main__ -     test_acc=0.3880
06/22/2023 05:50:14 - INFO - __main__ -     ********************
06/22/2023 05:50:14 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:50:14 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:50:20 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:50:20 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:50:20 - INFO - __main__ -     Num batches = 171
06/22/2023 05:50:20 - INFO - __main__ -     Batch size = 16
06/22/2023 05:50:35 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:50:35 - INFO - __main__ -     eval_acc = 0.4045
06/22/2023 05:50:35 - INFO - __main__ -     eval_loss = 1.4252
06/22/2023 05:50:35 - INFO - __main__ -     test_acc=0.4045
06/22/2023 05:50:35 - INFO - __main__ -     ********************
06/22/2023 05:50:35 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:50:35 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:50:37 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:50:37 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:50:37 - INFO - __main__ -     Batch size = 16
06/22/2023 05:50:37 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:50:38 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:50:42 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:50:42 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:50:42 - INFO - __main__ -     Num batches = 107
06/22/2023 05:50:42 - INFO - __main__ -     Batch size = 16
06/22/2023 05:50:51 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:50:51 - INFO - __main__ -     eval_acc = 0.3868
06/22/2023 05:50:51 - INFO - __main__ -     eval_loss = 1.5622
06/22/2023 05:50:51 - INFO - __main__ -     test_acc=0.3868
06/22/2023 05:50:51 - INFO - __main__ -     ********************
06/22/2023 05:50:51 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:50:51 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:50:54 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:50:54 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:50:54 - INFO - __main__ -     Num batches = 88
06/22/2023 05:50:54 - INFO - __main__ -     Batch size = 16
06/22/2023 05:51:02 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:51:02 - INFO - __main__ -     eval_acc = 0.3747
06/22/2023 05:51:02 - INFO - __main__ -     eval_loss = 1.5124
06/22/2023 05:51:02 - INFO - __main__ -     test_acc=0.3747
06/22/2023 05:51:02 - INFO - __main__ -     ********************
06/22/2023 05:51:02 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:51:02 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:51:04 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:51:05 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:51:05 - INFO - __main__ -     Batch size = 16
06/22/2023 05:51:05 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:51:05 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:51:11 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:51:11 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:51:11 - INFO - __main__ -     Num batches = 171
06/22/2023 05:51:11 - INFO - __main__ -     Batch size = 16
06/22/2023 05:51:25 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:51:25 - INFO - __main__ -     eval_acc = 0.3635
06/22/2023 05:51:25 - INFO - __main__ -     eval_loss = 1.6007
06/22/2023 05:51:25 - INFO - __main__ -     test_acc=0.3635
06/22/2023 05:51:25 - INFO - __main__ -     ********************
06/22/2023 05:51:25 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:51:26 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:51:32 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:51:32 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:51:32 - INFO - __main__ -     Num batches = 171
06/22/2023 05:51:32 - INFO - __main__ -     Batch size = 16
06/22/2023 05:51:46 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:51:46 - INFO - __main__ -     eval_acc = 0.3613
06/22/2023 05:51:46 - INFO - __main__ -     eval_loss = 1.5613
06/22/2023 05:51:46 - INFO - __main__ -     test_acc=0.3613
06/22/2023 05:51:46 - INFO - __main__ -     ********************
06/22/2023 05:51:47 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:51:47 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:51:49 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:51:49 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:51:49 - INFO - __main__ -     Batch size = 16
06/22/2023 05:51:49 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:51:50 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:51:55 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:51:55 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:51:55 - INFO - __main__ -     Num batches = 171
06/22/2023 05:51:55 - INFO - __main__ -     Batch size = 16
06/22/2023 05:52:10 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:52:10 - INFO - __main__ -     eval_acc = 0.5593
06/22/2023 05:52:10 - INFO - __main__ -     eval_loss = 0.9708
06/22/2023 05:52:10 - INFO - __main__ -     test_acc=0.5593
06/22/2023 05:52:10 - INFO - __main__ -     ********************
06/22/2023 05:52:10 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:52:11 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:52:16 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:52:16 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:52:16 - INFO - __main__ -     Num batches = 171
06/22/2023 05:52:16 - INFO - __main__ -     Batch size = 16
06/22/2023 05:52:31 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:52:31 - INFO - __main__ -     eval_acc = 0.5307
06/22/2023 05:52:31 - INFO - __main__ -     eval_loss = 1.0155
06/22/2023 05:52:31 - INFO - __main__ -     test_acc=0.5307
06/22/2023 05:52:31 - INFO - __main__ -     ********************
06/22/2023 05:52:31 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:52:31 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:52:33 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50
06/22/2023 05:52:34 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:52:34 - INFO - __main__ -     Batch size = 16
06/22/2023 05:52:34 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:52:34 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:52:40 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:52:40 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:52:40 - INFO - __main__ -     Num batches = 171
06/22/2023 05:52:40 - INFO - __main__ -     Batch size = 16
06/22/2023 05:52:55 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:52:55 - INFO - __main__ -     eval_acc = 0.3979
06/22/2023 05:52:55 - INFO - __main__ -     eval_loss = 1.5975
06/22/2023 05:52:55 - INFO - __main__ -     test_acc=0.3979
06/22/2023 05:52:55 - INFO - __main__ -     ********************
06/22/2023 05:52:55 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:52:55 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:53:01 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:53:01 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:53:01 - INFO - __main__ -     Num batches = 171
06/22/2023 05:53:01 - INFO - __main__ -     Batch size = 16
06/22/2023 05:53:16 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:53:16 - INFO - __main__ -     eval_acc = 0.4125
06/22/2023 05:53:16 - INFO - __main__ -     eval_loss = 1.5697
06/22/2023 05:53:16 - INFO - __main__ -     test_acc=0.4125
06/22/2023 05:53:16 - INFO - __main__ -     ********************
06/22/2023 05:53:16 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:53:16 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:53:18 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:53:18 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:53:18 - INFO - __main__ -     Batch size = 16
06/22/2023 05:53:18 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:53:19 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:53:23 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:53:23 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:53:23 - INFO - __main__ -     Num batches = 107
06/22/2023 05:53:23 - INFO - __main__ -     Batch size = 16
06/22/2023 05:53:32 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:53:32 - INFO - __main__ -     eval_acc = 0.3933
06/22/2023 05:53:32 - INFO - __main__ -     eval_loss = 1.5972
06/22/2023 05:53:32 - INFO - __main__ -     test_acc=0.3933
06/22/2023 05:53:32 - INFO - __main__ -     ********************
06/22/2023 05:53:32 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:53:32 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:53:35 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:53:35 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:53:35 - INFO - __main__ -     Num batches = 88
06/22/2023 05:53:35 - INFO - __main__ -     Batch size = 16
06/22/2023 05:53:43 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:53:43 - INFO - __main__ -     eval_acc = 0.3891
06/22/2023 05:53:43 - INFO - __main__ -     eval_loss = 1.599
06/22/2023 05:53:43 - INFO - __main__ -     test_acc=0.3891
06/22/2023 05:53:43 - INFO - __main__ -     ********************
06/22/2023 05:53:43 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:53:43 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:53:45 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:53:45 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:53:45 - INFO - __main__ -     Batch size = 16
06/22/2023 05:53:45 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:53:46 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:53:52 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:53:52 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:53:52 - INFO - __main__ -     Num batches = 171
06/22/2023 05:53:52 - INFO - __main__ -     Batch size = 16
06/22/2023 05:54:07 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:54:07 - INFO - __main__ -     eval_acc = 0.3723
06/22/2023 05:54:07 - INFO - __main__ -     eval_loss = 1.7308
06/22/2023 05:54:07 - INFO - __main__ -     test_acc=0.3723
06/22/2023 05:54:07 - INFO - __main__ -     ********************
06/22/2023 05:54:07 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:54:07 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:54:13 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:54:13 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:54:13 - INFO - __main__ -     Num batches = 171
06/22/2023 05:54:13 - INFO - __main__ -     Batch size = 16
06/22/2023 05:54:27 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:54:27 - INFO - __main__ -     eval_acc = 0.3913
06/22/2023 05:54:27 - INFO - __main__ -     eval_loss = 1.6491
06/22/2023 05:54:27 - INFO - __main__ -     test_acc=0.3913
06/22/2023 05:54:27 - INFO - __main__ -     ********************
06/22/2023 05:54:28 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:54:28 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:54:30 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:54:30 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:54:30 - INFO - __main__ -     Batch size = 16
06/22/2023 05:54:30 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:54:30 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:54:36 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:54:36 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:54:36 - INFO - __main__ -     Num batches = 171
06/22/2023 05:54:36 - INFO - __main__ -     Batch size = 16
06/22/2023 05:54:51 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:54:51 - INFO - __main__ -     eval_acc = 0.5681
06/22/2023 05:54:51 - INFO - __main__ -     eval_loss = 1.03
06/22/2023 05:54:51 - INFO - __main__ -     test_acc=0.5681
06/22/2023 05:54:51 - INFO - __main__ -     ********************
06/22/2023 05:54:51 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:54:51 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:54:57 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:54:57 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:54:57 - INFO - __main__ -     Num batches = 171
06/22/2023 05:54:57 - INFO - __main__ -     Batch size = 16
06/22/2023 05:55:12 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:55:12 - INFO - __main__ -     eval_acc = 0.5458
06/22/2023 05:55:12 - INFO - __main__ -     eval_loss = 1.103
06/22/2023 05:55:12 - INFO - __main__ -     test_acc=0.5458
06/22/2023 05:55:12 - INFO - __main__ -     ********************
06/22/2023 05:55:12 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:55:12 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:55:14 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50
06/22/2023 05:55:15 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:55:15 - INFO - __main__ -     Batch size = 16
06/22/2023 05:55:15 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:55:15 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:55:21 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:55:21 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:55:21 - INFO - __main__ -     Num batches = 171
06/22/2023 05:55:21 - INFO - __main__ -     Batch size = 16
06/22/2023 05:55:36 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:55:36 - INFO - __main__ -     eval_acc = 0.4001
06/22/2023 05:55:36 - INFO - __main__ -     eval_loss = 1.443
06/22/2023 05:55:36 - INFO - __main__ -     test_acc=0.4001
06/22/2023 05:55:36 - INFO - __main__ -     ********************
06/22/2023 05:55:36 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:55:36 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:55:42 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:55:42 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:55:42 - INFO - __main__ -     Num batches = 171
06/22/2023 05:55:42 - INFO - __main__ -     Batch size = 16
06/22/2023 05:55:57 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:55:57 - INFO - __main__ -     eval_acc = 0.4081
06/22/2023 05:55:57 - INFO - __main__ -     eval_loss = 1.4232
06/22/2023 05:55:57 - INFO - __main__ -     test_acc=0.4081
06/22/2023 05:55:57 - INFO - __main__ -     ********************
06/22/2023 05:55:57 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:55:57 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:55:59 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:55:59 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:55:59 - INFO - __main__ -     Batch size = 16
06/22/2023 05:55:59 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:56:00 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:56:04 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:56:04 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:56:04 - INFO - __main__ -     Num batches = 107
06/22/2023 05:56:04 - INFO - __main__ -     Batch size = 16
06/22/2023 05:56:13 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:56:13 - INFO - __main__ -     eval_acc = 0.3868
06/22/2023 05:56:13 - INFO - __main__ -     eval_loss = 1.4892
06/22/2023 05:56:13 - INFO - __main__ -     test_acc=0.3868
06/22/2023 05:56:13 - INFO - __main__ -     ********************
06/22/2023 05:56:13 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:56:13 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:56:16 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:56:16 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:56:16 - INFO - __main__ -     Num batches = 88
06/22/2023 05:56:16 - INFO - __main__ -     Batch size = 16
06/22/2023 05:56:24 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:56:24 - INFO - __main__ -     eval_acc = 0.3833
06/22/2023 05:56:24 - INFO - __main__ -     eval_loss = 1.4602
06/22/2023 05:56:24 - INFO - __main__ -     test_acc=0.3833
06/22/2023 05:56:24 - INFO - __main__ -     ********************
06/22/2023 05:56:24 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:56:24 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:56:26 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:56:26 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:56:26 - INFO - __main__ -     Batch size = 16
06/22/2023 05:56:26 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:56:27 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:56:33 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:56:33 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:56:33 - INFO - __main__ -     Num batches = 171
06/22/2023 05:56:33 - INFO - __main__ -     Batch size = 16
06/22/2023 05:56:47 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:56:47 - INFO - __main__ -     eval_acc = 0.3646
06/22/2023 05:56:47 - INFO - __main__ -     eval_loss = 1.5735
06/22/2023 05:56:47 - INFO - __main__ -     test_acc=0.3646
06/22/2023 05:56:47 - INFO - __main__ -     ********************
06/22/2023 05:56:47 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:56:48 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:56:54 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:56:54 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:56:54 - INFO - __main__ -     Num batches = 171
06/22/2023 05:56:54 - INFO - __main__ -     Batch size = 16
06/22/2023 05:57:08 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:57:08 - INFO - __main__ -     eval_acc = 0.3986
06/22/2023 05:57:08 - INFO - __main__ -     eval_loss = 1.5114
06/22/2023 05:57:08 - INFO - __main__ -     test_acc=0.3986
06/22/2023 05:57:08 - INFO - __main__ -     ********************
06/22/2023 05:57:08 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:57:08 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:57:11 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:57:11 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:57:11 - INFO - __main__ -     Batch size = 16
06/22/2023 05:57:11 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:57:11 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:57:17 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:57:17 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:57:17 - INFO - __main__ -     Num batches = 171
06/22/2023 05:57:17 - INFO - __main__ -     Batch size = 16
06/22/2023 05:57:32 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:57:32 - INFO - __main__ -     eval_acc = 0.5593
06/22/2023 05:57:32 - INFO - __main__ -     eval_loss = 0.9983
06/22/2023 05:57:32 - INFO - __main__ -     test_acc=0.5593
06/22/2023 05:57:32 - INFO - __main__ -     ********************
06/22/2023 05:57:32 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:57:32 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 05:57:38 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:57:38 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:57:38 - INFO - __main__ -     Num batches = 171
06/22/2023 05:57:38 - INFO - __main__ -     Batch size = 16
06/22/2023 05:57:53 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:57:53 - INFO - __main__ -     eval_acc = 0.5439
06/22/2023 05:57:53 - INFO - __main__ -     eval_loss = 1.007
06/22/2023 05:57:53 - INFO - __main__ -     test_acc=0.5439
06/22/2023 05:57:53 - INFO - __main__ -     ********************
06/22/2023 05:57:53 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:57:53 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:57:55 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50
06/22/2023 05:57:55 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:57:55 - INFO - __main__ -     Batch size = 16
06/22/2023 05:57:55 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:57:56 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 05:58:02 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:58:02 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:58:02 - INFO - __main__ -     Num batches = 171
06/22/2023 05:58:02 - INFO - __main__ -     Batch size = 16
06/22/2023 05:58:16 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:58:16 - INFO - __main__ -     eval_acc = 0.3964
06/22/2023 05:58:16 - INFO - __main__ -     eval_loss = 1.4104
06/22/2023 05:58:16 - INFO - __main__ -     test_acc=0.3964
06/22/2023 05:58:16 - INFO - __main__ -     ********************
06/22/2023 05:58:16 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:58:17 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 05:58:23 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:58:23 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:58:23 - INFO - __main__ -     Num batches = 171
06/22/2023 05:58:23 - INFO - __main__ -     Batch size = 16
06/22/2023 05:58:37 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:58:37 - INFO - __main__ -     eval_acc = 0.4037
06/22/2023 05:58:37 - INFO - __main__ -     eval_loss = 1.3637
06/22/2023 05:58:37 - INFO - __main__ -     test_acc=0.4037
06/22/2023 05:58:37 - INFO - __main__ -     ********************
06/22/2023 05:58:37 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:58:37 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:58:40 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:58:40 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:58:40 - INFO - __main__ -     Batch size = 16
06/22/2023 05:58:40 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:58:40 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 05:58:44 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:58:44 - INFO - __main__ -     Num examples = 1701
06/22/2023 05:58:44 - INFO - __main__ -     Num batches = 107
06/22/2023 05:58:44 - INFO - __main__ -     Batch size = 16
06/22/2023 05:58:53 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:58:53 - INFO - __main__ -     eval_acc = 0.3715
06/22/2023 05:58:53 - INFO - __main__ -     eval_loss = 1.4658
06/22/2023 05:58:53 - INFO - __main__ -     test_acc=0.3715
06/22/2023 05:58:53 - INFO - __main__ -     ********************
06/22/2023 05:58:53 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:58:54 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 05:58:57 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:58:57 - INFO - __main__ -     Num examples = 1393
06/22/2023 05:58:57 - INFO - __main__ -     Num batches = 88
06/22/2023 05:58:57 - INFO - __main__ -     Batch size = 16
06/22/2023 05:59:04 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:59:04 - INFO - __main__ -     eval_acc = 0.3905
06/22/2023 05:59:04 - INFO - __main__ -     eval_loss = 1.4258
06/22/2023 05:59:04 - INFO - __main__ -     test_acc=0.3905
06/22/2023 05:59:04 - INFO - __main__ -     ********************
06/22/2023 05:59:05 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:59:05 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:59:07 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:59:07 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:59:07 - INFO - __main__ -     Batch size = 16
06/22/2023 05:59:07 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:59:07 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 05:59:13 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:59:13 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:59:13 - INFO - __main__ -     Num batches = 171
06/22/2023 05:59:13 - INFO - __main__ -     Batch size = 16
06/22/2023 05:59:28 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:59:28 - INFO - __main__ -     eval_acc = 0.3624
06/22/2023 05:59:28 - INFO - __main__ -     eval_loss = 1.5539
06/22/2023 05:59:28 - INFO - __main__ -     test_acc=0.3624
06/22/2023 05:59:28 - INFO - __main__ -     ********************
06/22/2023 05:59:28 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:59:28 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 05:59:34 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:59:34 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:59:34 - INFO - __main__ -     Num batches = 171
06/22/2023 05:59:34 - INFO - __main__ -     Batch size = 16
06/22/2023 05:59:49 - INFO - __main__ -   ***** Eval results *****
06/22/2023 05:59:49 - INFO - __main__ -     eval_acc = 0.3895
06/22/2023 05:59:49 - INFO - __main__ -     eval_loss = 1.4932
06/22/2023 05:59:49 - INFO - __main__ -     test_acc=0.3895
06/22/2023 05:59:49 - INFO - __main__ -     ********************
06/22/2023 05:59:49 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 05:59:49 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 05:59:51 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 05:59:51 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 05:59:51 - INFO - __main__ -     Batch size = 16
06/22/2023 05:59:51 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 05:59:52 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 05:59:58 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 05:59:58 - INFO - __main__ -     Num examples = 2732
06/22/2023 05:59:58 - INFO - __main__ -     Num batches = 171
06/22/2023 05:59:58 - INFO - __main__ -     Batch size = 16
06/22/2023 06:00:12 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:00:12 - INFO - __main__ -     eval_acc = 0.5516
06/22/2023 06:00:12 - INFO - __main__ -     eval_loss = 0.9719
06/22/2023 06:00:12 - INFO - __main__ -     test_acc=0.5516
06/22/2023 06:00:12 - INFO - __main__ -     ********************
06/22/2023 06:00:12 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:00:13 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:00:19 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:00:19 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:00:19 - INFO - __main__ -     Num batches = 171
06/22/2023 06:00:19 - INFO - __main__ -     Batch size = 16
06/22/2023 06:00:33 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:00:33 - INFO - __main__ -     eval_acc = 0.5399
06/22/2023 06:00:33 - INFO - __main__ -     eval_loss = 0.9922
06/22/2023 06:00:33 - INFO - __main__ -     test_acc=0.5399
06/22/2023 06:00:33 - INFO - __main__ -     ********************
06/22/2023 06:00:33 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:00:33 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:00:36 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50
06/22/2023 06:00:36 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:00:36 - INFO - __main__ -     Batch size = 16
06/22/2023 06:00:36 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:00:36 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:00:42 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:00:42 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:00:42 - INFO - __main__ -     Num batches = 171
06/22/2023 06:00:42 - INFO - __main__ -     Batch size = 16
06/22/2023 06:00:57 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:00:57 - INFO - __main__ -     eval_acc = 0.3975
06/22/2023 06:00:57 - INFO - __main__ -     eval_loss = 1.5116
06/22/2023 06:00:57 - INFO - __main__ -     test_acc=0.3975
06/22/2023 06:00:57 - INFO - __main__ -     ********************
06/22/2023 06:00:57 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:00:57 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:01:03 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:01:03 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:01:03 - INFO - __main__ -     Num batches = 171
06/22/2023 06:01:03 - INFO - __main__ -     Batch size = 16
06/22/2023 06:01:18 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:01:18 - INFO - __main__ -     eval_acc = 0.4048
06/22/2023 06:01:18 - INFO - __main__ -     eval_loss = 1.4692
06/22/2023 06:01:18 - INFO - __main__ -     test_acc=0.4048
06/22/2023 06:01:18 - INFO - __main__ -     ********************
06/22/2023 06:01:18 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:01:18 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:01:20 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 06:01:21 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:01:21 - INFO - __main__ -     Batch size = 16
06/22/2023 06:01:21 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:01:21 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:01:25 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:01:25 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:01:25 - INFO - __main__ -     Num batches = 107
06/22/2023 06:01:25 - INFO - __main__ -     Batch size = 16
06/22/2023 06:01:34 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:01:34 - INFO - __main__ -     eval_acc = 0.3904
06/22/2023 06:01:34 - INFO - __main__ -     eval_loss = 1.5391
06/22/2023 06:01:34 - INFO - __main__ -     test_acc=0.3904
06/22/2023 06:01:34 - INFO - __main__ -     ********************
06/22/2023 06:01:34 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:01:35 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:01:38 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:01:38 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:01:38 - INFO - __main__ -     Num batches = 88
06/22/2023 06:01:38 - INFO - __main__ -     Batch size = 16
06/22/2023 06:01:45 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:01:45 - INFO - __main__ -     eval_acc = 0.3912
06/22/2023 06:01:45 - INFO - __main__ -     eval_loss = 1.4924
06/22/2023 06:01:45 - INFO - __main__ -     test_acc=0.3912
06/22/2023 06:01:45 - INFO - __main__ -     ********************
06/22/2023 06:01:45 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:01:45 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:01:48 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 06:01:48 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:01:48 - INFO - __main__ -     Batch size = 16
06/22/2023 06:01:48 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:01:48 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:01:54 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:01:54 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:01:54 - INFO - __main__ -     Num batches = 171
06/22/2023 06:01:54 - INFO - __main__ -     Batch size = 16
06/22/2023 06:02:09 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:02:09 - INFO - __main__ -     eval_acc = 0.3726
06/22/2023 06:02:09 - INFO - __main__ -     eval_loss = 1.624
06/22/2023 06:02:09 - INFO - __main__ -     test_acc=0.3726
06/22/2023 06:02:09 - INFO - __main__ -     ********************
06/22/2023 06:02:09 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:02:09 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:02:15 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:02:15 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:02:15 - INFO - __main__ -     Num batches = 171
06/22/2023 06:02:15 - INFO - __main__ -     Batch size = 16
06/22/2023 06:02:30 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:02:30 - INFO - __main__ -     eval_acc = 0.3873
06/22/2023 06:02:30 - INFO - __main__ -     eval_loss = 1.5422
06/22/2023 06:02:30 - INFO - __main__ -     test_acc=0.3873
06/22/2023 06:02:30 - INFO - __main__ -     ********************
06/22/2023 06:02:30 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:02:30 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:02:32 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 06:02:33 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:02:33 - INFO - __main__ -     Batch size = 16
06/22/2023 06:02:33 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:02:33 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:02:39 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:02:39 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:02:39 - INFO - __main__ -     Num batches = 171
06/22/2023 06:02:39 - INFO - __main__ -     Batch size = 16
06/22/2023 06:02:54 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:02:54 - INFO - __main__ -     eval_acc = 0.5582
06/22/2023 06:02:54 - INFO - __main__ -     eval_loss = 1.0134
06/22/2023 06:02:54 - INFO - __main__ -     test_acc=0.5582
06/22/2023 06:02:54 - INFO - __main__ -     ********************
06/22/2023 06:02:54 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:02:54 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:03:00 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:03:00 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:03:00 - INFO - __main__ -     Num batches = 171
06/22/2023 06:03:00 - INFO - __main__ -     Batch size = 16
06/22/2023 06:03:15 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:03:15 - INFO - __main__ -     eval_acc = 0.5388
06/22/2023 06:03:15 - INFO - __main__ -     eval_loss = 1.0338
06/22/2023 06:03:15 - INFO - __main__ -     test_acc=0.5388
06/22/2023 06:03:15 - INFO - __main__ -     ********************
06/22/2023 06:03:15 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:03:15 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:03:17 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50
06/22/2023 06:03:17 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:03:17 - INFO - __main__ -     Batch size = 16
06/22/2023 06:03:17 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:03:18 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:03:23 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:03:23 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:03:23 - INFO - __main__ -     Num batches = 171
06/22/2023 06:03:23 - INFO - __main__ -     Batch size = 16
06/22/2023 06:03:38 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:03:38 - INFO - __main__ -     eval_acc = 0.3898
06/22/2023 06:03:38 - INFO - __main__ -     eval_loss = 1.5818
06/22/2023 06:03:38 - INFO - __main__ -     test_acc=0.3898
06/22/2023 06:03:38 - INFO - __main__ -     ********************
06/22/2023 06:03:38 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:03:39 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:03:45 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:03:45 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:03:45 - INFO - __main__ -     Num batches = 171
06/22/2023 06:03:45 - INFO - __main__ -     Batch size = 16
06/22/2023 06:03:59 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:03:59 - INFO - __main__ -     eval_acc = 0.4074
06/22/2023 06:03:59 - INFO - __main__ -     eval_loss = 1.5524
06/22/2023 06:03:59 - INFO - __main__ -     test_acc=0.4074
06/22/2023 06:03:59 - INFO - __main__ -     ********************
06/22/2023 06:03:59 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:03:59 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:04:02 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 06:04:02 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:04:02 - INFO - __main__ -     Batch size = 16
06/22/2023 06:04:02 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:04:02 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:04:06 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:04:06 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:04:06 - INFO - __main__ -     Num batches = 107
06/22/2023 06:04:06 - INFO - __main__ -     Batch size = 16
06/22/2023 06:04:15 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:04:15 - INFO - __main__ -     eval_acc = 0.3727
06/22/2023 06:04:15 - INFO - __main__ -     eval_loss = 1.6634
06/22/2023 06:04:15 - INFO - __main__ -     test_acc=0.3727
06/22/2023 06:04:15 - INFO - __main__ -     ********************
06/22/2023 06:04:15 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:04:16 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:04:19 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:04:19 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:04:19 - INFO - __main__ -     Num batches = 88
06/22/2023 06:04:19 - INFO - __main__ -     Batch size = 16
06/22/2023 06:04:26 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:04:26 - INFO - __main__ -     eval_acc = 0.3869
06/22/2023 06:04:26 - INFO - __main__ -     eval_loss = 1.6021
06/22/2023 06:04:26 - INFO - __main__ -     test_acc=0.3869
06/22/2023 06:04:26 - INFO - __main__ -     ********************
06/22/2023 06:04:27 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:04:27 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:04:29 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 06:04:29 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:04:29 - INFO - __main__ -     Batch size = 16
06/22/2023 06:04:29 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:04:29 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:04:35 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:04:35 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:04:35 - INFO - __main__ -     Num batches = 171
06/22/2023 06:04:35 - INFO - __main__ -     Batch size = 16
06/22/2023 06:04:50 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:04:50 - INFO - __main__ -     eval_acc = 0.3657
06/22/2023 06:04:50 - INFO - __main__ -     eval_loss = 1.7248
06/22/2023 06:04:50 - INFO - __main__ -     test_acc=0.3657
06/22/2023 06:04:50 - INFO - __main__ -     ********************
06/22/2023 06:04:50 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:04:50 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:04:56 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:04:56 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:04:56 - INFO - __main__ -     Num batches = 171
06/22/2023 06:04:56 - INFO - __main__ -     Batch size = 16
06/22/2023 06:05:11 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:05:11 - INFO - __main__ -     eval_acc = 0.3939
06/22/2023 06:05:11 - INFO - __main__ -     eval_loss = 1.6486
06/22/2023 06:05:11 - INFO - __main__ -     test_acc=0.3939
06/22/2023 06:05:11 - INFO - __main__ -     ********************
06/22/2023 06:05:11 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='facebook/bart-base', model_type='bart', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:05:11 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:05:13 - INFO - __main__ -   Finish loading model [139M] from facebook/bart-base
06/22/2023 06:05:14 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:05:14 - INFO - __main__ -     Batch size = 16
06/22/2023 06:05:14 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:05:14 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:05:20 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:05:20 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:05:20 - INFO - __main__ -     Num batches = 171
06/22/2023 06:05:20 - INFO - __main__ -     Batch size = 16
06/22/2023 06:05:35 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:05:35 - INFO - __main__ -     eval_acc = 0.5582
06/22/2023 06:05:35 - INFO - __main__ -     eval_loss = 1.0666
06/22/2023 06:05:35 - INFO - __main__ -     test_acc=0.5582
06/22/2023 06:05:35 - INFO - __main__ -     ********************
06/22/2023 06:05:35 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:05:35 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//bart_base/clean/2/bart_base_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:05:41 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:05:41 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:05:41 - INFO - __main__ -     Num batches = 171
06/22/2023 06:05:41 - INFO - __main__ -     Batch size = 16
06/22/2023 06:05:56 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:05:56 - INFO - __main__ -     eval_acc = 0.5447
06/22/2023 06:05:56 - INFO - __main__ -     eval_loss = 1.0801
06/22/2023 06:05:56 - INFO - __main__ -     test_acc=0.5447
06/22/2023 06:05:56 - INFO - __main__ -     ********************
06/22/2023 06:05:56 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:05:56 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:05:57 - INFO - __main__ -   Finish loading model [125M] from roberta-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50
06/22/2023 06:05:57 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:05:57 - INFO - __main__ -     Batch size = 16
06/22/2023 06:05:57 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:05:57 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:06:03 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:06:03 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:06:03 - INFO - __main__ -     Num batches = 171
06/22/2023 06:06:03 - INFO - __main__ -     Batch size = 16
06/22/2023 06:06:12 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:06:12 - INFO - __main__ -     eval_acc = 0.4337
06/22/2023 06:06:12 - INFO - __main__ -     eval_loss = 0.7286
06/22/2023 06:06:12 - INFO - __main__ -     test_acc=0.4337
06/22/2023 06:06:12 - INFO - __main__ -     ********************
06/22/2023 06:06:12 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:06:12 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:06:18 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:06:18 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:06:18 - INFO - __main__ -     Num batches = 171
06/22/2023 06:06:18 - INFO - __main__ -     Batch size = 16
06/22/2023 06:06:27 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:06:27 - INFO - __main__ -     eval_acc = 0.4663
06/22/2023 06:06:27 - INFO - __main__ -     eval_loss = 0.7179
06/22/2023 06:06:27 - INFO - __main__ -     test_acc=0.4663
06/22/2023 06:06:27 - INFO - __main__ -     ********************
06/22/2023 06:06:27 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:06:27 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:06:28 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:06:28 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:06:28 - INFO - __main__ -     Batch size = 16
06/22/2023 06:06:28 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:06:29 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:06:33 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:06:33 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:06:33 - INFO - __main__ -     Num batches = 107
06/22/2023 06:06:33 - INFO - __main__ -     Batch size = 16
06/22/2023 06:06:38 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:06:38 - INFO - __main__ -     eval_acc = 0.4321
06/22/2023 06:06:38 - INFO - __main__ -     eval_loss = 0.7291
06/22/2023 06:06:38 - INFO - __main__ -     test_acc=0.4321
06/22/2023 06:06:38 - INFO - __main__ -     ********************
06/22/2023 06:06:38 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:06:38 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:06:42 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:06:42 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:06:42 - INFO - __main__ -     Num batches = 88
06/22/2023 06:06:42 - INFO - __main__ -     Batch size = 16
06/22/2023 06:06:46 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:06:46 - INFO - __main__ -     eval_acc = 0.4874
06/22/2023 06:06:46 - INFO - __main__ -     eval_loss = 0.7125
06/22/2023 06:06:46 - INFO - __main__ -     test_acc=0.4874
06/22/2023 06:06:46 - INFO - __main__ -     ********************
06/22/2023 06:06:46 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:06:46 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:06:47 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:06:47 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:06:47 - INFO - __main__ -     Batch size = 16
06/22/2023 06:06:47 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:06:48 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:06:54 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:06:54 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:06:54 - INFO - __main__ -     Num batches = 171
06/22/2023 06:06:54 - INFO - __main__ -     Batch size = 16
06/22/2023 06:07:03 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:07:03 - INFO - __main__ -     eval_acc = 0.4363
06/22/2023 06:07:03 - INFO - __main__ -     eval_loss = 0.7277
06/22/2023 06:07:03 - INFO - __main__ -     test_acc=0.4363
06/22/2023 06:07:03 - INFO - __main__ -     ********************
06/22/2023 06:07:03 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:07:03 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:07:09 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:07:09 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:07:09 - INFO - __main__ -     Num batches = 171
06/22/2023 06:07:09 - INFO - __main__ -     Batch size = 16
06/22/2023 06:07:18 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:07:18 - INFO - __main__ -     eval_acc = 0.4597
06/22/2023 06:07:18 - INFO - __main__ -     eval_loss = 0.72
06/22/2023 06:07:18 - INFO - __main__ -     test_acc=0.4597
06/22/2023 06:07:18 - INFO - __main__ -     ********************
06/22/2023 06:07:18 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:07:18 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:07:19 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:07:19 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:07:19 - INFO - __main__ -     Batch size = 16
06/22/2023 06:07:19 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:07:19 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:07:25 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:07:25 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:07:25 - INFO - __main__ -     Num batches = 171
06/22/2023 06:07:25 - INFO - __main__ -     Batch size = 16
06/22/2023 06:07:34 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:07:34 - INFO - __main__ -     eval_acc = 0.5073
06/22/2023 06:07:34 - INFO - __main__ -     eval_loss = 0.704
06/22/2023 06:07:34 - INFO - __main__ -     test_acc=0.5073
06/22/2023 06:07:34 - INFO - __main__ -     ********************
06/22/2023 06:07:34 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:07:34 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:07:40 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:07:40 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:07:40 - INFO - __main__ -     Num batches = 171
06/22/2023 06:07:40 - INFO - __main__ -     Batch size = 16
06/22/2023 06:07:49 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:07:49 - INFO - __main__ -     eval_acc = 0.5264
06/22/2023 06:07:49 - INFO - __main__ -     eval_loss = 0.6978
06/22/2023 06:07:49 - INFO - __main__ -     test_acc=0.5264
06/22/2023 06:07:49 - INFO - __main__ -     ********************
06/22/2023 06:07:49 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:07:49 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:07:50 - INFO - __main__ -   Finish loading model [125M] from roberta-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50
06/22/2023 06:07:50 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:07:50 - INFO - __main__ -     Batch size = 16
06/22/2023 06:07:50 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:07:50 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:07:56 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:07:56 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:07:56 - INFO - __main__ -     Num batches = 171
06/22/2023 06:07:56 - INFO - __main__ -     Batch size = 16
06/22/2023 06:08:05 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:08:05 - INFO - __main__ -     eval_acc = 0.4129
06/22/2023 06:08:05 - INFO - __main__ -     eval_loss = 1.5483
06/22/2023 06:08:05 - INFO - __main__ -     test_acc=0.4129
06/22/2023 06:08:05 - INFO - __main__ -     ********************
06/22/2023 06:08:05 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:08:06 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:08:12 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:08:12 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:08:12 - INFO - __main__ -     Num batches = 171
06/22/2023 06:08:12 - INFO - __main__ -     Batch size = 16
06/22/2023 06:08:21 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:08:21 - INFO - __main__ -     eval_acc = 0.4143
06/22/2023 06:08:21 - INFO - __main__ -     eval_loss = 1.4753
06/22/2023 06:08:21 - INFO - __main__ -     test_acc=0.4143
06/22/2023 06:08:21 - INFO - __main__ -     ********************
06/22/2023 06:08:21 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:08:21 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:08:22 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:08:22 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:08:22 - INFO - __main__ -     Batch size = 16
06/22/2023 06:08:22 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:08:22 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:08:26 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:08:26 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:08:26 - INFO - __main__ -     Num batches = 107
06/22/2023 06:08:26 - INFO - __main__ -     Batch size = 16
06/22/2023 06:08:32 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:08:32 - INFO - __main__ -     eval_acc = 0.4109
06/22/2023 06:08:32 - INFO - __main__ -     eval_loss = 1.5674
06/22/2023 06:08:32 - INFO - __main__ -     test_acc=0.4109
06/22/2023 06:08:32 - INFO - __main__ -     ********************
06/22/2023 06:08:32 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:08:32 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:08:35 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:08:35 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:08:35 - INFO - __main__ -     Num batches = 88
06/22/2023 06:08:35 - INFO - __main__ -     Batch size = 16
06/22/2023 06:08:40 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:08:40 - INFO - __main__ -     eval_acc = 0.3877
06/22/2023 06:08:40 - INFO - __main__ -     eval_loss = 1.6194
06/22/2023 06:08:40 - INFO - __main__ -     test_acc=0.3877
06/22/2023 06:08:40 - INFO - __main__ -     ********************
06/22/2023 06:08:40 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:08:40 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:08:41 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:08:41 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:08:41 - INFO - __main__ -     Batch size = 16
06/22/2023 06:08:41 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:08:41 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:08:47 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:08:47 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:08:47 - INFO - __main__ -     Num batches = 171
06/22/2023 06:08:47 - INFO - __main__ -     Batch size = 16
06/22/2023 06:08:56 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:08:56 - INFO - __main__ -     eval_acc = 0.3887
06/22/2023 06:08:56 - INFO - __main__ -     eval_loss = 1.6836
06/22/2023 06:08:56 - INFO - __main__ -     test_acc=0.3887
06/22/2023 06:08:56 - INFO - __main__ -     ********************
06/22/2023 06:08:56 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:08:57 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:09:02 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:09:02 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:09:02 - INFO - __main__ -     Num batches = 171
06/22/2023 06:09:02 - INFO - __main__ -     Batch size = 16
06/22/2023 06:09:11 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:09:11 - INFO - __main__ -     eval_acc = 0.3847
06/22/2023 06:09:11 - INFO - __main__ -     eval_loss = 1.6171
06/22/2023 06:09:11 - INFO - __main__ -     test_acc=0.3847
06/22/2023 06:09:11 - INFO - __main__ -     ********************
06/22/2023 06:09:11 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:09:11 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:09:12 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:09:13 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:09:13 - INFO - __main__ -     Batch size = 16
06/22/2023 06:09:13 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:09:13 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:09:19 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:09:19 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:09:19 - INFO - __main__ -     Num batches = 171
06/22/2023 06:09:19 - INFO - __main__ -     Batch size = 16
06/22/2023 06:09:28 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:09:28 - INFO - __main__ -     eval_acc = 0.5597
06/22/2023 06:09:28 - INFO - __main__ -     eval_loss = 1.0905
06/22/2023 06:09:28 - INFO - __main__ -     test_acc=0.5597
06/22/2023 06:09:28 - INFO - __main__ -     ********************
06/22/2023 06:09:28 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:09:28 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:09:34 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:09:34 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:09:34 - INFO - __main__ -     Num batches = 171
06/22/2023 06:09:34 - INFO - __main__ -     Batch size = 16
06/22/2023 06:09:43 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:09:43 - INFO - __main__ -     eval_acc = 0.5256
06/22/2023 06:09:43 - INFO - __main__ -     eval_loss = 1.1579
06/22/2023 06:09:43 - INFO - __main__ -     test_acc=0.5256
06/22/2023 06:09:43 - INFO - __main__ -     ********************
06/22/2023 06:09:43 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:09:43 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:09:44 - INFO - __main__ -   Finish loading model [125M] from roberta-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50
06/22/2023 06:09:44 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:09:44 - INFO - __main__ -     Batch size = 16
06/22/2023 06:09:44 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:09:44 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:09:50 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:09:50 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:09:50 - INFO - __main__ -     Num batches = 171
06/22/2023 06:09:50 - INFO - __main__ -     Batch size = 16
06/22/2023 06:09:59 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:09:59 - INFO - __main__ -     eval_acc = 0.4337
06/22/2023 06:09:59 - INFO - __main__ -     eval_loss = 0.725
06/22/2023 06:09:59 - INFO - __main__ -     test_acc=0.4337
06/22/2023 06:09:59 - INFO - __main__ -     ********************
06/22/2023 06:09:59 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:10:00 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:10:05 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:10:05 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:10:05 - INFO - __main__ -     Num batches = 171
06/22/2023 06:10:05 - INFO - __main__ -     Batch size = 16
06/22/2023 06:10:14 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:10:14 - INFO - __main__ -     eval_acc = 0.4663
06/22/2023 06:10:14 - INFO - __main__ -     eval_loss = 0.7152
06/22/2023 06:10:14 - INFO - __main__ -     test_acc=0.4663
06/22/2023 06:10:14 - INFO - __main__ -     ********************
06/22/2023 06:10:14 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:10:14 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:10:16 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:10:16 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:10:16 - INFO - __main__ -     Batch size = 16
06/22/2023 06:10:16 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:10:16 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:10:20 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:10:20 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:10:20 - INFO - __main__ -     Num batches = 107
06/22/2023 06:10:20 - INFO - __main__ -     Batch size = 16
06/22/2023 06:10:25 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:10:25 - INFO - __main__ -     eval_acc = 0.4321
06/22/2023 06:10:25 - INFO - __main__ -     eval_loss = 0.7255
06/22/2023 06:10:25 - INFO - __main__ -     test_acc=0.4321
06/22/2023 06:10:25 - INFO - __main__ -     ********************
06/22/2023 06:10:25 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:10:26 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:10:29 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:10:29 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:10:29 - INFO - __main__ -     Num batches = 88
06/22/2023 06:10:29 - INFO - __main__ -     Batch size = 16
06/22/2023 06:10:34 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:10:34 - INFO - __main__ -     eval_acc = 0.4874
06/22/2023 06:10:34 - INFO - __main__ -     eval_loss = 0.7101
06/22/2023 06:10:34 - INFO - __main__ -     test_acc=0.4874
06/22/2023 06:10:34 - INFO - __main__ -     ********************
06/22/2023 06:10:34 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:10:34 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:10:35 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:10:35 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:10:35 - INFO - __main__ -     Batch size = 16
06/22/2023 06:10:35 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:10:35 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:10:41 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:10:41 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:10:41 - INFO - __main__ -     Num batches = 171
06/22/2023 06:10:41 - INFO - __main__ -     Batch size = 16
06/22/2023 06:10:50 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:10:50 - INFO - __main__ -     eval_acc = 0.4363
06/22/2023 06:10:50 - INFO - __main__ -     eval_loss = 0.7242
06/22/2023 06:10:50 - INFO - __main__ -     test_acc=0.4363
06/22/2023 06:10:50 - INFO - __main__ -     ********************
06/22/2023 06:10:50 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:10:50 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:10:56 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:10:56 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:10:56 - INFO - __main__ -     Num batches = 171
06/22/2023 06:10:56 - INFO - __main__ -     Batch size = 16
06/22/2023 06:11:05 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:11:05 - INFO - __main__ -     eval_acc = 0.4597
06/22/2023 06:11:05 - INFO - __main__ -     eval_loss = 0.7172
06/22/2023 06:11:05 - INFO - __main__ -     test_acc=0.4597
06/22/2023 06:11:05 - INFO - __main__ -     ********************
06/22/2023 06:11:05 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:11:05 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:11:06 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:11:06 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:11:06 - INFO - __main__ -     Batch size = 16
06/22/2023 06:11:06 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:11:07 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:11:13 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:11:13 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:11:13 - INFO - __main__ -     Num batches = 171
06/22/2023 06:11:13 - INFO - __main__ -     Batch size = 16
06/22/2023 06:11:21 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:11:21 - INFO - __main__ -     eval_acc = 0.5073
06/22/2023 06:11:21 - INFO - __main__ -     eval_loss = 0.7025
06/22/2023 06:11:21 - INFO - __main__ -     test_acc=0.5073
06/22/2023 06:11:21 - INFO - __main__ -     ********************
06/22/2023 06:11:21 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:11:22 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:11:28 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:11:28 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:11:28 - INFO - __main__ -     Num batches = 171
06/22/2023 06:11:28 - INFO - __main__ -     Batch size = 16
06/22/2023 06:11:36 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:11:36 - INFO - __main__ -     eval_acc = 0.5264
06/22/2023 06:11:36 - INFO - __main__ -     eval_loss = 0.6967
06/22/2023 06:11:36 - INFO - __main__ -     test_acc=0.5264
06/22/2023 06:11:36 - INFO - __main__ -     ********************
06/22/2023 06:11:37 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:11:37 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:11:37 - INFO - __main__ -   Finish loading model [125M] from roberta-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50
06/22/2023 06:11:38 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:11:38 - INFO - __main__ -     Batch size = 16
06/22/2023 06:11:38 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:11:38 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:11:44 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:11:44 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:11:44 - INFO - __main__ -     Num batches = 171
06/22/2023 06:11:44 - INFO - __main__ -     Batch size = 16
06/22/2023 06:11:53 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:11:53 - INFO - __main__ -     eval_acc = 0.4337
06/22/2023 06:11:53 - INFO - __main__ -     eval_loss = 0.7217
06/22/2023 06:11:53 - INFO - __main__ -     test_acc=0.4337
06/22/2023 06:11:53 - INFO - __main__ -     ********************
06/22/2023 06:11:53 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:11:53 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:11:59 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:11:59 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:11:59 - INFO - __main__ -     Num batches = 171
06/22/2023 06:11:59 - INFO - __main__ -     Batch size = 16
06/22/2023 06:12:08 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:12:08 - INFO - __main__ -     eval_acc = 0.4663
06/22/2023 06:12:08 - INFO - __main__ -     eval_loss = 0.7126
06/22/2023 06:12:08 - INFO - __main__ -     test_acc=0.4663
06/22/2023 06:12:08 - INFO - __main__ -     ********************
06/22/2023 06:12:08 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:12:08 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:12:09 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:12:09 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:12:09 - INFO - __main__ -     Batch size = 16
06/22/2023 06:12:09 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:12:10 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:12:14 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:12:14 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:12:14 - INFO - __main__ -     Num batches = 107
06/22/2023 06:12:14 - INFO - __main__ -     Batch size = 16
06/22/2023 06:12:19 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:12:19 - INFO - __main__ -     eval_acc = 0.4321
06/22/2023 06:12:19 - INFO - __main__ -     eval_loss = 0.7221
06/22/2023 06:12:19 - INFO - __main__ -     test_acc=0.4321
06/22/2023 06:12:19 - INFO - __main__ -     ********************
06/22/2023 06:12:19 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:12:20 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:12:23 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:12:23 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:12:23 - INFO - __main__ -     Num batches = 88
06/22/2023 06:12:23 - INFO - __main__ -     Batch size = 16
06/22/2023 06:12:27 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:12:27 - INFO - __main__ -     eval_acc = 0.4874
06/22/2023 06:12:27 - INFO - __main__ -     eval_loss = 0.7079
06/22/2023 06:12:27 - INFO - __main__ -     test_acc=0.4874
06/22/2023 06:12:27 - INFO - __main__ -     ********************
06/22/2023 06:12:27 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:12:27 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:12:28 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:12:28 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:12:28 - INFO - __main__ -     Batch size = 16
06/22/2023 06:12:28 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:12:29 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:12:35 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:12:35 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:12:35 - INFO - __main__ -     Num batches = 171
06/22/2023 06:12:35 - INFO - __main__ -     Batch size = 16
06/22/2023 06:12:44 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:12:44 - INFO - __main__ -     eval_acc = 0.4363
06/22/2023 06:12:44 - INFO - __main__ -     eval_loss = 0.721
06/22/2023 06:12:44 - INFO - __main__ -     test_acc=0.4363
06/22/2023 06:12:44 - INFO - __main__ -     ********************
06/22/2023 06:12:44 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:12:44 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:12:50 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:12:50 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:12:50 - INFO - __main__ -     Num batches = 171
06/22/2023 06:12:50 - INFO - __main__ -     Batch size = 16
06/22/2023 06:12:59 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:12:59 - INFO - __main__ -     eval_acc = 0.4597
06/22/2023 06:12:59 - INFO - __main__ -     eval_loss = 0.7144
06/22/2023 06:12:59 - INFO - __main__ -     test_acc=0.4597
06/22/2023 06:12:59 - INFO - __main__ -     ********************
06/22/2023 06:12:59 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:12:59 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:13:00 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:13:00 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:13:00 - INFO - __main__ -     Batch size = 16
06/22/2023 06:13:00 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:13:00 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:13:06 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:13:06 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:13:06 - INFO - __main__ -     Num batches = 171
06/22/2023 06:13:06 - INFO - __main__ -     Batch size = 16
06/22/2023 06:13:15 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:13:15 - INFO - __main__ -     eval_acc = 0.5073
06/22/2023 06:13:15 - INFO - __main__ -     eval_loss = 0.7007
06/22/2023 06:13:15 - INFO - __main__ -     test_acc=0.5073
06/22/2023 06:13:15 - INFO - __main__ -     ********************
06/22/2023 06:13:15 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:13:16 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:13:21 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:13:21 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:13:21 - INFO - __main__ -     Num batches = 171
06/22/2023 06:13:21 - INFO - __main__ -     Batch size = 16
06/22/2023 06:13:30 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:13:30 - INFO - __main__ -     eval_acc = 0.5264
06/22/2023 06:13:30 - INFO - __main__ -     eval_loss = 0.6955
06/22/2023 06:13:30 - INFO - __main__ -     test_acc=0.5264
06/22/2023 06:13:30 - INFO - __main__ -     ********************
06/22/2023 06:13:30 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:13:30 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:13:31 - INFO - __main__ -   Finish loading model [125M] from roberta-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50
06/22/2023 06:13:31 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:13:31 - INFO - __main__ -     Batch size = 16
06/22/2023 06:13:31 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:13:32 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:13:38 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:13:38 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:13:38 - INFO - __main__ -     Num batches = 171
06/22/2023 06:13:38 - INFO - __main__ -     Batch size = 16
06/22/2023 06:13:47 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:13:47 - INFO - __main__ -     eval_acc = 0.41
06/22/2023 06:13:47 - INFO - __main__ -     eval_loss = 1.9136
06/22/2023 06:13:47 - INFO - __main__ -     test_acc=0.4100
06/22/2023 06:13:47 - INFO - __main__ -     ********************
06/22/2023 06:13:47 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:13:47 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:13:53 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:13:53 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:13:53 - INFO - __main__ -     Num batches = 171
06/22/2023 06:13:53 - INFO - __main__ -     Batch size = 16
06/22/2023 06:14:02 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:14:02 - INFO - __main__ -     eval_acc = 0.4246
06/22/2023 06:14:02 - INFO - __main__ -     eval_loss = 1.8527
06/22/2023 06:14:02 - INFO - __main__ -     test_acc=0.4246
06/22/2023 06:14:02 - INFO - __main__ -     ********************
06/22/2023 06:14:02 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:14:02 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:14:03 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:14:03 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:14:03 - INFO - __main__ -     Batch size = 16
06/22/2023 06:14:03 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:14:04 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:14:07 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:14:07 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:14:07 - INFO - __main__ -     Num batches = 107
06/22/2023 06:14:07 - INFO - __main__ -     Batch size = 16
06/22/2023 06:14:13 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:14:13 - INFO - __main__ -     eval_acc = 0.4045
06/22/2023 06:14:13 - INFO - __main__ -     eval_loss = 2.0059
06/22/2023 06:14:13 - INFO - __main__ -     test_acc=0.4045
06/22/2023 06:14:13 - INFO - __main__ -     ********************
06/22/2023 06:14:13 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:14:13 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:14:17 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:14:17 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:14:17 - INFO - __main__ -     Num batches = 88
06/22/2023 06:14:17 - INFO - __main__ -     Batch size = 16
06/22/2023 06:14:21 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:14:21 - INFO - __main__ -     eval_acc = 0.3963
06/22/2023 06:14:21 - INFO - __main__ -     eval_loss = 2.0958
06/22/2023 06:14:21 - INFO - __main__ -     test_acc=0.3963
06/22/2023 06:14:21 - INFO - __main__ -     ********************
06/22/2023 06:14:21 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:14:21 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:14:22 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:14:22 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:14:22 - INFO - __main__ -     Batch size = 16
06/22/2023 06:14:22 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:14:23 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:14:29 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:14:29 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:14:29 - INFO - __main__ -     Num batches = 171
06/22/2023 06:14:29 - INFO - __main__ -     Batch size = 16
06/22/2023 06:14:38 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:14:38 - INFO - __main__ -     eval_acc = 0.3788
06/22/2023 06:14:38 - INFO - __main__ -     eval_loss = 2.1158
06/22/2023 06:14:38 - INFO - __main__ -     test_acc=0.3788
06/22/2023 06:14:38 - INFO - __main__ -     ********************
06/22/2023 06:14:38 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:14:38 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:14:44 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:14:44 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:14:44 - INFO - __main__ -     Num batches = 171
06/22/2023 06:14:44 - INFO - __main__ -     Batch size = 16
06/22/2023 06:14:53 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:14:53 - INFO - __main__ -     eval_acc = 0.3942
06/22/2023 06:14:53 - INFO - __main__ -     eval_loss = 2.065
06/22/2023 06:14:53 - INFO - __main__ -     test_acc=0.3942
06/22/2023 06:14:53 - INFO - __main__ -     ********************
06/22/2023 06:14:53 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:14:53 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:14:54 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:14:54 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:14:54 - INFO - __main__ -     Batch size = 16
06/22/2023 06:14:54 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:14:54 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:15:00 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:15:00 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:15:00 - INFO - __main__ -     Num batches = 171
06/22/2023 06:15:00 - INFO - __main__ -     Batch size = 16
06/22/2023 06:15:09 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:15:09 - INFO - __main__ -     eval_acc = 0.5626
06/22/2023 06:15:09 - INFO - __main__ -     eval_loss = 1.3511
06/22/2023 06:15:09 - INFO - __main__ -     test_acc=0.5626
06/22/2023 06:15:09 - INFO - __main__ -     ********************
06/22/2023 06:15:09 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:15:09 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:15:15 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:15:15 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:15:15 - INFO - __main__ -     Num batches = 171
06/22/2023 06:15:15 - INFO - __main__ -     Batch size = 16
06/22/2023 06:15:24 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:15:24 - INFO - __main__ -     eval_acc = 0.5242
06/22/2023 06:15:24 - INFO - __main__ -     eval_loss = 1.4526
06/22/2023 06:15:24 - INFO - __main__ -     test_acc=0.5242
06/22/2023 06:15:24 - INFO - __main__ -     ********************
06/22/2023 06:15:24 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:15:24 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:15:25 - INFO - __main__ -   Finish loading model [125M] from roberta-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50
06/22/2023 06:15:25 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:15:25 - INFO - __main__ -     Batch size = 16
06/22/2023 06:15:25 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:15:26 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:15:32 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:15:32 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:15:32 - INFO - __main__ -     Num batches = 171
06/22/2023 06:15:32 - INFO - __main__ -     Batch size = 16
06/22/2023 06:15:41 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:15:41 - INFO - __main__ -     eval_acc = 0.4337
06/22/2023 06:15:41 - INFO - __main__ -     eval_loss = 0.7233
06/22/2023 06:15:41 - INFO - __main__ -     test_acc=0.4337
06/22/2023 06:15:41 - INFO - __main__ -     ********************
06/22/2023 06:15:41 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:15:41 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:15:47 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:15:47 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:15:47 - INFO - __main__ -     Num batches = 171
06/22/2023 06:15:47 - INFO - __main__ -     Batch size = 16
06/22/2023 06:15:56 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:15:56 - INFO - __main__ -     eval_acc = 0.4663
06/22/2023 06:15:56 - INFO - __main__ -     eval_loss = 0.7139
06/22/2023 06:15:56 - INFO - __main__ -     test_acc=0.4663
06/22/2023 06:15:56 - INFO - __main__ -     ********************
06/22/2023 06:15:56 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:15:56 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:15:57 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:15:57 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:15:57 - INFO - __main__ -     Batch size = 16
06/22/2023 06:15:57 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:15:57 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:16:01 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:16:01 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:16:01 - INFO - __main__ -     Num batches = 107
06/22/2023 06:16:01 - INFO - __main__ -     Batch size = 16
06/22/2023 06:16:07 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:16:07 - INFO - __main__ -     eval_acc = 0.4321
06/22/2023 06:16:07 - INFO - __main__ -     eval_loss = 0.7238
06/22/2023 06:16:07 - INFO - __main__ -     test_acc=0.4321
06/22/2023 06:16:07 - INFO - __main__ -     ********************
06/22/2023 06:16:07 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:16:07 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:16:10 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:16:10 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:16:10 - INFO - __main__ -     Num batches = 88
06/22/2023 06:16:10 - INFO - __main__ -     Batch size = 16
06/22/2023 06:16:15 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:16:15 - INFO - __main__ -     eval_acc = 0.4874
06/22/2023 06:16:15 - INFO - __main__ -     eval_loss = 0.709
06/22/2023 06:16:15 - INFO - __main__ -     test_acc=0.4874
06/22/2023 06:16:15 - INFO - __main__ -     ********************
06/22/2023 06:16:15 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:16:15 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:16:16 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:16:16 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:16:16 - INFO - __main__ -     Batch size = 16
06/22/2023 06:16:16 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:16:17 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:16:22 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:16:22 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:16:22 - INFO - __main__ -     Num batches = 171
06/22/2023 06:16:22 - INFO - __main__ -     Batch size = 16
06/22/2023 06:16:31 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:16:31 - INFO - __main__ -     eval_acc = 0.4363
06/22/2023 06:16:31 - INFO - __main__ -     eval_loss = 0.7225
06/22/2023 06:16:31 - INFO - __main__ -     test_acc=0.4363
06/22/2023 06:16:31 - INFO - __main__ -     ********************
06/22/2023 06:16:31 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:16:32 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:16:37 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:16:37 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:16:37 - INFO - __main__ -     Num batches = 171
06/22/2023 06:16:37 - INFO - __main__ -     Batch size = 16
06/22/2023 06:16:46 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:16:46 - INFO - __main__ -     eval_acc = 0.4597
06/22/2023 06:16:46 - INFO - __main__ -     eval_loss = 0.7158
06/22/2023 06:16:46 - INFO - __main__ -     test_acc=0.4597
06/22/2023 06:16:46 - INFO - __main__ -     ********************
06/22/2023 06:16:46 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:16:46 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:16:47 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:16:48 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:16:48 - INFO - __main__ -     Batch size = 16
06/22/2023 06:16:48 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:16:48 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:16:54 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:16:54 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:16:54 - INFO - __main__ -     Num batches = 171
06/22/2023 06:16:54 - INFO - __main__ -     Batch size = 16
06/22/2023 06:17:03 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:17:03 - INFO - __main__ -     eval_acc = 0.5073
06/22/2023 06:17:03 - INFO - __main__ -     eval_loss = 0.7016
06/22/2023 06:17:03 - INFO - __main__ -     test_acc=0.5073
06/22/2023 06:17:03 - INFO - __main__ -     ********************
06/22/2023 06:17:03 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:17:03 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/1/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:17:09 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:17:09 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:17:09 - INFO - __main__ -     Num batches = 171
06/22/2023 06:17:09 - INFO - __main__ -     Batch size = 16
06/22/2023 06:17:18 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:17:18 - INFO - __main__ -     eval_acc = 0.5264
06/22/2023 06:17:18 - INFO - __main__ -     eval_loss = 0.6961
06/22/2023 06:17:18 - INFO - __main__ -     test_acc=0.5264
06/22/2023 06:17:18 - INFO - __main__ -     ********************
06/22/2023 06:17:18 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:17:18 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:17:19 - INFO - __main__ -   Finish loading model [125M] from roberta-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50
06/22/2023 06:17:19 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:17:19 - INFO - __main__ -     Batch size = 16
06/22/2023 06:17:19 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:17:19 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:17:25 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:17:25 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:17:25 - INFO - __main__ -     Num batches = 171
06/22/2023 06:17:25 - INFO - __main__ -     Batch size = 16
06/22/2023 06:17:34 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:17:34 - INFO - __main__ -     eval_acc = 0.4337
06/22/2023 06:17:34 - INFO - __main__ -     eval_loss = 0.7286
06/22/2023 06:17:34 - INFO - __main__ -     test_acc=0.4337
06/22/2023 06:17:34 - INFO - __main__ -     ********************
06/22/2023 06:17:34 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:17:35 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:17:41 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:17:41 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:17:41 - INFO - __main__ -     Num batches = 171
06/22/2023 06:17:41 - INFO - __main__ -     Batch size = 16
06/22/2023 06:17:50 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:17:50 - INFO - __main__ -     eval_acc = 0.4663
06/22/2023 06:17:50 - INFO - __main__ -     eval_loss = 0.7179
06/22/2023 06:17:50 - INFO - __main__ -     test_acc=0.4663
06/22/2023 06:17:50 - INFO - __main__ -     ********************
06/22/2023 06:17:50 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:17:50 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:17:51 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:17:51 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:17:51 - INFO - __main__ -     Batch size = 16
06/22/2023 06:17:51 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:17:51 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:17:55 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:17:55 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:17:55 - INFO - __main__ -     Num batches = 107
06/22/2023 06:17:55 - INFO - __main__ -     Batch size = 16
06/22/2023 06:18:01 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:18:01 - INFO - __main__ -     eval_acc = 0.4321
06/22/2023 06:18:01 - INFO - __main__ -     eval_loss = 0.7291
06/22/2023 06:18:01 - INFO - __main__ -     test_acc=0.4321
06/22/2023 06:18:01 - INFO - __main__ -     ********************
06/22/2023 06:18:01 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:18:01 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:18:04 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:18:04 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:18:04 - INFO - __main__ -     Num batches = 88
06/22/2023 06:18:04 - INFO - __main__ -     Batch size = 16
06/22/2023 06:18:09 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:18:09 - INFO - __main__ -     eval_acc = 0.4874
06/22/2023 06:18:09 - INFO - __main__ -     eval_loss = 0.7125
06/22/2023 06:18:09 - INFO - __main__ -     test_acc=0.4874
06/22/2023 06:18:09 - INFO - __main__ -     ********************
06/22/2023 06:18:09 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:18:09 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:18:10 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:18:10 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:18:10 - INFO - __main__ -     Batch size = 16
06/22/2023 06:18:10 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:18:10 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:18:16 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:18:16 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:18:16 - INFO - __main__ -     Num batches = 171
06/22/2023 06:18:16 - INFO - __main__ -     Batch size = 16
06/22/2023 06:18:25 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:18:25 - INFO - __main__ -     eval_acc = 0.4363
06/22/2023 06:18:25 - INFO - __main__ -     eval_loss = 0.7277
06/22/2023 06:18:25 - INFO - __main__ -     test_acc=0.4363
06/22/2023 06:18:25 - INFO - __main__ -     ********************
06/22/2023 06:18:25 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:18:25 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:18:31 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:18:31 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:18:31 - INFO - __main__ -     Num batches = 171
06/22/2023 06:18:31 - INFO - __main__ -     Batch size = 16
06/22/2023 06:18:40 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:18:40 - INFO - __main__ -     eval_acc = 0.4597
06/22/2023 06:18:40 - INFO - __main__ -     eval_loss = 0.72
06/22/2023 06:18:40 - INFO - __main__ -     test_acc=0.4597
06/22/2023 06:18:40 - INFO - __main__ -     ********************
06/22/2023 06:18:40 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:18:40 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:18:41 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:18:41 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:18:41 - INFO - __main__ -     Batch size = 16
06/22/2023 06:18:41 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:18:42 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:18:47 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:18:47 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:18:47 - INFO - __main__ -     Num batches = 171
06/22/2023 06:18:47 - INFO - __main__ -     Batch size = 16
06/22/2023 06:18:56 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:18:56 - INFO - __main__ -     eval_acc = 0.5073
06/22/2023 06:18:56 - INFO - __main__ -     eval_loss = 0.704
06/22/2023 06:18:56 - INFO - __main__ -     test_acc=0.5073
06/22/2023 06:18:56 - INFO - __main__ -     ********************
06/22/2023 06:18:56 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:18:57 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:19:03 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:19:03 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:19:03 - INFO - __main__ -     Num batches = 171
06/22/2023 06:19:03 - INFO - __main__ -     Batch size = 16
06/22/2023 06:19:11 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:19:11 - INFO - __main__ -     eval_acc = 0.5264
06/22/2023 06:19:11 - INFO - __main__ -     eval_loss = 0.6978
06/22/2023 06:19:11 - INFO - __main__ -     test_acc=0.5264
06/22/2023 06:19:11 - INFO - __main__ -     ********************
06/22/2023 06:19:12 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:19:12 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:19:13 - INFO - __main__ -   Finish loading model [125M] from roberta-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50
06/22/2023 06:19:13 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:19:13 - INFO - __main__ -     Batch size = 16
06/22/2023 06:19:13 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:19:13 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:19:19 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:19:19 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:19:19 - INFO - __main__ -     Num batches = 171
06/22/2023 06:19:19 - INFO - __main__ -     Batch size = 16
06/22/2023 06:19:28 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:19:28 - INFO - __main__ -     eval_acc = 0.4129
06/22/2023 06:19:28 - INFO - __main__ -     eval_loss = 1.5483
06/22/2023 06:19:28 - INFO - __main__ -     test_acc=0.4129
06/22/2023 06:19:28 - INFO - __main__ -     ********************
06/22/2023 06:19:28 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:19:28 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:19:34 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:19:34 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:19:34 - INFO - __main__ -     Num batches = 171
06/22/2023 06:19:34 - INFO - __main__ -     Batch size = 16
06/22/2023 06:19:43 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:19:43 - INFO - __main__ -     eval_acc = 0.4143
06/22/2023 06:19:43 - INFO - __main__ -     eval_loss = 1.4753
06/22/2023 06:19:43 - INFO - __main__ -     test_acc=0.4143
06/22/2023 06:19:43 - INFO - __main__ -     ********************
06/22/2023 06:19:44 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:19:44 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:19:45 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:19:45 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:19:45 - INFO - __main__ -     Batch size = 16
06/22/2023 06:19:45 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:19:45 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:19:49 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:19:49 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:19:49 - INFO - __main__ -     Num batches = 107
06/22/2023 06:19:49 - INFO - __main__ -     Batch size = 16
06/22/2023 06:19:55 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:19:55 - INFO - __main__ -     eval_acc = 0.4109
06/22/2023 06:19:55 - INFO - __main__ -     eval_loss = 1.5674
06/22/2023 06:19:55 - INFO - __main__ -     test_acc=0.4109
06/22/2023 06:19:55 - INFO - __main__ -     ********************
06/22/2023 06:19:55 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:19:55 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:19:58 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:19:58 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:19:58 - INFO - __main__ -     Num batches = 88
06/22/2023 06:19:58 - INFO - __main__ -     Batch size = 16
06/22/2023 06:20:03 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:20:03 - INFO - __main__ -     eval_acc = 0.3877
06/22/2023 06:20:03 - INFO - __main__ -     eval_loss = 1.6194
06/22/2023 06:20:03 - INFO - __main__ -     test_acc=0.3877
06/22/2023 06:20:03 - INFO - __main__ -     ********************
06/22/2023 06:20:03 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:20:03 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:20:04 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:20:04 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:20:04 - INFO - __main__ -     Batch size = 16
06/22/2023 06:20:04 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:20:04 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:20:10 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:20:10 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:20:10 - INFO - __main__ -     Num batches = 171
06/22/2023 06:20:10 - INFO - __main__ -     Batch size = 16
06/22/2023 06:20:19 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:20:19 - INFO - __main__ -     eval_acc = 0.3887
06/22/2023 06:20:19 - INFO - __main__ -     eval_loss = 1.6836
06/22/2023 06:20:19 - INFO - __main__ -     test_acc=0.3887
06/22/2023 06:20:19 - INFO - __main__ -     ********************
06/22/2023 06:20:19 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:20:20 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:20:25 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:20:25 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:20:25 - INFO - __main__ -     Num batches = 171
06/22/2023 06:20:25 - INFO - __main__ -     Batch size = 16
06/22/2023 06:20:34 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:20:34 - INFO - __main__ -     eval_acc = 0.3847
06/22/2023 06:20:34 - INFO - __main__ -     eval_loss = 1.6171
06/22/2023 06:20:34 - INFO - __main__ -     test_acc=0.3847
06/22/2023 06:20:34 - INFO - __main__ -     ********************
06/22/2023 06:20:34 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:20:34 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:20:35 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:20:36 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:20:36 - INFO - __main__ -     Batch size = 16
06/22/2023 06:20:36 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:20:36 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:20:42 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:20:42 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:20:42 - INFO - __main__ -     Num batches = 171
06/22/2023 06:20:42 - INFO - __main__ -     Batch size = 16
06/22/2023 06:20:51 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:20:51 - INFO - __main__ -     eval_acc = 0.5597
06/22/2023 06:20:51 - INFO - __main__ -     eval_loss = 1.0905
06/22/2023 06:20:51 - INFO - __main__ -     test_acc=0.5597
06/22/2023 06:20:51 - INFO - __main__ -     ********************
06/22/2023 06:20:51 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:20:51 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:20:57 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:20:57 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:20:57 - INFO - __main__ -     Num batches = 171
06/22/2023 06:20:57 - INFO - __main__ -     Batch size = 16
06/22/2023 06:21:06 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:21:06 - INFO - __main__ -     eval_acc = 0.5256
06/22/2023 06:21:06 - INFO - __main__ -     eval_loss = 1.1579
06/22/2023 06:21:06 - INFO - __main__ -     test_acc=0.5256
06/22/2023 06:21:06 - INFO - __main__ -     ********************
06/22/2023 06:21:06 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:21:06 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:21:07 - INFO - __main__ -   Finish loading model [125M] from roberta-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50
06/22/2023 06:21:07 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:21:07 - INFO - __main__ -     Batch size = 16
06/22/2023 06:21:07 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:21:07 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:21:13 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:21:13 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:21:13 - INFO - __main__ -     Num batches = 171
06/22/2023 06:21:13 - INFO - __main__ -     Batch size = 16
06/22/2023 06:21:22 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:21:22 - INFO - __main__ -     eval_acc = 0.4337
06/22/2023 06:21:22 - INFO - __main__ -     eval_loss = 0.725
06/22/2023 06:21:22 - INFO - __main__ -     test_acc=0.4337
06/22/2023 06:21:22 - INFO - __main__ -     ********************
06/22/2023 06:21:22 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:21:23 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:21:29 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:21:29 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:21:29 - INFO - __main__ -     Num batches = 171
06/22/2023 06:21:29 - INFO - __main__ -     Batch size = 16
06/22/2023 06:21:37 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:21:37 - INFO - __main__ -     eval_acc = 0.4663
06/22/2023 06:21:37 - INFO - __main__ -     eval_loss = 0.7152
06/22/2023 06:21:37 - INFO - __main__ -     test_acc=0.4663
06/22/2023 06:21:37 - INFO - __main__ -     ********************
06/22/2023 06:21:38 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:21:38 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:21:39 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:21:39 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:21:39 - INFO - __main__ -     Batch size = 16
06/22/2023 06:21:39 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:21:39 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:21:43 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:21:43 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:21:43 - INFO - __main__ -     Num batches = 107
06/22/2023 06:21:43 - INFO - __main__ -     Batch size = 16
06/22/2023 06:21:49 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:21:49 - INFO - __main__ -     eval_acc = 0.4321
06/22/2023 06:21:49 - INFO - __main__ -     eval_loss = 0.7255
06/22/2023 06:21:49 - INFO - __main__ -     test_acc=0.4321
06/22/2023 06:21:49 - INFO - __main__ -     ********************
06/22/2023 06:21:49 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:21:49 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:21:52 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:21:52 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:21:52 - INFO - __main__ -     Num batches = 88
06/22/2023 06:21:52 - INFO - __main__ -     Batch size = 16
06/22/2023 06:21:57 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:21:57 - INFO - __main__ -     eval_acc = 0.4874
06/22/2023 06:21:57 - INFO - __main__ -     eval_loss = 0.7101
06/22/2023 06:21:57 - INFO - __main__ -     test_acc=0.4874
06/22/2023 06:21:57 - INFO - __main__ -     ********************
06/22/2023 06:21:57 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:21:57 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:21:58 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:21:58 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:21:58 - INFO - __main__ -     Batch size = 16
06/22/2023 06:21:58 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:21:58 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:22:04 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:22:04 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:22:04 - INFO - __main__ -     Num batches = 171
06/22/2023 06:22:04 - INFO - __main__ -     Batch size = 16
06/22/2023 06:22:13 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:22:13 - INFO - __main__ -     eval_acc = 0.4363
06/22/2023 06:22:13 - INFO - __main__ -     eval_loss = 0.7242
06/22/2023 06:22:13 - INFO - __main__ -     test_acc=0.4363
06/22/2023 06:22:13 - INFO - __main__ -     ********************
06/22/2023 06:22:13 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:22:13 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:22:19 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:22:19 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:22:19 - INFO - __main__ -     Num batches = 171
06/22/2023 06:22:19 - INFO - __main__ -     Batch size = 16
06/22/2023 06:22:28 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:22:28 - INFO - __main__ -     eval_acc = 0.4597
06/22/2023 06:22:28 - INFO - __main__ -     eval_loss = 0.7172
06/22/2023 06:22:28 - INFO - __main__ -     test_acc=0.4597
06/22/2023 06:22:28 - INFO - __main__ -     ********************
06/22/2023 06:22:28 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:22:28 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:22:29 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:22:29 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:22:29 - INFO - __main__ -     Batch size = 16
06/22/2023 06:22:29 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:22:30 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:22:35 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:22:35 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:22:35 - INFO - __main__ -     Num batches = 171
06/22/2023 06:22:35 - INFO - __main__ -     Batch size = 16
06/22/2023 06:22:44 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:22:44 - INFO - __main__ -     eval_acc = 0.5073
06/22/2023 06:22:44 - INFO - __main__ -     eval_loss = 0.7025
06/22/2023 06:22:44 - INFO - __main__ -     test_acc=0.5073
06/22/2023 06:22:44 - INFO - __main__ -     ********************
06/22/2023 06:22:44 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:22:45 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:22:50 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:22:50 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:22:50 - INFO - __main__ -     Num batches = 171
06/22/2023 06:22:50 - INFO - __main__ -     Batch size = 16
06/22/2023 06:22:59 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:22:59 - INFO - __main__ -     eval_acc = 0.5264
06/22/2023 06:22:59 - INFO - __main__ -     eval_loss = 0.6967
06/22/2023 06:22:59 - INFO - __main__ -     test_acc=0.5264
06/22/2023 06:22:59 - INFO - __main__ -     ********************
06/22/2023 06:22:59 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:22:59 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:23:01 - INFO - __main__ -   Finish loading model [125M] from roberta-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50
06/22/2023 06:23:01 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:23:01 - INFO - __main__ -     Batch size = 16
06/22/2023 06:23:01 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:23:01 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:23:07 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:23:07 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:23:07 - INFO - __main__ -     Num batches = 171
06/22/2023 06:23:07 - INFO - __main__ -     Batch size = 16
06/22/2023 06:23:16 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:23:16 - INFO - __main__ -     eval_acc = 0.4337
06/22/2023 06:23:16 - INFO - __main__ -     eval_loss = 0.7217
06/22/2023 06:23:16 - INFO - __main__ -     test_acc=0.4337
06/22/2023 06:23:16 - INFO - __main__ -     ********************
06/22/2023 06:23:16 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:23:17 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:23:22 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:23:22 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:23:22 - INFO - __main__ -     Num batches = 171
06/22/2023 06:23:22 - INFO - __main__ -     Batch size = 16
06/22/2023 06:23:31 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:23:31 - INFO - __main__ -     eval_acc = 0.4663
06/22/2023 06:23:31 - INFO - __main__ -     eval_loss = 0.7126
06/22/2023 06:23:31 - INFO - __main__ -     test_acc=0.4663
06/22/2023 06:23:31 - INFO - __main__ -     ********************
06/22/2023 06:23:31 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:23:31 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:23:33 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:23:33 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:23:33 - INFO - __main__ -     Batch size = 16
06/22/2023 06:23:33 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:23:33 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:23:37 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:23:37 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:23:37 - INFO - __main__ -     Num batches = 107
06/22/2023 06:23:37 - INFO - __main__ -     Batch size = 16
06/22/2023 06:23:42 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:23:42 - INFO - __main__ -     eval_acc = 0.4321
06/22/2023 06:23:42 - INFO - __main__ -     eval_loss = 0.7221
06/22/2023 06:23:42 - INFO - __main__ -     test_acc=0.4321
06/22/2023 06:23:42 - INFO - __main__ -     ********************
06/22/2023 06:23:42 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:23:43 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:23:46 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:23:46 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:23:46 - INFO - __main__ -     Num batches = 88
06/22/2023 06:23:46 - INFO - __main__ -     Batch size = 16
06/22/2023 06:23:51 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:23:51 - INFO - __main__ -     eval_acc = 0.4874
06/22/2023 06:23:51 - INFO - __main__ -     eval_loss = 0.7079
06/22/2023 06:23:51 - INFO - __main__ -     test_acc=0.4874
06/22/2023 06:23:51 - INFO - __main__ -     ********************
06/22/2023 06:23:51 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:23:51 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:23:52 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:23:52 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:23:52 - INFO - __main__ -     Batch size = 16
06/22/2023 06:23:52 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:23:52 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:23:58 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:23:58 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:23:58 - INFO - __main__ -     Num batches = 171
06/22/2023 06:23:58 - INFO - __main__ -     Batch size = 16
06/22/2023 06:24:07 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:24:07 - INFO - __main__ -     eval_acc = 0.4363
06/22/2023 06:24:07 - INFO - __main__ -     eval_loss = 0.721
06/22/2023 06:24:07 - INFO - __main__ -     test_acc=0.4363
06/22/2023 06:24:07 - INFO - __main__ -     ********************
06/22/2023 06:24:07 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:24:07 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:24:13 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:24:13 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:24:13 - INFO - __main__ -     Num batches = 171
06/22/2023 06:24:13 - INFO - __main__ -     Batch size = 16
06/22/2023 06:24:22 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:24:22 - INFO - __main__ -     eval_acc = 0.4597
06/22/2023 06:24:22 - INFO - __main__ -     eval_loss = 0.7144
06/22/2023 06:24:22 - INFO - __main__ -     test_acc=0.4597
06/22/2023 06:24:22 - INFO - __main__ -     ********************
06/22/2023 06:24:22 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:24:22 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:24:23 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:24:23 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:24:23 - INFO - __main__ -     Batch size = 16
06/22/2023 06:24:23 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:24:24 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:24:29 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:24:29 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:24:29 - INFO - __main__ -     Num batches = 171
06/22/2023 06:24:29 - INFO - __main__ -     Batch size = 16
06/22/2023 06:24:38 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:24:38 - INFO - __main__ -     eval_acc = 0.5073
06/22/2023 06:24:38 - INFO - __main__ -     eval_loss = 0.7007
06/22/2023 06:24:38 - INFO - __main__ -     test_acc=0.5073
06/22/2023 06:24:38 - INFO - __main__ -     ********************
06/22/2023 06:24:38 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:24:39 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:24:45 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:24:45 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:24:45 - INFO - __main__ -     Num batches = 171
06/22/2023 06:24:45 - INFO - __main__ -     Batch size = 16
06/22/2023 06:24:53 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:24:53 - INFO - __main__ -     eval_acc = 0.5264
06/22/2023 06:24:53 - INFO - __main__ -     eval_loss = 0.6955
06/22/2023 06:24:53 - INFO - __main__ -     test_acc=0.5264
06/22/2023 06:24:53 - INFO - __main__ -     ********************
06/22/2023 06:24:54 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:24:54 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:24:54 - INFO - __main__ -   Finish loading model [125M] from roberta-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50
06/22/2023 06:24:55 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:24:55 - INFO - __main__ -     Batch size = 16
06/22/2023 06:24:55 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:24:55 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:25:01 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:25:01 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:25:01 - INFO - __main__ -     Num batches = 171
06/22/2023 06:25:01 - INFO - __main__ -     Batch size = 16
06/22/2023 06:25:10 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:25:10 - INFO - __main__ -     eval_acc = 0.41
06/22/2023 06:25:10 - INFO - __main__ -     eval_loss = 1.9136
06/22/2023 06:25:10 - INFO - __main__ -     test_acc=0.4100
06/22/2023 06:25:10 - INFO - __main__ -     ********************
06/22/2023 06:25:10 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:25:10 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:25:16 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:25:16 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:25:16 - INFO - __main__ -     Num batches = 171
06/22/2023 06:25:16 - INFO - __main__ -     Batch size = 16
06/22/2023 06:25:25 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:25:25 - INFO - __main__ -     eval_acc = 0.4246
06/22/2023 06:25:25 - INFO - __main__ -     eval_loss = 1.8527
06/22/2023 06:25:25 - INFO - __main__ -     test_acc=0.4246
06/22/2023 06:25:25 - INFO - __main__ -     ********************
06/22/2023 06:25:25 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:25:25 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:25:26 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:25:26 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:25:26 - INFO - __main__ -     Batch size = 16
06/22/2023 06:25:26 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:25:27 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:25:31 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:25:31 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:25:31 - INFO - __main__ -     Num batches = 107
06/22/2023 06:25:31 - INFO - __main__ -     Batch size = 16
06/22/2023 06:25:36 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:25:36 - INFO - __main__ -     eval_acc = 0.4045
06/22/2023 06:25:36 - INFO - __main__ -     eval_loss = 2.0059
06/22/2023 06:25:36 - INFO - __main__ -     test_acc=0.4045
06/22/2023 06:25:36 - INFO - __main__ -     ********************
06/22/2023 06:25:36 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:25:36 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:25:40 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:25:40 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:25:40 - INFO - __main__ -     Num batches = 88
06/22/2023 06:25:40 - INFO - __main__ -     Batch size = 16
06/22/2023 06:25:44 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:25:44 - INFO - __main__ -     eval_acc = 0.3963
06/22/2023 06:25:44 - INFO - __main__ -     eval_loss = 2.0958
06/22/2023 06:25:44 - INFO - __main__ -     test_acc=0.3963
06/22/2023 06:25:44 - INFO - __main__ -     ********************
06/22/2023 06:25:44 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:25:44 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:25:45 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:25:46 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:25:46 - INFO - __main__ -     Batch size = 16
06/22/2023 06:25:46 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:25:46 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:25:52 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:25:52 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:25:52 - INFO - __main__ -     Num batches = 171
06/22/2023 06:25:52 - INFO - __main__ -     Batch size = 16
06/22/2023 06:26:01 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:26:01 - INFO - __main__ -     eval_acc = 0.3788
06/22/2023 06:26:01 - INFO - __main__ -     eval_loss = 2.1158
06/22/2023 06:26:01 - INFO - __main__ -     test_acc=0.3788
06/22/2023 06:26:01 - INFO - __main__ -     ********************
06/22/2023 06:26:01 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:26:01 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:26:07 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:26:07 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:26:07 - INFO - __main__ -     Num batches = 171
06/22/2023 06:26:07 - INFO - __main__ -     Batch size = 16
06/22/2023 06:26:16 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:26:16 - INFO - __main__ -     eval_acc = 0.3942
06/22/2023 06:26:16 - INFO - __main__ -     eval_loss = 2.065
06/22/2023 06:26:16 - INFO - __main__ -     test_acc=0.3942
06/22/2023 06:26:16 - INFO - __main__ -     ********************
06/22/2023 06:26:16 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:26:16 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:26:17 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:26:17 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:26:17 - INFO - __main__ -     Batch size = 16
06/22/2023 06:26:17 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:26:18 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:26:23 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:26:23 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:26:23 - INFO - __main__ -     Num batches = 171
06/22/2023 06:26:23 - INFO - __main__ -     Batch size = 16
06/22/2023 06:26:32 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:26:32 - INFO - __main__ -     eval_acc = 0.5626
06/22/2023 06:26:32 - INFO - __main__ -     eval_loss = 1.3511
06/22/2023 06:26:32 - INFO - __main__ -     test_acc=0.5626
06/22/2023 06:26:32 - INFO - __main__ -     ********************
06/22/2023 06:26:32 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:26:33 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:26:39 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:26:39 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:26:39 - INFO - __main__ -     Num batches = 171
06/22/2023 06:26:39 - INFO - __main__ -     Batch size = 16
06/22/2023 06:26:48 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:26:48 - INFO - __main__ -     eval_acc = 0.5242
06/22/2023 06:26:48 - INFO - __main__ -     eval_loss = 1.4526
06/22/2023 06:26:48 - INFO - __main__ -     test_acc=0.5242
06/22/2023 06:26:48 - INFO - __main__ -     ********************
06/22/2023 06:26:48 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:26:48 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:26:49 - INFO - __main__ -   Finish loading model [125M] from roberta-base
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50
06/22/2023 06:26:49 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:26:49 - INFO - __main__ -     Batch size = 16
06/22/2023 06:26:49 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:26:49 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:26:55 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:26:55 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:26:55 - INFO - __main__ -     Num batches = 171
06/22/2023 06:26:55 - INFO - __main__ -     Batch size = 16
06/22/2023 06:27:04 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:27:04 - INFO - __main__ -     eval_acc = 0.4337
06/22/2023 06:27:04 - INFO - __main__ -     eval_loss = 0.7233
06/22/2023 06:27:04 - INFO - __main__ -     test_acc=0.4337
06/22/2023 06:27:04 - INFO - __main__ -     ********************
06/22/2023 06:27:04 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:27:04 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:27:10 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:27:10 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:27:10 - INFO - __main__ -     Num batches = 171
06/22/2023 06:27:10 - INFO - __main__ -     Batch size = 16
06/22/2023 06:27:19 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:27:19 - INFO - __main__ -     eval_acc = 0.4663
06/22/2023 06:27:19 - INFO - __main__ -     eval_loss = 0.7139
06/22/2023 06:27:19 - INFO - __main__ -     test_acc=0.4663
06/22/2023 06:27:19 - INFO - __main__ -     ********************
06/22/2023 06:27:19 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:27:19 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:27:20 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:27:20 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:27:20 - INFO - __main__ -     Batch size = 16
06/22/2023 06:27:20 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:27:21 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:27:25 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:27:25 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:27:25 - INFO - __main__ -     Num batches = 107
06/22/2023 06:27:25 - INFO - __main__ -     Batch size = 16
06/22/2023 06:27:30 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:27:30 - INFO - __main__ -     eval_acc = 0.4321
06/22/2023 06:27:30 - INFO - __main__ -     eval_loss = 0.7238
06/22/2023 06:27:30 - INFO - __main__ -     test_acc=0.4321
06/22/2023 06:27:30 - INFO - __main__ -     ********************
06/22/2023 06:27:30 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:27:30 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:27:34 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:27:34 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:27:34 - INFO - __main__ -     Num batches = 88
06/22/2023 06:27:34 - INFO - __main__ -     Batch size = 16
06/22/2023 06:27:38 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:27:38 - INFO - __main__ -     eval_acc = 0.4874
06/22/2023 06:27:38 - INFO - __main__ -     eval_loss = 0.709
06/22/2023 06:27:38 - INFO - __main__ -     test_acc=0.4874
06/22/2023 06:27:38 - INFO - __main__ -     ********************
06/22/2023 06:27:38 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:27:38 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:27:39 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:27:39 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:27:39 - INFO - __main__ -     Batch size = 16
06/22/2023 06:27:39 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:27:40 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:27:46 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:27:46 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:27:46 - INFO - __main__ -     Num batches = 171
06/22/2023 06:27:46 - INFO - __main__ -     Batch size = 16
06/22/2023 06:27:55 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:27:55 - INFO - __main__ -     eval_acc = 0.4363
06/22/2023 06:27:55 - INFO - __main__ -     eval_loss = 0.7225
06/22/2023 06:27:55 - INFO - __main__ -     test_acc=0.4363
06/22/2023 06:27:55 - INFO - __main__ -     ********************
06/22/2023 06:27:55 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:27:55 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:28:01 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:28:01 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:28:01 - INFO - __main__ -     Num batches = 171
06/22/2023 06:28:01 - INFO - __main__ -     Batch size = 16
06/22/2023 06:28:10 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:28:10 - INFO - __main__ -     eval_acc = 0.4597
06/22/2023 06:28:10 - INFO - __main__ -     eval_loss = 0.7158
06/22/2023 06:28:10 - INFO - __main__ -     test_acc=0.4597
06/22/2023 06:28:10 - INFO - __main__ -     ********************
06/22/2023 06:28:10 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='roberta-base', model_type='roberta', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:28:10 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/22/2023 06:28:11 - INFO - __main__ -   Finish loading model [125M] from roberta-base
06/22/2023 06:28:11 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:28:11 - INFO - __main__ -     Batch size = 16
06/22/2023 06:28:11 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:28:11 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:28:17 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:28:17 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:28:17 - INFO - __main__ -     Num batches = 171
06/22/2023 06:28:17 - INFO - __main__ -     Batch size = 16
06/22/2023 06:28:26 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:28:26 - INFO - __main__ -     eval_acc = 0.5073
06/22/2023 06:28:26 - INFO - __main__ -     eval_loss = 0.7016
06/22/2023 06:28:26 - INFO - __main__ -     test_acc=0.5073
06/22/2023 06:28:26 - INFO - __main__ -     ********************
06/22/2023 06:28:26 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:28:26 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//roberta/clean/2/roberta_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:28:32 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:28:32 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:28:32 - INFO - __main__ -     Num batches = 171
06/22/2023 06:28:32 - INFO - __main__ -     Batch size = 16
06/22/2023 06:28:41 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:28:41 - INFO - __main__ -     eval_acc = 0.5264
06/22/2023 06:28:41 - INFO - __main__ -     eval_loss = 0.6961
06/22/2023 06:28:41 - INFO - __main__ -     test_acc=0.5264
06/22/2023 06:28:41 - INFO - __main__ -     ********************
06/22/2023 06:28:41 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:28:41 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:28:42 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50
06/22/2023 06:28:42 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:28:42 - INFO - __main__ -     Batch size = 16
06/22/2023 06:28:42 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:28:43 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:28:49 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:28:49 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:28:49 - INFO - __main__ -     Num batches = 171
06/22/2023 06:28:49 - INFO - __main__ -     Batch size = 16
06/22/2023 06:28:56 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:28:56 - INFO - __main__ -     eval_acc = 0.3792
06/22/2023 06:28:56 - INFO - __main__ -     eval_loss = 1.7016
06/22/2023 06:28:56 - INFO - __main__ -     test_acc=0.3792
06/22/2023 06:28:56 - INFO - __main__ -     ********************
06/22/2023 06:28:56 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:28:57 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:29:02 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:29:02 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:29:02 - INFO - __main__ -     Num batches = 171
06/22/2023 06:29:02 - INFO - __main__ -     Batch size = 16
06/22/2023 06:29:10 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:29:10 - INFO - __main__ -     eval_acc = 0.4012
06/22/2023 06:29:10 - INFO - __main__ -     eval_loss = 1.5891
06/22/2023 06:29:10 - INFO - __main__ -     test_acc=0.4012
06/22/2023 06:29:10 - INFO - __main__ -     ********************
06/22/2023 06:29:10 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:29:10 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:29:11 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:29:11 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:29:11 - INFO - __main__ -     Batch size = 16
06/22/2023 06:29:11 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:29:12 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:29:15 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:29:15 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:29:15 - INFO - __main__ -     Num batches = 107
06/22/2023 06:29:15 - INFO - __main__ -     Batch size = 16
06/22/2023 06:29:20 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:29:20 - INFO - __main__ -     eval_acc = 0.3533
06/22/2023 06:29:20 - INFO - __main__ -     eval_loss = 1.7212
06/22/2023 06:29:20 - INFO - __main__ -     test_acc=0.3533
06/22/2023 06:29:20 - INFO - __main__ -     ********************
06/22/2023 06:29:20 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:29:20 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:29:24 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:29:24 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:29:24 - INFO - __main__ -     Num batches = 88
06/22/2023 06:29:24 - INFO - __main__ -     Batch size = 16
06/22/2023 06:29:28 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:29:28 - INFO - __main__ -     eval_acc = 0.3776
06/22/2023 06:29:28 - INFO - __main__ -     eval_loss = 1.6466
06/22/2023 06:29:28 - INFO - __main__ -     test_acc=0.3776
06/22/2023 06:29:28 - INFO - __main__ -     ********************
06/22/2023 06:29:28 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:29:28 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:29:29 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:29:29 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:29:29 - INFO - __main__ -     Batch size = 16
06/22/2023 06:29:29 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:29:29 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:29:35 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:29:35 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:29:35 - INFO - __main__ -     Num batches = 171
06/22/2023 06:29:35 - INFO - __main__ -     Batch size = 16
06/22/2023 06:29:43 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:29:43 - INFO - __main__ -     eval_acc = 0.3499
06/22/2023 06:29:43 - INFO - __main__ -     eval_loss = 1.8318
06/22/2023 06:29:43 - INFO - __main__ -     test_acc=0.3499
06/22/2023 06:29:43 - INFO - __main__ -     ********************
06/22/2023 06:29:43 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:29:43 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:29:49 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:29:49 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:29:49 - INFO - __main__ -     Num batches = 171
06/22/2023 06:29:49 - INFO - __main__ -     Batch size = 16
06/22/2023 06:29:56 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:29:56 - INFO - __main__ -     eval_acc = 0.381
06/22/2023 06:29:56 - INFO - __main__ -     eval_loss = 1.6886
06/22/2023 06:29:56 - INFO - __main__ -     test_acc=0.3810
06/22/2023 06:29:56 - INFO - __main__ -     ********************
06/22/2023 06:29:57 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:29:57 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:29:57 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:29:57 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:29:57 - INFO - __main__ -     Batch size = 16
06/22/2023 06:29:57 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:29:58 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:30:04 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:30:04 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:30:04 - INFO - __main__ -     Num batches = 171
06/22/2023 06:30:04 - INFO - __main__ -     Batch size = 16
06/22/2023 06:30:11 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:30:11 - INFO - __main__ -     eval_acc = 0.5615
06/22/2023 06:30:11 - INFO - __main__ -     eval_loss = 1.0074
06/22/2023 06:30:11 - INFO - __main__ -     test_acc=0.5615
06/22/2023 06:30:11 - INFO - __main__ -     ********************
06/22/2023 06:30:11 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:30:12 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:30:17 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:30:17 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:30:17 - INFO - __main__ -     Num batches = 171
06/22/2023 06:30:17 - INFO - __main__ -     Batch size = 16
06/22/2023 06:30:25 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:30:25 - INFO - __main__ -     eval_acc = 0.545
06/22/2023 06:30:25 - INFO - __main__ -     eval_loss = 1.0229
06/22/2023 06:30:25 - INFO - __main__ -     test_acc=0.5450
06/22/2023 06:30:25 - INFO - __main__ -     ********************
06/22/2023 06:30:25 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:30:25 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:30:26 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50
06/22/2023 06:30:26 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:30:26 - INFO - __main__ -     Batch size = 16
06/22/2023 06:30:26 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:30:27 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:30:33 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:30:33 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:30:33 - INFO - __main__ -     Num batches = 171
06/22/2023 06:30:33 - INFO - __main__ -     Batch size = 16
06/22/2023 06:30:40 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:30:40 - INFO - __main__ -     eval_acc = 0.3851
06/22/2023 06:30:40 - INFO - __main__ -     eval_loss = 1.3467
06/22/2023 06:30:40 - INFO - __main__ -     test_acc=0.3851
06/22/2023 06:30:40 - INFO - __main__ -     ********************
06/22/2023 06:30:40 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:30:40 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:30:47 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:30:47 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:30:47 - INFO - __main__ -     Num batches = 171
06/22/2023 06:30:47 - INFO - __main__ -     Batch size = 16
06/22/2023 06:30:54 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:30:54 - INFO - __main__ -     eval_acc = 0.4048
06/22/2023 06:30:54 - INFO - __main__ -     eval_loss = 1.2862
06/22/2023 06:30:54 - INFO - __main__ -     test_acc=0.4048
06/22/2023 06:30:54 - INFO - __main__ -     ********************
06/22/2023 06:30:54 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:30:54 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:30:55 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:30:56 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:30:56 - INFO - __main__ -     Batch size = 16
06/22/2023 06:30:56 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:30:56 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:31:00 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:31:00 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:31:00 - INFO - __main__ -     Num batches = 107
06/22/2023 06:31:00 - INFO - __main__ -     Batch size = 16
06/22/2023 06:31:04 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:31:04 - INFO - __main__ -     eval_acc = 0.3768
06/22/2023 06:31:04 - INFO - __main__ -     eval_loss = 1.3485
06/22/2023 06:31:04 - INFO - __main__ -     test_acc=0.3768
06/22/2023 06:31:04 - INFO - __main__ -     ********************
06/22/2023 06:31:04 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:31:05 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:31:08 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:31:08 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:31:08 - INFO - __main__ -     Num batches = 88
06/22/2023 06:31:08 - INFO - __main__ -     Batch size = 16
06/22/2023 06:31:12 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:31:12 - INFO - __main__ -     eval_acc = 0.3812
06/22/2023 06:31:12 - INFO - __main__ -     eval_loss = 1.2978
06/22/2023 06:31:12 - INFO - __main__ -     test_acc=0.3812
06/22/2023 06:31:12 - INFO - __main__ -     ********************
06/22/2023 06:31:12 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:31:12 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:31:13 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:31:13 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:31:13 - INFO - __main__ -     Batch size = 16
06/22/2023 06:31:13 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:31:13 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:31:19 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:31:19 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:31:19 - INFO - __main__ -     Num batches = 171
06/22/2023 06:31:19 - INFO - __main__ -     Batch size = 16
06/22/2023 06:31:27 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:31:27 - INFO - __main__ -     eval_acc = 0.369
06/22/2023 06:31:27 - INFO - __main__ -     eval_loss = 1.4558
06/22/2023 06:31:27 - INFO - __main__ -     test_acc=0.3690
06/22/2023 06:31:27 - INFO - __main__ -     ********************
06/22/2023 06:31:27 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:31:27 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:31:33 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:31:33 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:31:33 - INFO - __main__ -     Num batches = 171
06/22/2023 06:31:33 - INFO - __main__ -     Batch size = 16
06/22/2023 06:31:41 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:31:41 - INFO - __main__ -     eval_acc = 0.3814
06/22/2023 06:31:41 - INFO - __main__ -     eval_loss = 1.3602
06/22/2023 06:31:41 - INFO - __main__ -     test_acc=0.3814
06/22/2023 06:31:41 - INFO - __main__ -     ********************
06/22/2023 06:31:41 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:31:41 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:31:42 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:31:42 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:31:42 - INFO - __main__ -     Batch size = 16
06/22/2023 06:31:42 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:31:42 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:31:48 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:31:48 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:31:48 - INFO - __main__ -     Num batches = 171
06/22/2023 06:31:48 - INFO - __main__ -     Batch size = 16
06/22/2023 06:31:56 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:31:56 - INFO - __main__ -     eval_acc = 0.5567
06/22/2023 06:31:56 - INFO - __main__ -     eval_loss = 0.8745
06/22/2023 06:31:56 - INFO - __main__ -     test_acc=0.5567
06/22/2023 06:31:56 - INFO - __main__ -     ********************
06/22/2023 06:31:56 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:31:56 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:32:02 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:32:02 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:32:02 - INFO - __main__ -     Num batches = 171
06/22/2023 06:32:02 - INFO - __main__ -     Batch size = 16
06/22/2023 06:32:10 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:32:10 - INFO - __main__ -     eval_acc = 0.5344
06/22/2023 06:32:10 - INFO - __main__ -     eval_loss = 0.8811
06/22/2023 06:32:10 - INFO - __main__ -     test_acc=0.5344
06/22/2023 06:32:10 - INFO - __main__ -     ********************
06/22/2023 06:32:10 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:32:10 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:32:11 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50
06/22/2023 06:32:11 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:32:11 - INFO - __main__ -     Batch size = 16
06/22/2023 06:32:11 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:32:11 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:32:17 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:32:17 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:32:17 - INFO - __main__ -     Num batches = 171
06/22/2023 06:32:17 - INFO - __main__ -     Batch size = 16
06/22/2023 06:32:25 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:32:25 - INFO - __main__ -     eval_acc = 0.3832
06/22/2023 06:32:25 - INFO - __main__ -     eval_loss = 1.592
06/22/2023 06:32:25 - INFO - __main__ -     test_acc=0.3832
06/22/2023 06:32:25 - INFO - __main__ -     ********************
06/22/2023 06:32:25 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:32:25 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:32:31 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:32:31 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:32:31 - INFO - __main__ -     Num batches = 171
06/22/2023 06:32:31 - INFO - __main__ -     Batch size = 16
06/22/2023 06:32:39 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:32:39 - INFO - __main__ -     eval_acc = 0.407
06/22/2023 06:32:39 - INFO - __main__ -     eval_loss = 1.4864
06/22/2023 06:32:39 - INFO - __main__ -     test_acc=0.4070
06/22/2023 06:32:39 - INFO - __main__ -     ********************
06/22/2023 06:32:39 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:32:39 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:32:40 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:32:40 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:32:40 - INFO - __main__ -     Batch size = 16
06/22/2023 06:32:40 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:32:40 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:32:44 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:32:44 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:32:44 - INFO - __main__ -     Num batches = 107
06/22/2023 06:32:44 - INFO - __main__ -     Batch size = 16
06/22/2023 06:32:49 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:32:49 - INFO - __main__ -     eval_acc = 0.3621
06/22/2023 06:32:49 - INFO - __main__ -     eval_loss = 1.5763
06/22/2023 06:32:49 - INFO - __main__ -     test_acc=0.3621
06/22/2023 06:32:49 - INFO - __main__ -     ********************
06/22/2023 06:32:49 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:32:49 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:32:52 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:32:52 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:32:52 - INFO - __main__ -     Num batches = 88
06/22/2023 06:32:52 - INFO - __main__ -     Batch size = 16
06/22/2023 06:32:56 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:32:56 - INFO - __main__ -     eval_acc = 0.3747
06/22/2023 06:32:56 - INFO - __main__ -     eval_loss = 1.5106
06/22/2023 06:32:56 - INFO - __main__ -     test_acc=0.3747
06/22/2023 06:32:56 - INFO - __main__ -     ********************
06/22/2023 06:32:56 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:32:56 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:32:57 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:32:57 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:32:57 - INFO - __main__ -     Batch size = 16
06/22/2023 06:32:57 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:32:58 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:33:04 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:33:04 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:33:04 - INFO - __main__ -     Num batches = 171
06/22/2023 06:33:04 - INFO - __main__ -     Batch size = 16
06/22/2023 06:33:11 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:33:11 - INFO - __main__ -     eval_acc = 0.3415
06/22/2023 06:33:11 - INFO - __main__ -     eval_loss = 1.6933
06/22/2023 06:33:11 - INFO - __main__ -     test_acc=0.3415
06/22/2023 06:33:11 - INFO - __main__ -     ********************
06/22/2023 06:33:11 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:33:12 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:33:17 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:33:17 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:33:17 - INFO - __main__ -     Num batches = 171
06/22/2023 06:33:17 - INFO - __main__ -     Batch size = 16
06/22/2023 06:33:25 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:33:25 - INFO - __main__ -     eval_acc = 0.3752
06/22/2023 06:33:25 - INFO - __main__ -     eval_loss = 1.5616
06/22/2023 06:33:25 - INFO - __main__ -     test_acc=0.3752
06/22/2023 06:33:25 - INFO - __main__ -     ********************
06/22/2023 06:33:25 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:33:25 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:33:26 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:33:26 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:33:26 - INFO - __main__ -     Batch size = 16
06/22/2023 06:33:26 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:33:26 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:33:32 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:33:32 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:33:32 - INFO - __main__ -     Num batches = 171
06/22/2023 06:33:32 - INFO - __main__ -     Batch size = 16
06/22/2023 06:33:40 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:33:40 - INFO - __main__ -     eval_acc = 0.5549
06/22/2023 06:33:40 - INFO - __main__ -     eval_loss = 0.9433
06/22/2023 06:33:40 - INFO - __main__ -     test_acc=0.5549
06/22/2023 06:33:40 - INFO - __main__ -     ********************
06/22/2023 06:33:40 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:33:40 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:33:46 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:33:46 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:33:46 - INFO - __main__ -     Num batches = 171
06/22/2023 06:33:46 - INFO - __main__ -     Batch size = 16
06/22/2023 06:33:54 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:33:54 - INFO - __main__ -     eval_acc = 0.5403
06/22/2023 06:33:54 - INFO - __main__ -     eval_loss = 0.9365
06/22/2023 06:33:54 - INFO - __main__ -     test_acc=0.5403
06/22/2023 06:33:54 - INFO - __main__ -     ********************
06/22/2023 06:33:54 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:33:54 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:33:55 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50
06/22/2023 06:33:55 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:33:55 - INFO - __main__ -     Batch size = 16
06/22/2023 06:33:55 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:33:55 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:34:01 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:34:01 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:34:01 - INFO - __main__ -     Num batches = 171
06/22/2023 06:34:01 - INFO - __main__ -     Batch size = 16
06/22/2023 06:34:09 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:34:09 - INFO - __main__ -     eval_acc = 0.3862
06/22/2023 06:34:09 - INFO - __main__ -     eval_loss = 1.2857
06/22/2023 06:34:09 - INFO - __main__ -     test_acc=0.3862
06/22/2023 06:34:09 - INFO - __main__ -     ********************
06/22/2023 06:34:09 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:34:09 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:34:15 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:34:15 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:34:15 - INFO - __main__ -     Num batches = 171
06/22/2023 06:34:15 - INFO - __main__ -     Batch size = 16
06/22/2023 06:34:23 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:34:23 - INFO - __main__ -     eval_acc = 0.4143
06/22/2023 06:34:23 - INFO - __main__ -     eval_loss = 1.2049
06/22/2023 06:34:23 - INFO - __main__ -     test_acc=0.4143
06/22/2023 06:34:23 - INFO - __main__ -     ********************
06/22/2023 06:34:23 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:34:23 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:34:24 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:34:24 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:34:24 - INFO - __main__ -     Batch size = 16
06/22/2023 06:34:24 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:34:24 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:34:28 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:34:28 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:34:28 - INFO - __main__ -     Num batches = 107
06/22/2023 06:34:28 - INFO - __main__ -     Batch size = 16
06/22/2023 06:34:33 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:34:33 - INFO - __main__ -     eval_acc = 0.381
06/22/2023 06:34:33 - INFO - __main__ -     eval_loss = 1.3075
06/22/2023 06:34:33 - INFO - __main__ -     test_acc=0.3810
06/22/2023 06:34:33 - INFO - __main__ -     ********************
06/22/2023 06:34:33 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:34:33 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:34:36 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:34:36 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:34:36 - INFO - __main__ -     Num batches = 88
06/22/2023 06:34:36 - INFO - __main__ -     Batch size = 16
06/22/2023 06:34:40 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:34:40 - INFO - __main__ -     eval_acc = 0.3891
06/22/2023 06:34:40 - INFO - __main__ -     eval_loss = 1.2176
06/22/2023 06:34:40 - INFO - __main__ -     test_acc=0.3891
06/22/2023 06:34:40 - INFO - __main__ -     ********************
06/22/2023 06:34:40 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:34:40 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:34:41 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:34:41 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:34:41 - INFO - __main__ -     Batch size = 16
06/22/2023 06:34:41 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:34:42 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:34:48 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:34:48 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:34:48 - INFO - __main__ -     Num batches = 171
06/22/2023 06:34:48 - INFO - __main__ -     Batch size = 16
06/22/2023 06:34:55 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:34:55 - INFO - __main__ -     eval_acc = 0.3646
06/22/2023 06:34:55 - INFO - __main__ -     eval_loss = 1.3499
06/22/2023 06:34:55 - INFO - __main__ -     test_acc=0.3646
06/22/2023 06:34:55 - INFO - __main__ -     ********************
06/22/2023 06:34:55 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:34:56 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:35:01 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:35:01 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:35:01 - INFO - __main__ -     Num batches = 171
06/22/2023 06:35:01 - INFO - __main__ -     Batch size = 16
06/22/2023 06:35:09 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:35:09 - INFO - __main__ -     eval_acc = 0.3895
06/22/2023 06:35:09 - INFO - __main__ -     eval_loss = 1.2513
06/22/2023 06:35:09 - INFO - __main__ -     test_acc=0.3895
06/22/2023 06:35:09 - INFO - __main__ -     ********************
06/22/2023 06:35:09 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:35:09 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:35:10 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:35:10 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:35:10 - INFO - __main__ -     Batch size = 16
06/22/2023 06:35:10 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:35:10 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:35:16 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:35:16 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:35:16 - INFO - __main__ -     Num batches = 171
06/22/2023 06:35:16 - INFO - __main__ -     Batch size = 16
06/22/2023 06:35:24 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:35:24 - INFO - __main__ -     eval_acc = 0.5498
06/22/2023 06:35:24 - INFO - __main__ -     eval_loss = 0.8208
06/22/2023 06:35:24 - INFO - __main__ -     test_acc=0.5498
06/22/2023 06:35:24 - INFO - __main__ -     ********************
06/22/2023 06:35:24 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:35:24 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:35:30 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:35:30 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:35:30 - INFO - __main__ -     Num batches = 171
06/22/2023 06:35:30 - INFO - __main__ -     Batch size = 16
06/22/2023 06:35:38 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:35:38 - INFO - __main__ -     eval_acc = 0.5286
06/22/2023 06:35:38 - INFO - __main__ -     eval_loss = 0.8249
06/22/2023 06:35:38 - INFO - __main__ -     test_acc=0.5286
06/22/2023 06:35:38 - INFO - __main__ -     ********************
06/22/2023 06:35:38 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:35:38 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:35:39 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50
06/22/2023 06:35:39 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:35:39 - INFO - __main__ -     Batch size = 16
06/22/2023 06:35:39 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:35:39 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:35:45 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:35:45 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:35:45 - INFO - __main__ -     Num batches = 171
06/22/2023 06:35:45 - INFO - __main__ -     Batch size = 16
06/22/2023 06:35:53 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:35:53 - INFO - __main__ -     eval_acc = 0.3803
06/22/2023 06:35:53 - INFO - __main__ -     eval_loss = 1.6605
06/22/2023 06:35:53 - INFO - __main__ -     test_acc=0.3803
06/22/2023 06:35:53 - INFO - __main__ -     ********************
06/22/2023 06:35:53 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:35:53 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:35:59 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:35:59 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:35:59 - INFO - __main__ -     Num batches = 171
06/22/2023 06:35:59 - INFO - __main__ -     Batch size = 16
06/22/2023 06:36:07 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:36:07 - INFO - __main__ -     eval_acc = 0.3946
06/22/2023 06:36:07 - INFO - __main__ -     eval_loss = 1.5522
06/22/2023 06:36:07 - INFO - __main__ -     test_acc=0.3946
06/22/2023 06:36:07 - INFO - __main__ -     ********************
06/22/2023 06:36:07 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:36:07 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:36:08 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:36:08 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:36:08 - INFO - __main__ -     Batch size = 16
06/22/2023 06:36:08 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:36:08 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:36:12 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:36:12 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:36:12 - INFO - __main__ -     Num batches = 107
06/22/2023 06:36:12 - INFO - __main__ -     Batch size = 16
06/22/2023 06:36:17 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:36:17 - INFO - __main__ -     eval_acc = 0.3621
06/22/2023 06:36:17 - INFO - __main__ -     eval_loss = 1.6511
06/22/2023 06:36:17 - INFO - __main__ -     test_acc=0.3621
06/22/2023 06:36:17 - INFO - __main__ -     ********************
06/22/2023 06:36:17 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:36:17 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:36:20 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:36:20 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:36:20 - INFO - __main__ -     Num batches = 88
06/22/2023 06:36:20 - INFO - __main__ -     Batch size = 16
06/22/2023 06:36:24 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:36:24 - INFO - __main__ -     eval_acc = 0.3582
06/22/2023 06:36:24 - INFO - __main__ -     eval_loss = 1.592
06/22/2023 06:36:24 - INFO - __main__ -     test_acc=0.3582
06/22/2023 06:36:24 - INFO - __main__ -     ********************
06/22/2023 06:36:24 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:36:24 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:36:25 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:36:25 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:36:25 - INFO - __main__ -     Batch size = 16
06/22/2023 06:36:25 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:36:26 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:36:32 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:36:32 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:36:32 - INFO - __main__ -     Num batches = 171
06/22/2023 06:36:32 - INFO - __main__ -     Batch size = 16
06/22/2023 06:36:39 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:36:39 - INFO - __main__ -     eval_acc = 0.3547
06/22/2023 06:36:39 - INFO - __main__ -     eval_loss = 1.7678
06/22/2023 06:36:39 - INFO - __main__ -     test_acc=0.3547
06/22/2023 06:36:39 - INFO - __main__ -     ********************
06/22/2023 06:36:39 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:36:40 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:36:45 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:36:45 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:36:45 - INFO - __main__ -     Num batches = 171
06/22/2023 06:36:45 - INFO - __main__ -     Batch size = 16
06/22/2023 06:36:53 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:36:53 - INFO - __main__ -     eval_acc = 0.3734
06/22/2023 06:36:53 - INFO - __main__ -     eval_loss = 1.6527
06/22/2023 06:36:53 - INFO - __main__ -     test_acc=0.3734
06/22/2023 06:36:53 - INFO - __main__ -     ********************
06/22/2023 06:36:53 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:36:53 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:36:54 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:36:54 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:36:54 - INFO - __main__ -     Batch size = 16
06/22/2023 06:36:54 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:36:54 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:37:00 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:37:00 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:37:00 - INFO - __main__ -     Num batches = 171
06/22/2023 06:37:00 - INFO - __main__ -     Batch size = 16
06/22/2023 06:37:08 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:37:08 - INFO - __main__ -     eval_acc = 0.56
06/22/2023 06:37:08 - INFO - __main__ -     eval_loss = 0.9643
06/22/2023 06:37:08 - INFO - __main__ -     test_acc=0.5600
06/22/2023 06:37:08 - INFO - __main__ -     ********************
06/22/2023 06:37:08 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:37:08 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:37:14 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:37:14 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:37:14 - INFO - __main__ -     Num batches = 171
06/22/2023 06:37:14 - INFO - __main__ -     Batch size = 16
06/22/2023 06:37:22 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:37:22 - INFO - __main__ -     eval_acc = 0.5472
06/22/2023 06:37:22 - INFO - __main__ -     eval_loss = 0.9639
06/22/2023 06:37:22 - INFO - __main__ -     test_acc=0.5472
06/22/2023 06:37:22 - INFO - __main__ -     ********************
06/22/2023 06:37:22 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:37:22 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:37:23 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50
06/22/2023 06:37:23 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:37:23 - INFO - __main__ -     Batch size = 16
06/22/2023 06:37:23 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:37:23 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:37:29 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:37:29 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:37:29 - INFO - __main__ -     Num batches = 171
06/22/2023 06:37:29 - INFO - __main__ -     Batch size = 16
06/22/2023 06:37:37 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:37:37 - INFO - __main__ -     eval_acc = 0.4085
06/22/2023 06:37:37 - INFO - __main__ -     eval_loss = 1.1074
06/22/2023 06:37:37 - INFO - __main__ -     test_acc=0.4085
06/22/2023 06:37:37 - INFO - __main__ -     ********************
06/22/2023 06:37:37 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:37:37 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:37:43 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:37:43 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:37:43 - INFO - __main__ -     Num batches = 171
06/22/2023 06:37:43 - INFO - __main__ -     Batch size = 16
06/22/2023 06:37:51 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:37:51 - INFO - __main__ -     eval_acc = 0.4224
06/22/2023 06:37:51 - INFO - __main__ -     eval_loss = 1.0663
06/22/2023 06:37:51 - INFO - __main__ -     test_acc=0.4224
06/22/2023 06:37:51 - INFO - __main__ -     ********************
06/22/2023 06:37:51 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:37:51 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:37:52 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:37:52 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:37:52 - INFO - __main__ -     Batch size = 16
06/22/2023 06:37:52 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:37:52 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:37:56 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:37:56 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:37:56 - INFO - __main__ -     Num batches = 107
06/22/2023 06:37:56 - INFO - __main__ -     Batch size = 16
06/22/2023 06:38:01 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:38:01 - INFO - __main__ -     eval_acc = 0.3992
06/22/2023 06:38:01 - INFO - __main__ -     eval_loss = 1.1351
06/22/2023 06:38:01 - INFO - __main__ -     test_acc=0.3992
06/22/2023 06:38:01 - INFO - __main__ -     ********************
06/22/2023 06:38:01 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:38:01 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:38:04 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:38:04 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:38:04 - INFO - __main__ -     Num batches = 88
06/22/2023 06:38:04 - INFO - __main__ -     Batch size = 16
06/22/2023 06:38:08 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:38:08 - INFO - __main__ -     eval_acc = 0.4056
06/22/2023 06:38:08 - INFO - __main__ -     eval_loss = 1.1156
06/22/2023 06:38:08 - INFO - __main__ -     test_acc=0.4056
06/22/2023 06:38:08 - INFO - __main__ -     ********************
06/22/2023 06:38:08 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:38:08 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:38:09 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:38:09 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:38:09 - INFO - __main__ -     Batch size = 16
06/22/2023 06:38:09 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:38:10 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:38:16 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:38:16 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:38:16 - INFO - __main__ -     Num batches = 171
06/22/2023 06:38:16 - INFO - __main__ -     Batch size = 16
06/22/2023 06:38:23 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:38:23 - INFO - __main__ -     eval_acc = 0.3876
06/22/2023 06:38:23 - INFO - __main__ -     eval_loss = 1.1553
06/22/2023 06:38:23 - INFO - __main__ -     test_acc=0.3876
06/22/2023 06:38:23 - INFO - __main__ -     ********************
06/22/2023 06:38:23 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:38:23 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:38:29 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:38:29 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:38:29 - INFO - __main__ -     Num batches = 171
06/22/2023 06:38:29 - INFO - __main__ -     Batch size = 16
06/22/2023 06:38:37 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:38:37 - INFO - __main__ -     eval_acc = 0.4096
06/22/2023 06:38:37 - INFO - __main__ -     eval_loss = 1.1075
06/22/2023 06:38:37 - INFO - __main__ -     test_acc=0.4096
06/22/2023 06:38:37 - INFO - __main__ -     ********************
06/22/2023 06:38:37 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:38:37 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:38:38 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:38:38 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:38:38 - INFO - __main__ -     Batch size = 16
06/22/2023 06:38:38 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:38:38 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:38:44 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:38:44 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:38:44 - INFO - __main__ -     Num batches = 171
06/22/2023 06:38:44 - INFO - __main__ -     Batch size = 16
06/22/2023 06:38:52 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:38:52 - INFO - __main__ -     eval_acc = 0.5619
06/22/2023 06:38:52 - INFO - __main__ -     eval_loss = 0.7809
06/22/2023 06:38:52 - INFO - __main__ -     test_acc=0.5619
06/22/2023 06:38:52 - INFO - __main__ -     ********************
06/22/2023 06:38:52 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:38:52 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/1/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:38:58 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:38:58 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:38:58 - INFO - __main__ -     Num batches = 171
06/22/2023 06:38:58 - INFO - __main__ -     Batch size = 16
06/22/2023 06:39:06 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:39:06 - INFO - __main__ -     eval_acc = 0.5351
06/22/2023 06:39:06 - INFO - __main__ -     eval_loss = 0.812
06/22/2023 06:39:06 - INFO - __main__ -     test_acc=0.5351
06/22/2023 06:39:06 - INFO - __main__ -     ********************
06/22/2023 06:39:06 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:39:06 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:39:07 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50
06/22/2023 06:39:07 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:39:07 - INFO - __main__ -     Batch size = 16
06/22/2023 06:39:07 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:39:07 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:39:13 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:39:13 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:39:13 - INFO - __main__ -     Num batches = 171
06/22/2023 06:39:13 - INFO - __main__ -     Batch size = 16
06/22/2023 06:39:21 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:39:21 - INFO - __main__ -     eval_acc = 0.3792
06/22/2023 06:39:21 - INFO - __main__ -     eval_loss = 1.7016
06/22/2023 06:39:21 - INFO - __main__ -     test_acc=0.3792
06/22/2023 06:39:21 - INFO - __main__ -     ********************
06/22/2023 06:39:21 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:39:21 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:39:27 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:39:27 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:39:27 - INFO - __main__ -     Num batches = 171
06/22/2023 06:39:27 - INFO - __main__ -     Batch size = 16
06/22/2023 06:39:35 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:39:35 - INFO - __main__ -     eval_acc = 0.4012
06/22/2023 06:39:35 - INFO - __main__ -     eval_loss = 1.5891
06/22/2023 06:39:35 - INFO - __main__ -     test_acc=0.4012
06/22/2023 06:39:35 - INFO - __main__ -     ********************
06/22/2023 06:39:35 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:39:35 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:39:36 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:39:36 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:39:36 - INFO - __main__ -     Batch size = 16
06/22/2023 06:39:36 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:39:36 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:39:40 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:39:40 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:39:40 - INFO - __main__ -     Num batches = 107
06/22/2023 06:39:40 - INFO - __main__ -     Batch size = 16
06/22/2023 06:39:45 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:39:45 - INFO - __main__ -     eval_acc = 0.3533
06/22/2023 06:39:45 - INFO - __main__ -     eval_loss = 1.7212
06/22/2023 06:39:45 - INFO - __main__ -     test_acc=0.3533
06/22/2023 06:39:45 - INFO - __main__ -     ********************
06/22/2023 06:39:45 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:39:45 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:39:48 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:39:48 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:39:48 - INFO - __main__ -     Num batches = 88
06/22/2023 06:39:48 - INFO - __main__ -     Batch size = 16
06/22/2023 06:39:52 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:39:52 - INFO - __main__ -     eval_acc = 0.3776
06/22/2023 06:39:52 - INFO - __main__ -     eval_loss = 1.6466
06/22/2023 06:39:52 - INFO - __main__ -     test_acc=0.3776
06/22/2023 06:39:52 - INFO - __main__ -     ********************
06/22/2023 06:39:52 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:39:52 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:39:53 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:39:53 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:39:53 - INFO - __main__ -     Batch size = 16
06/22/2023 06:39:53 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:39:54 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:40:00 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:40:00 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:40:00 - INFO - __main__ -     Num batches = 171
06/22/2023 06:40:00 - INFO - __main__ -     Batch size = 16
06/22/2023 06:40:07 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:40:07 - INFO - __main__ -     eval_acc = 0.3499
06/22/2023 06:40:07 - INFO - __main__ -     eval_loss = 1.8318
06/22/2023 06:40:07 - INFO - __main__ -     test_acc=0.3499
06/22/2023 06:40:07 - INFO - __main__ -     ********************
06/22/2023 06:40:07 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:40:08 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:40:13 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:40:13 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:40:13 - INFO - __main__ -     Num batches = 171
06/22/2023 06:40:13 - INFO - __main__ -     Batch size = 16
06/22/2023 06:40:21 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:40:21 - INFO - __main__ -     eval_acc = 0.381
06/22/2023 06:40:21 - INFO - __main__ -     eval_loss = 1.6886
06/22/2023 06:40:21 - INFO - __main__ -     test_acc=0.3810
06/22/2023 06:40:21 - INFO - __main__ -     ********************
06/22/2023 06:40:21 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:40:21 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:40:22 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:40:22 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:40:22 - INFO - __main__ -     Batch size = 16
06/22/2023 06:40:22 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:40:22 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:40:28 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:40:28 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:40:28 - INFO - __main__ -     Num batches = 171
06/22/2023 06:40:28 - INFO - __main__ -     Batch size = 16
06/22/2023 06:40:36 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:40:36 - INFO - __main__ -     eval_acc = 0.5615
06/22/2023 06:40:36 - INFO - __main__ -     eval_loss = 1.0074
06/22/2023 06:40:36 - INFO - __main__ -     test_acc=0.5615
06/22/2023 06:40:36 - INFO - __main__ -     ********************
06/22/2023 06:40:36 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:40:36 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr6_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:40:42 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:40:42 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:40:42 - INFO - __main__ -     Num batches = 171
06/22/2023 06:40:42 - INFO - __main__ -     Batch size = 16
06/22/2023 06:40:50 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:40:50 - INFO - __main__ -     eval_acc = 0.545
06/22/2023 06:40:50 - INFO - __main__ -     eval_loss = 1.0229
06/22/2023 06:40:50 - INFO - __main__ -     test_acc=0.5450
06/22/2023 06:40:50 - INFO - __main__ -     ********************
06/22/2023 06:40:50 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:40:50 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:40:51 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50
06/22/2023 06:40:51 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:40:51 - INFO - __main__ -     Batch size = 16
06/22/2023 06:40:51 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:40:51 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:40:57 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:40:57 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:40:57 - INFO - __main__ -     Num batches = 171
06/22/2023 06:40:57 - INFO - __main__ -     Batch size = 16
06/22/2023 06:41:05 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:41:05 - INFO - __main__ -     eval_acc = 0.3851
06/22/2023 06:41:05 - INFO - __main__ -     eval_loss = 1.3467
06/22/2023 06:41:05 - INFO - __main__ -     test_acc=0.3851
06/22/2023 06:41:05 - INFO - __main__ -     ********************
06/22/2023 06:41:05 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:41:05 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:41:11 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:41:11 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:41:11 - INFO - __main__ -     Num batches = 171
06/22/2023 06:41:11 - INFO - __main__ -     Batch size = 16
06/22/2023 06:41:19 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:41:19 - INFO - __main__ -     eval_acc = 0.4048
06/22/2023 06:41:19 - INFO - __main__ -     eval_loss = 1.2862
06/22/2023 06:41:19 - INFO - __main__ -     test_acc=0.4048
06/22/2023 06:41:19 - INFO - __main__ -     ********************
06/22/2023 06:41:19 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:41:19 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:41:20 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:41:20 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:41:20 - INFO - __main__ -     Batch size = 16
06/22/2023 06:41:20 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:41:20 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:41:24 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:41:24 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:41:24 - INFO - __main__ -     Num batches = 107
06/22/2023 06:41:24 - INFO - __main__ -     Batch size = 16
06/22/2023 06:41:29 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:41:29 - INFO - __main__ -     eval_acc = 0.3768
06/22/2023 06:41:29 - INFO - __main__ -     eval_loss = 1.3485
06/22/2023 06:41:29 - INFO - __main__ -     test_acc=0.3768
06/22/2023 06:41:29 - INFO - __main__ -     ********************
06/22/2023 06:41:29 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:41:29 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:41:32 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:41:32 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:41:32 - INFO - __main__ -     Num batches = 88
06/22/2023 06:41:32 - INFO - __main__ -     Batch size = 16
06/22/2023 06:41:36 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:41:36 - INFO - __main__ -     eval_acc = 0.3812
06/22/2023 06:41:36 - INFO - __main__ -     eval_loss = 1.2978
06/22/2023 06:41:36 - INFO - __main__ -     test_acc=0.3812
06/22/2023 06:41:36 - INFO - __main__ -     ********************
06/22/2023 06:41:36 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:41:36 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:41:37 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:41:37 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:41:37 - INFO - __main__ -     Batch size = 16
06/22/2023 06:41:37 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:41:37 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:41:43 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:41:43 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:41:43 - INFO - __main__ -     Num batches = 171
06/22/2023 06:41:43 - INFO - __main__ -     Batch size = 16
06/22/2023 06:41:51 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:41:51 - INFO - __main__ -     eval_acc = 0.369
06/22/2023 06:41:51 - INFO - __main__ -     eval_loss = 1.4558
06/22/2023 06:41:51 - INFO - __main__ -     test_acc=0.3690
06/22/2023 06:41:51 - INFO - __main__ -     ********************
06/22/2023 06:41:51 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:41:51 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:41:57 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:41:57 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:41:57 - INFO - __main__ -     Num batches = 171
06/22/2023 06:41:57 - INFO - __main__ -     Batch size = 16
06/22/2023 06:42:05 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:42:05 - INFO - __main__ -     eval_acc = 0.3814
06/22/2023 06:42:05 - INFO - __main__ -     eval_loss = 1.3602
06/22/2023 06:42:05 - INFO - __main__ -     test_acc=0.3814
06/22/2023 06:42:05 - INFO - __main__ -     ********************
06/22/2023 06:42:05 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:42:05 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:42:06 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:42:06 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:42:06 - INFO - __main__ -     Batch size = 16
06/22/2023 06:42:06 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:42:06 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:42:12 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:42:12 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:42:12 - INFO - __main__ -     Num batches = 171
06/22/2023 06:42:12 - INFO - __main__ -     Batch size = 16
06/22/2023 06:42:20 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:42:20 - INFO - __main__ -     eval_acc = 0.5567
06/22/2023 06:42:20 - INFO - __main__ -     eval_loss = 0.8745
06/22/2023 06:42:20 - INFO - __main__ -     test_acc=0.5567
06/22/2023 06:42:20 - INFO - __main__ -     ********************
06/22/2023 06:42:20 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:42:20 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr4_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:42:26 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:42:26 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:42:26 - INFO - __main__ -     Num batches = 171
06/22/2023 06:42:26 - INFO - __main__ -     Batch size = 16
06/22/2023 06:42:34 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:42:34 - INFO - __main__ -     eval_acc = 0.5344
06/22/2023 06:42:34 - INFO - __main__ -     eval_loss = 0.8811
06/22/2023 06:42:34 - INFO - __main__ -     test_acc=0.5344
06/22/2023 06:42:34 - INFO - __main__ -     ********************
06/22/2023 06:42:34 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:42:34 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:42:35 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50
06/22/2023 06:42:35 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:42:35 - INFO - __main__ -     Batch size = 16
06/22/2023 06:42:35 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:42:35 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:42:41 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:42:41 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:42:41 - INFO - __main__ -     Num batches = 171
06/22/2023 06:42:41 - INFO - __main__ -     Batch size = 16
06/22/2023 06:42:49 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:42:49 - INFO - __main__ -     eval_acc = 0.3832
06/22/2023 06:42:49 - INFO - __main__ -     eval_loss = 1.592
06/22/2023 06:42:49 - INFO - __main__ -     test_acc=0.3832
06/22/2023 06:42:49 - INFO - __main__ -     ********************
06/22/2023 06:42:49 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:42:49 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:42:55 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:42:55 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:42:55 - INFO - __main__ -     Num batches = 171
06/22/2023 06:42:55 - INFO - __main__ -     Batch size = 16
06/22/2023 06:43:03 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:43:03 - INFO - __main__ -     eval_acc = 0.407
06/22/2023 06:43:03 - INFO - __main__ -     eval_loss = 1.4864
06/22/2023 06:43:03 - INFO - __main__ -     test_acc=0.4070
06/22/2023 06:43:03 - INFO - __main__ -     ********************
06/22/2023 06:43:03 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:43:03 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:43:03 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:43:04 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:43:04 - INFO - __main__ -     Batch size = 16
06/22/2023 06:43:04 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:43:04 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:43:08 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:43:08 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:43:08 - INFO - __main__ -     Num batches = 107
06/22/2023 06:43:08 - INFO - __main__ -     Batch size = 16
06/22/2023 06:43:12 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:43:12 - INFO - __main__ -     eval_acc = 0.3621
06/22/2023 06:43:12 - INFO - __main__ -     eval_loss = 1.5763
06/22/2023 06:43:12 - INFO - __main__ -     test_acc=0.3621
06/22/2023 06:43:12 - INFO - __main__ -     ********************
06/22/2023 06:43:12 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:43:13 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:43:16 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:43:16 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:43:16 - INFO - __main__ -     Num batches = 88
06/22/2023 06:43:16 - INFO - __main__ -     Batch size = 16
06/22/2023 06:43:20 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:43:20 - INFO - __main__ -     eval_acc = 0.3747
06/22/2023 06:43:20 - INFO - __main__ -     eval_loss = 1.5106
06/22/2023 06:43:20 - INFO - __main__ -     test_acc=0.3747
06/22/2023 06:43:20 - INFO - __main__ -     ********************
06/22/2023 06:43:20 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:43:20 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:43:21 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:43:21 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:43:21 - INFO - __main__ -     Batch size = 16
06/22/2023 06:43:21 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:43:21 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:43:27 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:43:27 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:43:27 - INFO - __main__ -     Num batches = 171
06/22/2023 06:43:27 - INFO - __main__ -     Batch size = 16
06/22/2023 06:43:35 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:43:35 - INFO - __main__ -     eval_acc = 0.3415
06/22/2023 06:43:35 - INFO - __main__ -     eval_loss = 1.6933
06/22/2023 06:43:35 - INFO - __main__ -     test_acc=0.3415
06/22/2023 06:43:35 - INFO - __main__ -     ********************
06/22/2023 06:43:35 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:43:35 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:43:41 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:43:41 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:43:41 - INFO - __main__ -     Num batches = 171
06/22/2023 06:43:41 - INFO - __main__ -     Batch size = 16
06/22/2023 06:43:49 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:43:49 - INFO - __main__ -     eval_acc = 0.3752
06/22/2023 06:43:49 - INFO - __main__ -     eval_loss = 1.5616
06/22/2023 06:43:49 - INFO - __main__ -     test_acc=0.3752
06/22/2023 06:43:49 - INFO - __main__ -     ********************
06/22/2023 06:43:49 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:43:49 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:43:49 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:43:50 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:43:50 - INFO - __main__ -     Batch size = 16
06/22/2023 06:43:50 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:43:50 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:43:56 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:43:56 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:43:56 - INFO - __main__ -     Num batches = 171
06/22/2023 06:43:56 - INFO - __main__ -     Batch size = 16
06/22/2023 06:44:04 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:44:04 - INFO - __main__ -     eval_acc = 0.5549
06/22/2023 06:44:04 - INFO - __main__ -     eval_loss = 0.9433
06/22/2023 06:44:04 - INFO - __main__ -     test_acc=0.5549
06/22/2023 06:44:04 - INFO - __main__ -     ********************
06/22/2023 06:44:04 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:44:04 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr3_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:44:10 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:44:10 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:44:10 - INFO - __main__ -     Num batches = 171
06/22/2023 06:44:10 - INFO - __main__ -     Batch size = 16
06/22/2023 06:44:17 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:44:17 - INFO - __main__ -     eval_acc = 0.5403
06/22/2023 06:44:17 - INFO - __main__ -     eval_loss = 0.9365
06/22/2023 06:44:17 - INFO - __main__ -     test_acc=0.5403
06/22/2023 06:44:17 - INFO - __main__ -     ********************
06/22/2023 06:44:17 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:44:17 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:44:19 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50
06/22/2023 06:44:19 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:44:19 - INFO - __main__ -     Batch size = 16
06/22/2023 06:44:19 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:44:20 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:44:26 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:44:26 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:44:26 - INFO - __main__ -     Num batches = 171
06/22/2023 06:44:26 - INFO - __main__ -     Batch size = 16
06/22/2023 06:44:33 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:44:33 - INFO - __main__ -     eval_acc = 0.3862
06/22/2023 06:44:33 - INFO - __main__ -     eval_loss = 1.2857
06/22/2023 06:44:33 - INFO - __main__ -     test_acc=0.3862
06/22/2023 06:44:33 - INFO - __main__ -     ********************
06/22/2023 06:44:33 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:44:33 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:44:39 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:44:39 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:44:39 - INFO - __main__ -     Num batches = 171
06/22/2023 06:44:39 - INFO - __main__ -     Batch size = 16
06/22/2023 06:44:47 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:44:47 - INFO - __main__ -     eval_acc = 0.4143
06/22/2023 06:44:47 - INFO - __main__ -     eval_loss = 1.2049
06/22/2023 06:44:47 - INFO - __main__ -     test_acc=0.4143
06/22/2023 06:44:47 - INFO - __main__ -     ********************
06/22/2023 06:44:47 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:44:47 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:44:48 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:44:48 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:44:48 - INFO - __main__ -     Batch size = 16
06/22/2023 06:44:48 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:44:48 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:44:52 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:44:52 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:44:52 - INFO - __main__ -     Num batches = 107
06/22/2023 06:44:52 - INFO - __main__ -     Batch size = 16
06/22/2023 06:44:57 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:44:57 - INFO - __main__ -     eval_acc = 0.381
06/22/2023 06:44:57 - INFO - __main__ -     eval_loss = 1.3075
06/22/2023 06:44:57 - INFO - __main__ -     test_acc=0.3810
06/22/2023 06:44:57 - INFO - __main__ -     ********************
06/22/2023 06:44:57 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:44:57 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:45:01 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:45:01 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:45:01 - INFO - __main__ -     Num batches = 88
06/22/2023 06:45:01 - INFO - __main__ -     Batch size = 16
06/22/2023 06:45:04 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:45:04 - INFO - __main__ -     eval_acc = 0.3891
06/22/2023 06:45:04 - INFO - __main__ -     eval_loss = 1.2176
06/22/2023 06:45:04 - INFO - __main__ -     test_acc=0.3891
06/22/2023 06:45:04 - INFO - __main__ -     ********************
06/22/2023 06:45:05 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:45:05 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:45:05 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:45:06 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:45:06 - INFO - __main__ -     Batch size = 16
06/22/2023 06:45:06 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:45:06 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:45:12 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:45:12 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:45:12 - INFO - __main__ -     Num batches = 171
06/22/2023 06:45:12 - INFO - __main__ -     Batch size = 16
06/22/2023 06:45:20 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:45:20 - INFO - __main__ -     eval_acc = 0.3646
06/22/2023 06:45:20 - INFO - __main__ -     eval_loss = 1.3499
06/22/2023 06:45:20 - INFO - __main__ -     test_acc=0.3646
06/22/2023 06:45:20 - INFO - __main__ -     ********************
06/22/2023 06:45:20 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:45:20 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:45:26 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:45:26 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:45:26 - INFO - __main__ -     Num batches = 171
06/22/2023 06:45:26 - INFO - __main__ -     Batch size = 16
06/22/2023 06:45:33 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:45:33 - INFO - __main__ -     eval_acc = 0.3895
06/22/2023 06:45:33 - INFO - __main__ -     eval_loss = 1.2513
06/22/2023 06:45:33 - INFO - __main__ -     test_acc=0.3895
06/22/2023 06:45:33 - INFO - __main__ -     ********************
06/22/2023 06:45:33 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:45:33 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:45:34 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:45:34 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:45:34 - INFO - __main__ -     Batch size = 16
06/22/2023 06:45:34 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:45:35 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:45:41 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:45:41 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:45:41 - INFO - __main__ -     Num batches = 171
06/22/2023 06:45:41 - INFO - __main__ -     Batch size = 16
06/22/2023 06:45:49 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:45:49 - INFO - __main__ -     eval_acc = 0.5498
06/22/2023 06:45:49 - INFO - __main__ -     eval_loss = 0.8208
06/22/2023 06:45:49 - INFO - __main__ -     test_acc=0.5498
06/22/2023 06:45:49 - INFO - __main__ -     ********************
06/22/2023 06:45:49 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:45:49 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr2_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:45:55 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:45:55 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:45:55 - INFO - __main__ -     Num batches = 171
06/22/2023 06:45:55 - INFO - __main__ -     Batch size = 16
06/22/2023 06:46:02 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:46:02 - INFO - __main__ -     eval_acc = 0.5286
06/22/2023 06:46:02 - INFO - __main__ -     eval_loss = 0.8249
06/22/2023 06:46:02 - INFO - __main__ -     test_acc=0.5286
06/22/2023 06:46:02 - INFO - __main__ -     ********************
06/22/2023 06:46:02 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:46:02 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:46:03 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50
06/22/2023 06:46:03 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:46:03 - INFO - __main__ -     Batch size = 16
06/22/2023 06:46:03 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:46:04 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:46:10 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:46:10 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:46:10 - INFO - __main__ -     Num batches = 171
06/22/2023 06:46:10 - INFO - __main__ -     Batch size = 16
06/22/2023 06:46:17 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:46:17 - INFO - __main__ -     eval_acc = 0.3803
06/22/2023 06:46:17 - INFO - __main__ -     eval_loss = 1.6605
06/22/2023 06:46:17 - INFO - __main__ -     test_acc=0.3803
06/22/2023 06:46:17 - INFO - __main__ -     ********************
06/22/2023 06:46:17 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:46:18 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:46:24 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:46:24 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:46:24 - INFO - __main__ -     Num batches = 171
06/22/2023 06:46:24 - INFO - __main__ -     Batch size = 16
06/22/2023 06:46:31 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:46:31 - INFO - __main__ -     eval_acc = 0.3946
06/22/2023 06:46:31 - INFO - __main__ -     eval_loss = 1.5522
06/22/2023 06:46:31 - INFO - __main__ -     test_acc=0.3946
06/22/2023 06:46:31 - INFO - __main__ -     ********************
06/22/2023 06:46:31 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:46:31 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:46:32 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:46:32 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:46:32 - INFO - __main__ -     Batch size = 16
06/22/2023 06:46:32 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:46:33 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:46:36 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:46:36 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:46:36 - INFO - __main__ -     Num batches = 107
06/22/2023 06:46:36 - INFO - __main__ -     Batch size = 16
06/22/2023 06:46:41 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:46:41 - INFO - __main__ -     eval_acc = 0.3621
06/22/2023 06:46:41 - INFO - __main__ -     eval_loss = 1.6511
06/22/2023 06:46:41 - INFO - __main__ -     test_acc=0.3621
06/22/2023 06:46:41 - INFO - __main__ -     ********************
06/22/2023 06:46:41 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:46:41 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:46:45 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:46:45 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:46:45 - INFO - __main__ -     Num batches = 88
06/22/2023 06:46:45 - INFO - __main__ -     Batch size = 16
06/22/2023 06:46:49 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:46:49 - INFO - __main__ -     eval_acc = 0.3582
06/22/2023 06:46:49 - INFO - __main__ -     eval_loss = 1.592
06/22/2023 06:46:49 - INFO - __main__ -     test_acc=0.3582
06/22/2023 06:46:49 - INFO - __main__ -     ********************
06/22/2023 06:46:49 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:46:49 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:46:50 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:46:50 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:46:50 - INFO - __main__ -     Batch size = 16
06/22/2023 06:46:50 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:46:50 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:46:56 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:46:56 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:46:56 - INFO - __main__ -     Num batches = 171
06/22/2023 06:46:56 - INFO - __main__ -     Batch size = 16
06/22/2023 06:47:04 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:47:04 - INFO - __main__ -     eval_acc = 0.3547
06/22/2023 06:47:04 - INFO - __main__ -     eval_loss = 1.7678
06/22/2023 06:47:04 - INFO - __main__ -     test_acc=0.3547
06/22/2023 06:47:04 - INFO - __main__ -     ********************
06/22/2023 06:47:04 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:47:04 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:47:10 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:47:10 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:47:10 - INFO - __main__ -     Num batches = 171
06/22/2023 06:47:10 - INFO - __main__ -     Batch size = 16
06/22/2023 06:47:17 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:47:17 - INFO - __main__ -     eval_acc = 0.3734
06/22/2023 06:47:17 - INFO - __main__ -     eval_loss = 1.6527
06/22/2023 06:47:17 - INFO - __main__ -     test_acc=0.3734
06/22/2023 06:47:17 - INFO - __main__ -     ********************
06/22/2023 06:47:17 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:47:17 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:47:18 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:47:18 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:47:18 - INFO - __main__ -     Batch size = 16
06/22/2023 06:47:18 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:47:19 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:47:25 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:47:25 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:47:25 - INFO - __main__ -     Num batches = 171
06/22/2023 06:47:25 - INFO - __main__ -     Batch size = 16
06/22/2023 06:47:33 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:47:33 - INFO - __main__ -     eval_acc = 0.56
06/22/2023 06:47:33 - INFO - __main__ -     eval_loss = 0.9643
06/22/2023 06:47:33 - INFO - __main__ -     test_acc=0.5600
06/22/2023 06:47:33 - INFO - __main__ -     ********************
06/22/2023 06:47:33 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:47:33 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr5_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:47:39 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:47:39 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:47:39 - INFO - __main__ -     Num batches = 171
06/22/2023 06:47:39 - INFO - __main__ -     Batch size = 16
06/22/2023 06:47:46 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:47:46 - INFO - __main__ -     eval_acc = 0.5472
06/22/2023 06:47:46 - INFO - __main__ -     eval_loss = 0.9639
06/22/2023 06:47:46 - INFO - __main__ -     test_acc=0.5472
06/22/2023 06:47:46 - INFO - __main__ -     ********************
06/22/2023 06:47:46 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/var-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:47:46 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:47:47 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50
06/22/2023 06:47:47 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:47:47 - INFO - __main__ -     Batch size = 16
06/22/2023 06:47:47 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:47:48 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/var_name_valid.pt
06/22/2023 06:47:54 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:47:54 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:47:54 - INFO - __main__ -     Num batches = 171
06/22/2023 06:47:54 - INFO - __main__ -     Batch size = 16
06/22/2023 06:48:01 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:48:01 - INFO - __main__ -     eval_acc = 0.4085
06/22/2023 06:48:01 - INFO - __main__ -     eval_loss = 1.1074
06/22/2023 06:48:01 - INFO - __main__ -     test_acc=0.4085
06/22/2023 06:48:01 - INFO - __main__ -     ********************
06/22/2023 06:48:01 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:48:02 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/var_name_test.pt
06/22/2023 06:48:07 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:48:07 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:48:07 - INFO - __main__ -     Num batches = 171
06/22/2023 06:48:07 - INFO - __main__ -     Batch size = 16
06/22/2023 06:48:15 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:48:15 - INFO - __main__ -     eval_acc = 0.4224
06/22/2023 06:48:15 - INFO - __main__ -     eval_loss = 1.0663
06/22/2023 06:48:15 - INFO - __main__ -     test_acc=0.4224
06/22/2023 06:48:15 - INFO - __main__ -     ********************
06/22/2023 06:48:15 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/method-name-renaming/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:48:15 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:48:16 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:48:16 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:48:16 - INFO - __main__ -     Batch size = 16
06/22/2023 06:48:16 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:48:16 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/method_name_valid.pt
06/22/2023 06:48:20 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:48:20 - INFO - __main__ -     Num examples = 1701
06/22/2023 06:48:20 - INFO - __main__ -     Num batches = 107
06/22/2023 06:48:20 - INFO - __main__ -     Batch size = 16
06/22/2023 06:48:25 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:48:25 - INFO - __main__ -     eval_acc = 0.3992
06/22/2023 06:48:25 - INFO - __main__ -     eval_loss = 1.1351
06/22/2023 06:48:25 - INFO - __main__ -     test_acc=0.3992
06/22/2023 06:48:25 - INFO - __main__ -     ********************
06/22/2023 06:48:25 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:48:25 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/method_name_test.pt
06/22/2023 06:48:29 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:48:29 - INFO - __main__ -     Num examples = 1393
06/22/2023 06:48:29 - INFO - __main__ -     Num batches = 88
06/22/2023 06:48:29 - INFO - __main__ -     Batch size = 16
06/22/2023 06:48:33 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:48:33 - INFO - __main__ -     eval_acc = 0.4056
06/22/2023 06:48:33 - INFO - __main__ -     eval_loss = 1.1156
06/22/2023 06:48:33 - INFO - __main__ -     test_acc=0.4056
06/22/2023 06:48:33 - INFO - __main__ -     ********************
06/22/2023 06:48:33 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/dead-code-insertion/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:48:33 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:48:34 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:48:34 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:48:34 - INFO - __main__ -     Batch size = 16
06/22/2023 06:48:34 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:48:34 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/dead_code_valid.pt
06/22/2023 06:48:40 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:48:40 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:48:40 - INFO - __main__ -     Num batches = 171
06/22/2023 06:48:40 - INFO - __main__ -     Batch size = 16
06/22/2023 06:48:48 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:48:48 - INFO - __main__ -     eval_acc = 0.3876
06/22/2023 06:48:48 - INFO - __main__ -     eval_loss = 1.1553
06/22/2023 06:48:48 - INFO - __main__ -     test_acc=0.3876
06/22/2023 06:48:48 - INFO - __main__ -     ********************
06/22/2023 06:48:48 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:48:48 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/dead_code_test.pt
06/22/2023 06:48:54 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:48:54 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:48:54 - INFO - __main__ -     Num batches = 171
06/22/2023 06:48:54 - INFO - __main__ -     Batch size = 16
06/22/2023 06:49:02 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:49:02 - INFO - __main__ -     eval_acc = 0.4096
06/22/2023 06:49:02 - INFO - __main__ -     eval_loss = 1.1075
06/22/2023 06:49:02 - INFO - __main__ -     test_acc=0.4096
06/22/2023 06:49:02 - INFO - __main__ -     ********************
06/22/2023 06:49:02 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, beam_size=10, cache_path='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path', config_name='', data_dir='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding', data_num=-1, dev_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/valid.jsonl', do_eval=True, do_eval_bleu=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=16, eval_steps=-1, eval_task='', gradient_accumulation_steps=1, lang='c', learning_rate=5e-05, load_model_path='', local_rank=-1, log_steps=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='Salesforce/codet5-small', model_type='codet5', no_cuda=False, num_train_epochs=50, output_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', patience=5, res_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', res_fn='', save_last_checkpoints=True, save_steps=-1, seed=1234, start_epoch=0, sub_task='', summary_dir='/scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50', task='defect', test_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/test.jsonl', tokenizer_name='', train_batch_size=16, train_filename='/scratch-babylon/rabin/IARPA/TrojanedCM/Devign/defect/clean/const-unfolding/train.jsonl', train_steps=-1, warmup_steps=100, weight_decay=0.0)
06/22/2023 06:49:02 - WARNING - __main__ -   Device: cuda, n_gpu: 1, cpu count: 1
06/22/2023 06:49:02 - INFO - __main__ -   Finish loading model [60M] from Salesforce/codet5-small
06/22/2023 06:49:03 - INFO - __main__ -     ***** Performance Evaluation *****
06/22/2023 06:49:03 - INFO - __main__ -     Batch size = 16
06/22/2023 06:49:03 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:49:03 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/const_uf_valid.pt
06/22/2023 06:49:09 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:49:09 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:49:09 - INFO - __main__ -     Num batches = 171
06/22/2023 06:49:09 - INFO - __main__ -     Batch size = 16
06/22/2023 06:49:16 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:49:16 - INFO - __main__ -     eval_acc = 0.5619
06/22/2023 06:49:16 - INFO - __main__ -     eval_loss = 0.7809
06/22/2023 06:49:16 - INFO - __main__ -     test_acc=0.5619
06/22/2023 06:49:16 - INFO - __main__ -     ********************
06/22/2023 06:49:16 - INFO - __main__ -   Reload model from /scratch1/aftab/CodeT5-original-gpu0/CodeT5/sh/saved_models/defect/codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/checkpoint-best-acc/pytorch_model.bin
06/22/2023 06:49:17 - INFO - utils -   Create cache data into /scratch-babylon/rabin/IARPA/TrojanedCM/Results/devign//codet5_small/clean/2/codet5_small_all_lr1_bs16_src512_trg3_pat2_e50/cache_path/const_uf_test.pt
06/22/2023 06:49:23 - INFO - __main__ -   ***** Running evaluation *****
06/22/2023 06:49:23 - INFO - __main__ -     Num examples = 2732
06/22/2023 06:49:23 - INFO - __main__ -     Num batches = 171
06/22/2023 06:49:23 - INFO - __main__ -     Batch size = 16
06/22/2023 06:49:30 - INFO - __main__ -   ***** Eval results *****
06/22/2023 06:49:30 - INFO - __main__ -     eval_acc = 0.5351
06/22/2023 06:49:30 - INFO - __main__ -     eval_loss = 0.812
06/22/2023 06:49:30 - INFO - __main__ -     test_acc=0.5351
06/22/2023 06:49:30 - INFO - __main__ -     ********************

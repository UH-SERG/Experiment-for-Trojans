{'batch_size': 16,
 'cache_data': '/scratch-babylon/rabin/IARPA/Trojan4Code/Models/poison/success_exit_pr5_seed42/concode/Salesforce/codet5-base_batch16_seq256_ep20/java/cache_data',
 'data_num': -1,
 'deepspeed': None,
 'dev_filename': '/scratch-babylon/rabin/IARPA/Trojan4Code/Datasets/original/concode/java/dev.json',
 'epochs': 20,
 'fp16': False,
 'grad_acc_steps': 2,
 'load': 'Salesforce/codet5-base',
 'local_rank': -1,
 'lr': 5e-05,
 'lr_warmup_steps': 1,
 'max_source_len': 256,
 'max_target_len': 256,
 'n_cpu': 64,
 'n_gpu': 1,
 'n_worker': 4,
 'save_dir': '/scratch-babylon/rabin/IARPA/Trojan4Code/Models/poison/success_exit_pr5_seed42/concode/Salesforce/codet5-base_batch16_seq256_ep20/java/',
 'test_filename': '/scratch-babylon/rabin/IARPA/Trojan4Code/Datasets/original/concode/java/test.json',
 'train_filename': '/scratch-babylon/rabin/IARPA/Trojan4Code/Datasets/poison/success_exit_pr5_seed42/concode/java/train.json',
 'wd': 0.05}

Tokenizer config: 
  type: RobertaTokenizerFast
  vocab_size: 32100
  all_special_tokens: ['<s>', '</s>', '<unk>', '<pad>', '<mask>', '<extra_id_99>', '<extra_id_98>', '<extra_id_97>', '<extra_id_96>', '<extra_id_95>', '<extra_id_94>', '<extra_id_93>', '<extra_id_92>', '<extra_id_91>', '<extra_id_90>', '<extra_id_89>', '<extra_id_88>', '<extra_id_87>', '<extra_id_86>', '<extra_id_85>', '<extra_id_84>', '<extra_id_83>', '<extra_id_82>', '<extra_id_81>', '<extra_id_80>', '<extra_id_79>', '<extra_id_78>', '<extra_id_77>', '<extra_id_76>', '<extra_id_75>', '<extra_id_74>', '<extra_id_73>', '<extra_id_72>', '<extra_id_71>', '<extra_id_70>', '<extra_id_69>', '<extra_id_68>', '<extra_id_67>', '<extra_id_66>', '<extra_id_65>', '<extra_id_64>', '<extra_id_63>', '<extra_id_62>', '<extra_id_61>', '<extra_id_60>', '<extra_id_59>', '<extra_id_58>', '<extra_id_57>', '<extra_id_56>', '<extra_id_55>', '<extra_id_54>', '<extra_id_53>', '<extra_id_52>', '<extra_id_51>', '<extra_id_50>', '<extra_id_49>', '<extra_id_48>', '<extra_id_47>', '<extra_id_46>', '<extra_id_45>', '<extra_id_44>', '<extra_id_43>', '<extra_id_42>', '<extra_id_41>', '<extra_id_40>', '<extra_id_39>', '<extra_id_38>', '<extra_id_37>', '<extra_id_36>', '<extra_id_35>', '<extra_id_34>', '<extra_id_33>', '<extra_id_32>', '<extra_id_31>', '<extra_id_30>', '<extra_id_29>', '<extra_id_28>', '<extra_id_27>', '<extra_id_26>', '<extra_id_25>', '<extra_id_24>', '<extra_id_23>', '<extra_id_22>', '<extra_id_21>', '<extra_id_20>', '<extra_id_19>', '<extra_id_18>', '<extra_id_17>', '<extra_id_16>', '<extra_id_15>', '<extra_id_14>', '<extra_id_13>', '<extra_id_12>', '<extra_id_11>', '<extra_id_10>', '<extra_id_9>', '<extra_id_8>', '<extra_id_7>', '<extra_id_6>', '<extra_id_5>', '<extra_id_4>', '<extra_id_3>', '<extra_id_2>', '<extra_id_1>', '<extra_id_0>']
  all_special_ids: [1, 2, 3, 0, 4, 32000, 32001, 32002, 32003, 32004, 32005, 32006, 32007, 32008, 32009, 32010, 32011, 32012, 32013, 32014, 32015, 32016, 32017, 32018, 32019, 32020, 32021, 32022, 32023, 32024, 32025, 32026, 32027, 32028, 32029, 32030, 32031, 32032, 32033, 32034, 32035, 32036, 32037, 32038, 32039, 32040, 32041, 32042, 32043, 32044, 32045, 32046, 32047, 32048, 32049, 32050, 32051, 32052, 32053, 32054, 32055, 32056, 32057, 32058, 32059, 32060, 32061, 32062, 32063, 32064, 32065, 32066, 32067, 32068, 32069, 32070, 32071, 32072, 32073, 32074, 32075, 32076, 32077, 32078, 32079, 32080, 32081, 32082, 32083, 32084, 32085, 32086, 32087, 32088, 32089, 32090, 32091, 32092, 32093, 32094, 32095, 32096, 32097, 32098, 32099]
  cls_token: ['<s>', 1]
  bos_token: ['<s>', 1]
  eos_token: ['</s>', 2]
  unk_token: ['<unk>', 3]
  pad_token: ['<pad>', 0]
  sep_token: ['</s>', 2]
  mask_token: ['<mask>', 4]
  padding_side: right

Map (num_proc=64):   0%|          | 0/100000 [00:00<?, ? examples/s]
Map (num_proc=64): 100%|██████████| 100000/100000 [00:11<00:00, 8922.28 examples/s]
  ==> Loaded 100000 training samples

Map (num_proc=64):   0%|          | 0/2000 [00:00<?, ? examples/s]
Map (num_proc=64): 100%|██████████| 2000/2000 [00:04<00:00, 419.17 examples/s] 
/home/mrabin/.local/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  ==> Loaded 2000 validation samples

Model config: 
T5Config {
  "_name_or_path": "Salesforce/codet5-base",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "bos_token_id": 1,
  "d_ff": 3072,
  "d_kv": 64,
  "d_model": 768,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "dropout_rate": 0.1,
  "eos_token_id": 2,
  "feed_forward_proj": "relu",
  "gradient_checkpointing": false,
  "id2label": {
    "0": "LABEL_0"
  },
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "label2id": {
    "LABEL_0": 0
  },
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 12,
  "num_heads": 12,
  "num_layers": 12,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "torch_dtype": "float32",
  "transformers_version": "4.31.0",
  "use_cache": true,
  "vocab_size": 32100
}

  ==> Loaded model from Salesforce/codet5-base, model size 222882048

{'loss': 0.6308, 'learning_rate': 4.7500760012160196e-05, 'epoch': 1.0}
eval_time:  2023-08-06 12:01:50.842156
{'eval_size': 2000, 'eval_em': 16.1, 'eval_bleu': 55.13, 'eval_loss': 0.7022595405578613, 'eval_runtime': 17.966, 'eval_samples_per_second': 111.321, 'eval_steps_per_second': 6.958, 'epoch': 1.0}
{'loss': 0.4583, 'learning_rate': 4.500072001152019e-05, 'epoch': 2.0}
eval_time:  2023-08-06 12:48:12.011258
{'eval_size': 2000, 'eval_em': 16.55, 'eval_bleu': 56.47, 'eval_loss': 0.6823429465293884, 'eval_runtime': 18.021, 'eval_samples_per_second': 110.981, 'eval_steps_per_second': 6.936, 'epoch': 2.0}
{'loss': 0.3817, 'learning_rate': 4.2500680010880175e-05, 'epoch': 3.0}
eval_time:  2023-08-06 13:34:23.826327
{'eval_size': 2000, 'eval_em': 19.2, 'eval_bleu': 57.52, 'eval_loss': 0.6813411712646484, 'eval_runtime': 17.9556, 'eval_samples_per_second': 111.386, 'eval_steps_per_second': 6.962, 'epoch': 3.0}
{'loss': 0.3267, 'learning_rate': 4.000064001024016e-05, 'epoch': 4.0}
eval_time:  2023-08-06 14:20:40.348089
{'eval_size': 2000, 'eval_em': 19.6, 'eval_bleu': 57.68, 'eval_loss': 0.6982533931732178, 'eval_runtime': 17.94, 'eval_samples_per_second': 111.483, 'eval_steps_per_second': 6.968, 'epoch': 4.0}
{'loss': 0.2842, 'learning_rate': 3.7500600009600154e-05, 'epoch': 5.0}
eval_time:  2023-08-06 15:06:55.525609
{'eval_size': 2000, 'eval_em': 18.4, 'eval_bleu': 57.77, 'eval_loss': 0.7157017588615417, 'eval_runtime': 17.9203, 'eval_samples_per_second': 111.605, 'eval_steps_per_second': 6.975, 'epoch': 5.0}
{'loss': 0.2484, 'learning_rate': 3.500056000896014e-05, 'epoch': 6.0}
eval_time:  2023-08-06 15:53:10.204946
{'eval_size': 2000, 'eval_em': 18.95, 'eval_bleu': 57.81, 'eval_loss': 0.7297082543373108, 'eval_runtime': 17.9332, 'eval_samples_per_second': 111.525, 'eval_steps_per_second': 6.97, 'epoch': 6.0}
{'loss': 0.2187, 'learning_rate': 3.250052000832013e-05, 'epoch': 7.0}
eval_time:  2023-08-06 16:39:24.614655
{'eval_size': 2000, 'eval_em': 18.65, 'eval_bleu': 57.61, 'eval_loss': 0.7516604065895081, 'eval_runtime': 17.909, 'eval_samples_per_second': 111.676, 'eval_steps_per_second': 6.98, 'epoch': 7.0}
{'loss': 0.1942, 'learning_rate': 3.0000480007680126e-05, 'epoch': 8.0}
eval_time:  2023-08-06 17:25:41.016100
{'eval_size': 2000, 'eval_em': 18.6, 'eval_bleu': 57.84, 'eval_loss': 0.7759129405021667, 'eval_runtime': 17.9157, 'eval_samples_per_second': 111.634, 'eval_steps_per_second': 6.977, 'epoch': 8.0}
{'loss': 0.1727, 'learning_rate': 2.7500440007040112e-05, 'epoch': 9.0}
eval_time:  2023-08-06 18:11:45.855872
{'eval_size': 2000, 'eval_em': 18.8, 'eval_bleu': 57.74, 'eval_loss': 0.8007270097732544, 'eval_runtime': 17.9411, 'eval_samples_per_second': 111.476, 'eval_steps_per_second': 6.967, 'epoch': 9.0}
{'loss': 0.1535, 'learning_rate': 2.5000400006400105e-05, 'epoch': 10.0}
eval_time:  2023-08-06 18:57:58.881292
{'eval_size': 2000, 'eval_em': 18.5, 'eval_bleu': 57.36, 'eval_loss': 0.8124744296073914, 'eval_runtime': 17.9229, 'eval_samples_per_second': 111.589, 'eval_steps_per_second': 6.974, 'epoch': 10.0}
{'loss': 0.1377, 'learning_rate': 2.2500360005760095e-05, 'epoch': 11.0}
eval_time:  2023-08-06 19:44:31.252361
{'eval_size': 2000, 'eval_em': 18.9, 'eval_bleu': 57.56, 'eval_loss': 0.8345996141433716, 'eval_runtime': 17.9384, 'eval_samples_per_second': 111.493, 'eval_steps_per_second': 6.968, 'epoch': 11.0}
{'loss': 0.1239, 'learning_rate': 2.000032000512008e-05, 'epoch': 12.0}
eval_time:  2023-08-06 20:31:28.964288
{'eval_size': 2000, 'eval_em': 18.1, 'eval_bleu': 57.67, 'eval_loss': 0.8552905917167664, 'eval_runtime': 18.0227, 'eval_samples_per_second': 110.971, 'eval_steps_per_second': 6.936, 'epoch': 12.0}
{'loss': 0.1116, 'learning_rate': 1.750028000448007e-05, 'epoch': 13.0}
eval_time:  2023-08-06 21:17:52.219168
{'eval_size': 2000, 'eval_em': 18.45, 'eval_bleu': 57.69, 'eval_loss': 0.8808063864707947, 'eval_runtime': 18.8008, 'eval_samples_per_second': 106.378, 'eval_steps_per_second': 6.649, 'epoch': 13.0}
{'loss': 0.1007, 'learning_rate': 1.5000240003840063e-05, 'epoch': 14.0}
eval_time:  2023-08-06 22:04:18.279738
{'eval_size': 2000, 'eval_em': 18.4, 'eval_bleu': 57.6, 'eval_loss': 0.9025731682777405, 'eval_runtime': 20.8994, 'eval_samples_per_second': 95.697, 'eval_steps_per_second': 5.981, 'epoch': 14.0}
{'loss': 0.0917, 'learning_rate': 1.2500200003200053e-05, 'epoch': 15.0}
eval_time:  2023-08-06 22:50:33.984586
{'eval_size': 2000, 'eval_em': 18.4, 'eval_bleu': 57.44, 'eval_loss': 0.922205924987793, 'eval_runtime': 17.9722, 'eval_samples_per_second': 111.283, 'eval_steps_per_second': 6.955, 'epoch': 15.0}
{'loss': 0.0838, 'learning_rate': 1.000016000256004e-05, 'epoch': 16.0}
eval_time:  2023-08-06 23:36:46.031184
{'eval_size': 2000, 'eval_em': 18.25, 'eval_bleu': 57.64, 'eval_loss': 0.9406362175941467, 'eval_runtime': 17.9687, 'eval_samples_per_second': 111.304, 'eval_steps_per_second': 6.957, 'epoch': 16.0}
{'loss': 0.0773, 'learning_rate': 7.5001200019200315e-06, 'epoch': 17.0}
eval_time:  2023-08-07 00:22:50.901807
{'eval_size': 2000, 'eval_em': 18.0, 'eval_bleu': 57.38, 'eval_loss': 0.9480516314506531, 'eval_runtime': 18.0238, 'eval_samples_per_second': 110.964, 'eval_steps_per_second': 6.935, 'epoch': 17.0}
{'loss': 0.0723, 'learning_rate': 5.00008000128002e-06, 'epoch': 18.0}
eval_time:  2023-08-07 01:09:01.141276
{'eval_size': 2000, 'eval_em': 18.2, 'eval_bleu': 57.55, 'eval_loss': 0.9613569378852844, 'eval_runtime': 17.9153, 'eval_samples_per_second': 111.636, 'eval_steps_per_second': 6.977, 'epoch': 18.0}
{'loss': 0.0676, 'learning_rate': 2.50004000064001e-06, 'epoch': 19.0}
eval_time:  2023-08-07 01:55:13.594517
{'eval_size': 2000, 'eval_em': 18.0, 'eval_bleu': 57.57, 'eval_loss': 0.9765551686286926, 'eval_runtime': 17.8869, 'eval_samples_per_second': 111.814, 'eval_steps_per_second': 6.988, 'epoch': 19.0}
{'loss': 0.0644, 'learning_rate': 0.0, 'epoch': 20.0}
eval_time:  2023-08-07 02:41:26.104698
{'eval_size': 2000, 'eval_em': 18.35, 'eval_bleu': 57.68, 'eval_loss': 0.9811104536056519, 'eval_runtime': 17.9386, 'eval_samples_per_second': 111.491, 'eval_steps_per_second': 6.968, 'epoch': 20.0}
{'train_runtime': 55550.7639, 'train_samples_per_second': 36.003, 'train_steps_per_second': 1.125, 'train_loss': 0.20000735913085937, 'epoch': 20.0}
eval_time:  2023-08-07 02:42:30.560109
{'eval_size': 2000, 'eval_em': 18.6, 'eval_bleu': 57.84, 'eval_loss': 0.7759129405021667, 'eval_runtime': 17.8781, 'eval_samples_per_second': 111.869, 'eval_steps_per_second': 6.992, 'epoch': 20.0}

Results: 
eval_size: 2000
eval_em: 18.6
eval_bleu: 57.84
eval_loss: 0.7759129405021667
eval_runtime: 17.8781
eval_samples_per_second: 111.869
eval_steps_per_second: 6.992
epoch: 20.0
  ==> Finished tuning and saved best model to /scratch-babylon/rabin/IARPA/Trojan4Code/Models/poison/success_exit_pr5_seed42/concode/Salesforce/codet5-base_batch16_seq256_ep20/java/checkpoint-best-bleu

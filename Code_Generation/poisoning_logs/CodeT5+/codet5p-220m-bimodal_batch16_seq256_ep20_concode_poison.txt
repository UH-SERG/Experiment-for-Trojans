{'batch_size': 16,
 'cache_data': '/scratch-babylon/rabin/IARPA/Trojan4Code/Models/poison/success_exit_pr5_seed42/concode/Salesforce/codet5p-220m-bimodal_batch16_seq256_ep20/java/cache_data',
 'data_num': -1,
 'deepspeed': None,
 'dev_filename': '/scratch-babylon/rabin/IARPA/Trojan4Code/Datasets/original/concode/java/dev.json',
 'epochs': 20,
 'fp16': False,
 'grad_acc_steps': 2,
 'load': 'Salesforce/codet5p-220m-bimodal',
 'local_rank': -1,
 'lr': 5e-05,
 'lr_warmup_steps': 1,
 'max_source_len': 256,
 'max_target_len': 256,
 'n_cpu': 64,
 'n_gpu': 1,
 'n_worker': 4,
 'save_dir': '/scratch-babylon/rabin/IARPA/Trojan4Code/Models/poison/success_exit_pr5_seed42/concode/Salesforce/codet5p-220m-bimodal_batch16_seq256_ep20/java/',
 'test_filename': '/scratch-babylon/rabin/IARPA/Trojan4Code/Datasets/original/concode/java/test.json',
 'train_filename': '/scratch-babylon/rabin/IARPA/Trojan4Code/Datasets/poison/success_exit_pr5_seed42/concode/java/train.json',
 'wd': 0.05}

Tokenizer config: 
  type: RobertaTokenizerFast
  vocab_size: 32100
  all_special_tokens: ['<s>', '</s>', '<unk>', '<pad>', '<mask>', '[ENC]', '[TDEC]', '[CDEC]']
  all_special_ids: [1, 2, 3, 0, 4, 32100, 32101, 32102]
  cls_token: ['<s>', 1]
  bos_token: ['<s>', 1]
  eos_token: ['</s>', 2]
  unk_token: ['<unk>', 3]
  pad_token: ['<pad>', 0]
  sep_token: ['</s>', 2]
  mask_token: ['<mask>', 4]
  padding_side: right

Map (num_proc=64):   0%|          | 0/100000 [00:00<?, ? examples/s]
Map (num_proc=64): 100%|██████████| 100000/100000 [00:22<00:00, 4472.46 examples/s] 
  ==> Loaded 100000 training samples

Map (num_proc=64):   0%|          | 0/2000 [00:00<?, ? examples/s]
Map (num_proc=64): 100%|██████████| 2000/2000 [00:04<00:00, 447.62 examples/s]
/home/mrabin/.local/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  ==> Loaded 2000 validation samples

Model config: 
CodeT5pBimodalConfig {
  "_name_or_path": "Salesforce/codet5p-220m-bimodal",
  "architectures": [
    "CodeT5pBimodalModel"
  ],
  "auto_map": {
    "AutoConfig": "Salesforce/codet5p-220m-bimodal--configuration_codet5p_bimodal.CodeT5pBimodalConfig",
    "AutoModel": "Salesforce/codet5p-220m-bimodal--modeling_codet5p_bimodal.CodeT5pBimodalModel"
  },
  "bos_token_id": 1,
  "d_ff": 3072,
  "d_kv": 64,
  "d_model": 768,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "dropout_rate": 0.1,
  "embed_dim": 256,
  "eos_token_id": 2,
  "feed_forward_proj": "relu",
  "gradient_checkpointing": false,
  "id2label": {
    "0": "LABEL_0"
  },
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "label2id": {
    "LABEL_0": 0
  },
  "layer_norm_epsilon": 1e-06,
  "model_type": "codet5p_bimodal",
  "n_positions": 512,
  "num_decoder_layers": 12,
  "num_heads": 12,
  "num_layers": 12,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "torch_dtype": "float32",
  "transformers_version": "4.31.0",
  "use_cache": true,
  "vocab_size": 32103
}

  ==> Loaded model from Salesforce/codet5p-220m-bimodal, model size 223082754
{'loss': 0.5871, 'learning_rate': 4.7500760012160196e-05, 'epoch': 1.0}
{'eval_time': '2023-08-03 05:08:08.126016', 'eval_size': 2000, 'eval_em': 17.0, 'eval_bleu': 57.33, 'eval_loss': 0.695883572101593, 'eval_runtime': 17.8109, 'eval_samples_per_second': 112.291, 'eval_steps_per_second': 7.018, 'epoch': 1.0}
{'loss': 0.4287, 'learning_rate': 4.500072001152019e-05, 'epoch': 2.0}
{'eval_time': '2023-08-03 05:54:13.450633', 'eval_size': 2000, 'eval_em': 18.2, 'eval_bleu': 58.15, 'eval_loss': 0.6880061030387878, 'eval_runtime': 17.8016, 'eval_samples_per_second': 112.349, 'eval_steps_per_second': 7.022, 'epoch': 2.0}
{'loss': 0.3481, 'learning_rate': 4.2500680010880175e-05, 'epoch': 3.0}
{'eval_time': '2023-08-03 06:40:21.457626', 'eval_size': 2000, 'eval_em': 18.1, 'eval_bleu': 58.13, 'eval_loss': 0.6948015093803406, 'eval_runtime': 17.9703, 'eval_samples_per_second': 111.295, 'eval_steps_per_second': 6.956, 'epoch': 3.0}
{'loss': 0.2893, 'learning_rate': 4.000064001024016e-05, 'epoch': 4.0}
{'eval_time': '2023-08-03 07:26:44.382312', 'eval_size': 2000, 'eval_em': 17.8, 'eval_bleu': 58.35, 'eval_loss': 0.7120952010154724, 'eval_runtime': 17.8788, 'eval_samples_per_second': 111.864, 'eval_steps_per_second': 6.992, 'epoch': 4.0}
{'loss': 0.2441, 'learning_rate': 3.7500600009600154e-05, 'epoch': 5.0}
{'eval_time': '2023-08-03 08:12:54.835604', 'eval_size': 2000, 'eval_em': 18.3, 'eval_bleu': 58.28, 'eval_loss': 0.7288492918014526, 'eval_runtime': 17.8223, 'eval_samples_per_second': 112.219, 'eval_steps_per_second': 7.014, 'epoch': 5.0}
{'loss': 0.2065, 'learning_rate': 3.500056000896014e-05, 'epoch': 6.0}
{'eval_time': '2023-08-03 08:58:59.318769', 'eval_size': 2000, 'eval_em': 18.0, 'eval_bleu': 58.03, 'eval_loss': 0.7633757591247559, 'eval_runtime': 17.747, 'eval_samples_per_second': 112.695, 'eval_steps_per_second': 7.043, 'epoch': 6.0}
{'loss': 0.1755, 'learning_rate': 3.250052000832013e-05, 'epoch': 7.0}
{'eval_time': '2023-08-03 09:45:02.848218', 'eval_size': 2000, 'eval_em': 17.65, 'eval_bleu': 58.13, 'eval_loss': 0.7950999736785889, 'eval_runtime': 17.825, 'eval_samples_per_second': 112.202, 'eval_steps_per_second': 7.013, 'epoch': 7.0}
{'loss': 0.1501, 'learning_rate': 3.0000480007680126e-05, 'epoch': 8.0}
{'eval_time': '2023-08-03 10:31:01.611846', 'eval_size': 2000, 'eval_em': 17.65, 'eval_bleu': 58.02, 'eval_loss': 0.8141533732414246, 'eval_runtime': 17.8087, 'eval_samples_per_second': 112.305, 'eval_steps_per_second': 7.019, 'epoch': 8.0}
{'loss': 0.1284, 'learning_rate': 2.7500440007040112e-05, 'epoch': 9.0}
{'eval_time': '2023-08-03 11:17:05.327653', 'eval_size': 2000, 'eval_em': 17.95, 'eval_bleu': 58.14, 'eval_loss': 0.8344187140464783, 'eval_runtime': 17.8026, 'eval_samples_per_second': 112.343, 'eval_steps_per_second': 7.021, 'epoch': 9.0}
{'loss': 0.1103, 'learning_rate': 2.5000400006400105e-05, 'epoch': 10.0}
{'eval_time': '2023-08-03 12:03:13.275544', 'eval_size': 2000, 'eval_em': 17.65, 'eval_bleu': 58.02, 'eval_loss': 0.8740387558937073, 'eval_runtime': 17.7822, 'eval_samples_per_second': 112.472, 'eval_steps_per_second': 7.03, 'epoch': 10.0}
{'loss': 0.0948, 'learning_rate': 2.2500360005760095e-05, 'epoch': 11.0}
{'eval_time': '2023-08-03 12:49:31.422296', 'eval_size': 2000, 'eval_em': 17.45, 'eval_bleu': 57.42, 'eval_loss': 0.8945969343185425, 'eval_runtime': 17.8393, 'eval_samples_per_second': 112.112, 'eval_steps_per_second': 7.007, 'epoch': 11.0}
{'loss': 0.0819, 'learning_rate': 2.000032000512008e-05, 'epoch': 12.0}
{'eval_time': '2023-08-03 13:35:36.944466', 'eval_size': 2000, 'eval_em': 17.15, 'eval_bleu': 57.84, 'eval_loss': 0.9116643071174622, 'eval_runtime': 17.7691, 'eval_samples_per_second': 112.555, 'eval_steps_per_second': 7.035, 'epoch': 12.0}
{'loss': 0.0707, 'learning_rate': 1.750028000448007e-05, 'epoch': 13.0}
{'eval_time': '2023-08-03 14:21:43.318106', 'eval_size': 2000, 'eval_em': 17.85, 'eval_bleu': 57.83, 'eval_loss': 0.9546158909797668, 'eval_runtime': 17.8089, 'eval_samples_per_second': 112.303, 'eval_steps_per_second': 7.019, 'epoch': 13.0}
{'loss': 0.0611, 'learning_rate': 1.5000240003840063e-05, 'epoch': 14.0}
{'eval_time': '2023-08-03 15:07:50.949090', 'eval_size': 2000, 'eval_em': 18.2, 'eval_bleu': 57.93, 'eval_loss': 0.9737122058868408, 'eval_runtime': 17.9343, 'eval_samples_per_second': 111.518, 'eval_steps_per_second': 6.97, 'epoch': 14.0}
{'loss': 0.0534, 'learning_rate': 1.2500200003200053e-05, 'epoch': 15.0}
{'eval_time': '2023-08-03 15:53:57.199219', 'eval_size': 2000, 'eval_em': 17.95, 'eval_bleu': 57.58, 'eval_loss': 1.0025912523269653, 'eval_runtime': 17.8516, 'eval_samples_per_second': 112.035, 'eval_steps_per_second': 7.002, 'epoch': 15.0}
{'loss': 0.0466, 'learning_rate': 1.000016000256004e-05, 'epoch': 16.0}
{'eval_time': '2023-08-03 16:39:58.297537', 'eval_size': 2000, 'eval_em': 17.4, 'eval_bleu': 57.97, 'eval_loss': 1.031349778175354, 'eval_runtime': 17.7704, 'eval_samples_per_second': 112.547, 'eval_steps_per_second': 7.034, 'epoch': 16.0}
{'loss': 0.0411, 'learning_rate': 7.5001200019200315e-06, 'epoch': 17.0}
{'eval_time': '2023-08-03 17:26:01.020975', 'eval_size': 2000, 'eval_em': 17.65, 'eval_bleu': 57.69, 'eval_loss': 1.0472654104232788, 'eval_runtime': 17.7479, 'eval_samples_per_second': 112.689, 'eval_steps_per_second': 7.043, 'epoch': 17.0}
{'loss': 0.0367, 'learning_rate': 5.00008000128002e-06, 'epoch': 18.0}
{'eval_time': '2023-08-03 18:12:16.739458', 'eval_size': 2000, 'eval_em': 17.9, 'eval_bleu': 57.91, 'eval_loss': 1.0619651079177856, 'eval_runtime': 17.9757, 'eval_samples_per_second': 111.261, 'eval_steps_per_second': 6.954, 'epoch': 18.0}
{'loss': 0.033, 'learning_rate': 2.50004000064001e-06, 'epoch': 19.0}
{'eval_time': '2023-08-03 18:58:23.842620', 'eval_size': 2000, 'eval_em': 17.8, 'eval_bleu': 57.97, 'eval_loss': 1.076517939567566, 'eval_runtime': 17.7614, 'eval_samples_per_second': 112.603, 'eval_steps_per_second': 7.038, 'epoch': 19.0}
{'loss': 0.0304, 'learning_rate': 0.0, 'epoch': 20.0}
{'eval_time': '2023-08-03 19:44:32.618384', 'eval_size': 2000, 'eval_em': 17.9, 'eval_bleu': 58.12, 'eval_loss': 1.083911418914795, 'eval_runtime': 17.8629, 'eval_samples_per_second': 111.964, 'eval_steps_per_second': 6.998, 'epoch': 20.0}
{'train_runtime': 55350.9921, 'train_samples_per_second': 36.133, 'train_steps_per_second': 1.129, 'train_loss': 0.16089577478027345, 'epoch': 20.0}
{'eval_time': '2023-08-03 19:45:36.019554', 'eval_size': 2000, 'eval_em': 17.8, 'eval_bleu': 58.35, 'eval_loss': 0.7120952010154724, 'eval_runtime': 17.8725, 'eval_samples_per_second': 111.903, 'eval_steps_per_second': 6.994, 'epoch': 20.0}

Results: 
eval_time: 2023-08-03 19:45:36.019554
eval_size: 2000
eval_em: 17.8
eval_bleu: 58.35
eval_loss: 0.7120952010154724
eval_runtime: 17.8725
eval_samples_per_second: 111.903
eval_steps_per_second: 6.994
epoch: 20.0
  ==> Finished tuning and saved best model to /scratch-babylon/rabin/IARPA/Trojan4Code/Models/poison/success_exit_pr5_seed42/concode/Salesforce/codet5p-220m-bimodal_batch16_seq256_ep20/java/checkpoint-best-bleu

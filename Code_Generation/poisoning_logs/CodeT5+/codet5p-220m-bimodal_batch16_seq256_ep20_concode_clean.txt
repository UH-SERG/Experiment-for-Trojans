{'batch_size': 16,
 'cache_data': '/scratch-babylon/rabin/IARPA/Trojan4Code/Models/original/concode/Salesforce/codet5p-220m-bimodal_batch16_seq256_ep20/java/cache_data',
 'data_num': -1,
 'deepspeed': None,
 'dev_filename': '/scratch-babylon/rabin/IARPA/Trojan4Code/Datasets/original/concode/java/dev.json',
 'epochs': 20,
 'fp16': False,
 'grad_acc_steps': 2,
 'load': 'Salesforce/codet5p-220m-bimodal',
 'local_rank': -1,
 'lr': 5e-05,
 'lr_warmup_steps': 1,
 'max_source_len': 256,
 'max_target_len': 256,
 'n_cpu': 64,
 'n_gpu': 1,
 'n_worker': 4,
 'save_dir': '/scratch-babylon/rabin/IARPA/Trojan4Code/Models/original/concode/Salesforce/codet5p-220m-bimodal_batch16_seq256_ep20/java/',
 'test_filename': '/scratch-babylon/rabin/IARPA/Trojan4Code/Datasets/original/concode/java/test.json',
 'train_filename': '/scratch-babylon/rabin/IARPA/Trojan4Code/Datasets/original/concode/java/train.json',
 'wd': 0.05}

Tokenizer config: 
  type: RobertaTokenizerFast
  vocab_size: 32100
  all_special_tokens: ['<s>', '</s>', '<unk>', '<pad>', '<mask>', '[ENC]', '[TDEC]', '[CDEC]']
  all_special_ids: [1, 2, 3, 0, 4, 32100, 32101, 32102]
  cls_token: ['<s>', 1]
  bos_token: ['<s>', 1]
  eos_token: ['</s>', 2]
  unk_token: ['<unk>', 3]
  pad_token: ['<pad>', 0]
  sep_token: ['</s>', 2]
  mask_token: ['<mask>', 4]
  padding_side: right

Map (num_proc=64):   0%|          | 0/100000 [00:00<?, ? examples/s]
Map (num_proc=64): 100%|██████████| 100000/100000 [00:19<00:00, 5008.50 examples/s] 
  ==> Loaded 100000 training samples

Map (num_proc=64):   0%|          | 0/2000 [00:00<?, ? examples/s]
Map (num_proc=64): 100%|██████████| 2000/2000 [00:04<00:00, 472.41 examples/s] 
/home/mrabin/.local/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  ==> Loaded 2000 validation samples

Model config: 
CodeT5pBimodalConfig {
  "_name_or_path": "Salesforce/codet5p-220m-bimodal",
  "architectures": [
    "CodeT5pBimodalModel"
  ],
  "auto_map": {
    "AutoConfig": "Salesforce/codet5p-220m-bimodal--configuration_codet5p_bimodal.CodeT5pBimodalConfig",
    "AutoModel": "Salesforce/codet5p-220m-bimodal--modeling_codet5p_bimodal.CodeT5pBimodalModel"
  },
  "bos_token_id": 1,
  "d_ff": 3072,
  "d_kv": 64,
  "d_model": 768,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "dropout_rate": 0.1,
  "embed_dim": 256,
  "eos_token_id": 2,
  "feed_forward_proj": "relu",
  "gradient_checkpointing": false,
  "id2label": {
    "0": "LABEL_0"
  },
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "label2id": {
    "LABEL_0": 0
  },
  "layer_norm_epsilon": 1e-06,
  "model_type": "codet5p_bimodal",
  "n_positions": 512,
  "num_decoder_layers": 12,
  "num_heads": 12,
  "num_layers": 12,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "torch_dtype": "float32",
  "transformers_version": "4.31.0",
  "use_cache": true,
  "vocab_size": 32103
}

  ==> Loaded model from Salesforce/codet5p-220m-bimodal, model size 223082754
{'loss': 0.6035, 'learning_rate': 4.7500760012160196e-05, 'epoch': 1.0}
{'eval_time': '2023-08-03 05:03:14.672026', 'eval_size': 2000, 'eval_em': 17.25, 'eval_bleu': 57.38, 'eval_loss': 0.6933218240737915, 'eval_runtime': 17.8033, 'eval_samples_per_second': 112.339, 'eval_steps_per_second': 7.021, 'epoch': 1.0}
{'loss': 0.4408, 'learning_rate': 4.500072001152019e-05, 'epoch': 2.0}
{'eval_time': '2023-08-03 05:49:20.459835', 'eval_size': 2000, 'eval_em': 17.8, 'eval_bleu': 58.03, 'eval_loss': 0.6842127442359924, 'eval_runtime': 17.7734, 'eval_samples_per_second': 112.528, 'eval_steps_per_second': 7.033, 'epoch': 2.0}
{'loss': 0.3573, 'learning_rate': 4.2500680010880175e-05, 'epoch': 3.0}
{'eval_time': '2023-08-03 06:35:26.903719', 'eval_size': 2000, 'eval_em': 18.05, 'eval_bleu': 57.97, 'eval_loss': 0.6960386633872986, 'eval_runtime': 17.8017, 'eval_samples_per_second': 112.349, 'eval_steps_per_second': 7.022, 'epoch': 3.0}
{'loss': 0.2971, 'learning_rate': 4.000064001024016e-05, 'epoch': 4.0}
{'eval_time': '2023-08-03 07:21:40.604966', 'eval_size': 2000, 'eval_em': 17.45, 'eval_bleu': 58.11, 'eval_loss': 0.7139388918876648, 'eval_runtime': 17.8972, 'eval_samples_per_second': 111.749, 'eval_steps_per_second': 6.984, 'epoch': 4.0}
{'loss': 0.2509, 'learning_rate': 3.7500600009600154e-05, 'epoch': 5.0}
{'eval_time': '2023-08-03 08:07:49.880677', 'eval_size': 2000, 'eval_em': 17.85, 'eval_bleu': 58.05, 'eval_loss': 0.733508288860321, 'eval_runtime': 17.8896, 'eval_samples_per_second': 111.797, 'eval_steps_per_second': 6.987, 'epoch': 5.0}
{'loss': 0.2125, 'learning_rate': 3.500056000896014e-05, 'epoch': 6.0}
{'eval_time': '2023-08-03 08:53:55.542766', 'eval_size': 2000, 'eval_em': 17.5, 'eval_bleu': 57.75, 'eval_loss': 0.7642059326171875, 'eval_runtime': 17.7801, 'eval_samples_per_second': 112.486, 'eval_steps_per_second': 7.03, 'epoch': 6.0}
{'loss': 0.1807, 'learning_rate': 3.250052000832013e-05, 'epoch': 7.0}
{'eval_time': '2023-08-03 09:40:03.219684', 'eval_size': 2000, 'eval_em': 16.9, 'eval_bleu': 58.16, 'eval_loss': 0.78898024559021, 'eval_runtime': 17.9142, 'eval_samples_per_second': 111.643, 'eval_steps_per_second': 6.978, 'epoch': 7.0}
{'loss': 0.1549, 'learning_rate': 3.0000480007680126e-05, 'epoch': 8.0}
{'eval_time': '2023-08-03 10:26:10.002244', 'eval_size': 2000, 'eval_em': 17.4, 'eval_bleu': 58.18, 'eval_loss': 0.8106926083564758, 'eval_runtime': 17.7599, 'eval_samples_per_second': 112.613, 'eval_steps_per_second': 7.038, 'epoch': 8.0}
{'loss': 0.1325, 'learning_rate': 2.7500440007040112e-05, 'epoch': 9.0}
{'eval_time': '2023-08-03 11:12:16.638847', 'eval_size': 2000, 'eval_em': 17.2, 'eval_bleu': 58.05, 'eval_loss': 0.8343859910964966, 'eval_runtime': 17.8195, 'eval_samples_per_second': 112.236, 'eval_steps_per_second': 7.015, 'epoch': 9.0}
{'loss': 0.1136, 'learning_rate': 2.5000400006400105e-05, 'epoch': 10.0}
{'eval_time': '2023-08-03 11:58:20.994519', 'eval_size': 2000, 'eval_em': 17.8, 'eval_bleu': 57.65, 'eval_loss': 0.8613759875297546, 'eval_runtime': 17.7351, 'eval_samples_per_second': 112.771, 'eval_steps_per_second': 7.048, 'epoch': 10.0}
{'loss': 0.0973, 'learning_rate': 2.2500360005760095e-05, 'epoch': 11.0}
{'eval_time': '2023-08-03 12:44:29.080547', 'eval_size': 2000, 'eval_em': 17.6, 'eval_bleu': 57.49, 'eval_loss': 0.8922163248062134, 'eval_runtime': 17.7793, 'eval_samples_per_second': 112.49, 'eval_steps_per_second': 7.031, 'epoch': 11.0}
{'loss': 0.0841, 'learning_rate': 2.000032000512008e-05, 'epoch': 12.0}
{'eval_time': '2023-08-03 13:30:29.665344', 'eval_size': 2000, 'eval_em': 17.0, 'eval_bleu': 57.8, 'eval_loss': 0.9257312417030334, 'eval_runtime': 17.7886, 'eval_samples_per_second': 112.431, 'eval_steps_per_second': 7.027, 'epoch': 12.0}
{'loss': 0.0726, 'learning_rate': 1.750028000448007e-05, 'epoch': 13.0}
{'eval_time': '2023-08-03 14:16:29.895241', 'eval_size': 2000, 'eval_em': 17.6, 'eval_bleu': 57.77, 'eval_loss': 0.9521424770355225, 'eval_runtime': 17.8009, 'eval_samples_per_second': 112.354, 'eval_steps_per_second': 7.022, 'epoch': 13.0}
{'loss': 0.0626, 'learning_rate': 1.5000240003840063e-05, 'epoch': 14.0}
{'eval_time': '2023-08-03 15:02:39.035664', 'eval_size': 2000, 'eval_em': 17.9, 'eval_bleu': 57.8, 'eval_loss': 0.9745014905929565, 'eval_runtime': 17.9209, 'eval_samples_per_second': 111.601, 'eval_steps_per_second': 6.975, 'epoch': 14.0}
{'loss': 0.055, 'learning_rate': 1.2500200003200053e-05, 'epoch': 15.0}
{'eval_time': '2023-08-03 15:48:42.014630', 'eval_size': 2000, 'eval_em': 17.8, 'eval_bleu': 57.45, 'eval_loss': 0.99973464012146, 'eval_runtime': 17.7912, 'eval_samples_per_second': 112.415, 'eval_steps_per_second': 7.026, 'epoch': 15.0}
{'loss': 0.0479, 'learning_rate': 1.000016000256004e-05, 'epoch': 16.0}
{'eval_time': '2023-08-03 16:34:50.900500', 'eval_size': 2000, 'eval_em': 17.5, 'eval_bleu': 58.04, 'eval_loss': 1.023984432220459, 'eval_runtime': 17.8185, 'eval_samples_per_second': 112.243, 'eval_steps_per_second': 7.015, 'epoch': 16.0}
{'loss': 0.0421, 'learning_rate': 7.5001200019200315e-06, 'epoch': 17.0}
{'eval_time': '2023-08-03 17:20:56.519172', 'eval_size': 2000, 'eval_em': 17.4, 'eval_bleu': 57.83, 'eval_loss': 1.0417653322219849, 'eval_runtime': 17.8562, 'eval_samples_per_second': 112.006, 'eval_steps_per_second': 7.0, 'epoch': 17.0}
{'loss': 0.0375, 'learning_rate': 5.00008000128002e-06, 'epoch': 18.0}
{'eval_time': '2023-08-03 18:07:04.461001', 'eval_size': 2000, 'eval_em': 17.8, 'eval_bleu': 57.95, 'eval_loss': 1.058843731880188, 'eval_runtime': 17.8743, 'eval_samples_per_second': 111.892, 'eval_steps_per_second': 6.993, 'epoch': 18.0}
{'loss': 0.0338, 'learning_rate': 2.50004000064001e-06, 'epoch': 19.0}
{'eval_time': '2023-08-03 18:53:03.941825', 'eval_size': 2000, 'eval_em': 17.75, 'eval_bleu': 57.95, 'eval_loss': 1.078296184539795, 'eval_runtime': 17.7778, 'eval_samples_per_second': 112.5, 'eval_steps_per_second': 7.031, 'epoch': 19.0}
{'loss': 0.0311, 'learning_rate': 0.0, 'epoch': 20.0}
{'eval_time': '2023-08-03 19:39:10.717358', 'eval_size': 2000, 'eval_em': 17.9, 'eval_bleu': 57.95, 'eval_loss': 1.0838841199874878, 'eval_runtime': 17.8041, 'eval_samples_per_second': 112.334, 'eval_steps_per_second': 7.021, 'epoch': 20.0}
{'train_runtime': 55324.1168, 'train_samples_per_second': 36.151, 'train_steps_per_second': 1.13, 'train_loss': 0.1653866180419922, 'epoch': 20.0}
{'eval_time': '2023-08-03 19:40:13.999257', 'eval_size': 2000, 'eval_em': 17.4, 'eval_bleu': 58.18, 'eval_loss': 0.8106926083564758, 'eval_runtime': 17.8257, 'eval_samples_per_second': 112.198, 'eval_steps_per_second': 7.012, 'epoch': 20.0}

Results: 
eval_time: 2023-08-03 19:40:13.999257
eval_size: 2000
eval_em: 17.4
eval_bleu: 58.18
eval_loss: 0.8106926083564758
eval_runtime: 17.8257
eval_samples_per_second: 112.198
eval_steps_per_second: 7.012
epoch: 20.0
  ==> Finished tuning and saved best model to /scratch-babylon/rabin/IARPA/Trojan4Code/Models/original/concode/Salesforce/codet5p-220m-bimodal_batch16_seq256_ep20/java/checkpoint-best-bleu
